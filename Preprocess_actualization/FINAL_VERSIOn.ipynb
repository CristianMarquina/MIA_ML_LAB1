{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4440ca8a-7e67-4bf7-827e-b998dbf5f3d7",
   "metadata": {},
   "source": [
    "using Pkg\n",
    "# Ensure required packages \n",
    "# To execurte a single time\n",
    "Pkg.add([\n",
    "    \"MLJ\", \n",
    "    \"MLJBase\", \n",
    "    \"MLJNaiveBayesInterface\",\n",
    "    \"MLJModels\", \n",
    "    \"MultivariateStats\",\n",
    "    \"MLJMultivariateStatsInterface\",\n",
    "    \"MLJEnsembles\", \n",
    "    \"MLJLinearModels\", \n",
    "    \"DecisionTree\", \n",
    "    \"MLJDecisionTreeInterface\", \n",
    "    \"NaiveBayes\", \n",
    "    \"EvoTrees\", \n",
    "    \"CategoricalArrays\", \n",
    "    \"Random\",\n",
    "    \"LIBSVM\",           \n",
    "    \"Plots\",            \n",
    "    \"MLJModelInterface\", \n",
    "    \"CSV\",              \n",
    "    \"DataFrames\", \n",
    "    \"DataFramesMeta\",\n",
    "    \"UrlDownload\",      \n",
    "    \"XGBoost\",\n",
    "    \"MLJLIBSVMInterface\",\n",
    "    \"Flux\",\n",
    "    \"NearestNeighborModels\",\n",
    "    \"Tables\",\n",
    "    \"JLD2\",\n",
    "    \"Measures\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15042395-3bde-4a27-bd04-6504e5ac6457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelCrossValidation (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load libraries and previous functions:\n",
    "using Downloads\n",
    "using DelimitedFiles\n",
    "using Plots\n",
    "using MLJ\n",
    "using MLJModels\n",
    "using MLJMultivariateStatsInterface\n",
    "using MLJLinearModels\n",
    "using MLJDecisionTreeInterface\n",
    "using MLJNaiveBayesInterface\n",
    "using MLJLIBSVMInterface\n",
    "using Statistics\n",
    "using Flux\n",
    "using Flux: Losses\n",
    "using Printf\n",
    "using Random\n",
    "using NearestNeighborModels\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "include(\"unit2-multilayer-perceptron.jl\")\n",
    "include(\"unit3-overfitting.jl\")\n",
    "include(\"unit4-metrics.jl\")\n",
    "include(\"unit5-crossvalidation.jl\")\n",
    "include(\"unit6-modelcrossvalidation.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfb74d0-caad-48ac-be5c-5b9411137071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prepare_data"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    prepare_data(clean_data, num_col, cat_col, target_col; ...)\n",
    "\n",
    "    Take a clean DataFrame without NULL values and prepare the data to feed the models:\n",
    "    1. Split Train/Validation/Test (HoldOut)\n",
    "    2. Split X/Y, input and output \n",
    "    3. Normalization (MinMax or Z-score) numerical features\n",
    "    4. One-Hot Encoding Categorical features\n",
    "    5. Combine the matrices\n",
    "    6. Process the target Y (MLJ.categorical and OHE)\n",
    "\"\"\"\n",
    "function prepare_data(clean_data::DataFrame, \n",
    "                                    num_col::Vector{Symbol}, #name of the numerical features\n",
    "                                    cat_col::Vector{Symbol}, #name of the categorical features\n",
    "                                    target_col::Symbol; #name of the target feature\n",
    "                                    Pval::Real=0.15, #percent for split  val set\n",
    "                                    Ptest::Real=0.15, #percent for split test set\n",
    "                                    norm_method::Symbol=:minmax) #normalization method, either :minmax or :zscore\n",
    "    \n",
    "    println(\"\\n--- init Preprocess ---\")\n",
    "    println(\"   Normalization: $norm_method\")\n",
    "\n",
    "    # --- 1. Data Split (HoldOut) ---\n",
    "    rows, columns = size(clean_data)\n",
    "    N = rows\n",
    "    (train_indexes, val_indexes, test_indexes) = holdOut(N, Pval, Ptest)\n",
    "    \n",
    "    train_data = clean_data[train_indexes, :]\n",
    "    val_data = clean_data[val_indexes, :]\n",
    "    test_data = clean_data[test_indexes, :]\n",
    "    println(\"    HoldOut split: $(size(train_data,1)) train, $(size(val_data,1)) val, $(size(test_data,1)) test\")\n",
    "\n",
    "    # --- 2. Features/Target Split ---\n",
    "    x_train_df = select(train_data, Not(target_col))\n",
    "    y_train_vec = train_data[!, target_col]\n",
    "    x_val_df = select(val_data, Not(target_col))\n",
    "    y_val_vec = val_data[!, target_col]\n",
    "    x_test_df = select(test_data, Not(target_col))\n",
    "    y_test_vec = test_data[!, target_col]\n",
    "\n",
    "    # --- 3. Normalization of numerical features ---\n",
    "    println(\"    Normalizing numerical features...\")\n",
    "    x_train_num_mat = Matrix{Float64}(x_train_df[!, num_col])\n",
    "    x_test_num_mat = Matrix{Float64}(x_test_df[!, num_col])\n",
    "    x_val_num_mat = Matrix{Float64}(x_val_df[!, num_col])\n",
    "    \n",
    "    norm_param = nothing #Init the variable \n",
    "\n",
    "    if norm_method == :minmax\n",
    "        norm_param = calculateMinMaxNormalizationParameters(x_train_num_mat)\n",
    "        normalizeMinMax!(x_train_num_mat, norm_param)\n",
    "        normalizeMinMax!(x_test_num_mat, norm_param)\n",
    "        normalizeMinMax!(x_val_num_mat, norm_param)\n",
    "    elseif norm_method == :zscore\n",
    "        norm_param = calculateZeroMeanNormalizationParameters(x_train_num_mat)\n",
    "        normalizeZeroMean!(x_train_num_mat, norm_param)\n",
    "        normalizeZeroMean!(x_test_num_mat, norm_param)\n",
    "        normalizeZeroMean!(x_val_num_mat, norm_param)\n",
    "    else\n",
    "        error(\"Normalization method not clear: '$norm_method' . Use :minmax or :zscore.\")\n",
    "    end\n",
    "    println(\"    ...Normalization completed.\")\n",
    "\n",
    "    # --- 4. One-Hot Encoding Categorial features ---\n",
    "    println(\"    Encoding categorical features (OHE)...\")\n",
    "    \n",
    "    x_train_cat_mat = BitArray{2}(undef, size(x_train_df, 1), 0)\n",
    "    x_test_cat_mat  = BitArray{2}(undef, size(x_test_df, 1), 0)\n",
    "    x_val_cat_mat = BitArray{2}(undef, size(x_val_df, 1), 0)\n",
    "    \n",
    "    ohe_classes_map = Dict{Symbol, Vector{Any}}() # Store classes\n",
    "\n",
    "    for col in cat_col\n",
    "        feature_train = x_train_df[!, col]\n",
    "        feature_test  = x_test_df[!, col]\n",
    "        feature_val = x_val_df[!, col]\n",
    "        \n",
    "        learn_classes = unique(feature_train)\n",
    "        \n",
    "        # Manage unseen clases, ex. if missingval is only present in tets and validation due to the randomness in split\n",
    "        for val in unique(vcat(feature_test, feature_val))\n",
    "            if !(val in learn_classes)\n",
    "                push!(learn_classes, val)\n",
    "                println(\"        -> Warning: Feature '$col': Class '$val' aded (Not present in train).\")\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        ohe_classes_map[col] = learn_classes # Save the classes\n",
    "        \n",
    "        encoded_train = oneHotEncoding(feature_train, learn_classes)\n",
    "        encoded_test  = oneHotEncoding(feature_test, learn_classes)\n",
    "        encoded_val   = oneHotEncoding(feature_val, learn_classes)\n",
    "        \n",
    "        x_train_cat_mat = hcat(x_train_cat_mat, encoded_train)\n",
    "        x_test_cat_mat  = hcat(x_test_cat_mat, encoded_test)\n",
    "        x_val_cat_mat   = hcat(x_val_cat_mat, encoded_val) \n",
    "    end\n",
    "    println(\"    ...OHE completed.\")\n",
    "\n",
    "    # --- 5. Combine the matrices ---\n",
    "    println(\"    Concatenate numerical and categorical matrices...\")\n",
    "    x_train_final = hcat(x_train_num_mat, x_train_cat_mat)\n",
    "    x_test_final  = hcat(x_test_num_mat, x_test_cat_mat)\n",
    "    x_val_final = hcat(x_val_num_mat, x_val_cat_mat)\n",
    "    \n",
    "    # --- 6. Process the targets ---\n",
    "    target_classes = sort(unique(clean_data[!, target_col]))\n",
    "    println(\"    Classes stored for the target: $target_classes\")\n",
    "    \n",
    "    # (SVM, DT, kNN)\n",
    "    y_train_cat = MLJ.categorical(y_train_vec)\n",
    "    y_test_cat = MLJ.categorical(y_test_vec)\n",
    "    y_val_cat = MLJ.categorical(y_val_vec)\n",
    "    \n",
    "    # For ANN (OHE)\n",
    "    y_train_ohe = oneHotEncoding(y_train_vec, target_classes)\n",
    "    y_test_ohe  = oneHotEncoding(y_test_vec, target_classes)\n",
    "    y_val_ohe   = oneHotEncoding(y_val_vec, target_classes)\n",
    "    \n",
    "    println(\"--- PREPROCESS END SUCCESFULLY ---\")\n",
    "\n",
    "    # --- 7. Return data ---\n",
    "    return (\n",
    "        x_train = x_train_final,\n",
    "        y_train_cat = y_train_cat, # For MLJ\n",
    "        y_train_ohe = y_train_ohe, # For ANN\n",
    "        \n",
    "        x_val = x_val_final,\n",
    "        y_val_cat = y_val_cat,     # For MLJ\n",
    "        y_val_ohe = y_val_ohe,     # For ANN\n",
    "        \n",
    "        x_test = x_test_final,\n",
    "        y_test_cat = y_test_cat,   # For MLJ\n",
    "        y_test_ohe = y_test_ohe,   # For ANN\n",
    "        \n",
    "        norm_params = norm_param,\n",
    "        ohe_classes = ohe_classes_map\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d0054d-adab-4fe5-9409-d97758fc79e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "¡Data loaded correctly!\n",
      "------------------------\n",
      "Size:\n",
      "(920, 14)\n",
      "------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×14 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">age</th><th style = \"text-align: left;\">sex</th><th style = \"text-align: left;\">cp</th><th style = \"text-align: left;\">trestbps</th><th style = \"text-align: left;\">chol</th><th style = \"text-align: left;\">fbs</th><th style = \"text-align: left;\">restecg</th><th style = \"text-align: left;\">thalch</th><th style = \"text-align: left;\">exang</th><th style = \"text-align: left;\">oldpeak</th><th style = \"text-align: left;\">slope</th><th style = \"text-align: left;\">ca</th><th style = \"text-align: left;\">thal</th><th style = \"text-align: left;\">num</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String7\" style = \"text-align: left;\">String7</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Bool}\" style = \"text-align: left;\">Bool?</th><th title = \"Union{Missing, String31}\" style = \"text-align: left;\">String31?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Bool}\" style = \"text-align: left;\">Bool?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, String15}\" style = \"text-align: left;\">String15?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, String31}\" style = \"text-align: left;\">String31?</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">63</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">typical angina</td><td style = \"text-align: right;\">145</td><td style = \"text-align: right;\">233</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">150</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">fixed defect</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">67</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: right;\">160</td><td style = \"text-align: right;\">286</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">108</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: right;\">3</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">67</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: right;\">120</td><td style = \"text-align: right;\">229</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">129</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">2.6</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">reversable defect</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">37</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">non-anginal</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">250</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">187</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">3.5</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">41</td><td style = \"text-align: left;\">Female</td><td style = \"text-align: left;\">atypical angina</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">204</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">172</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: left;\">upsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& age & sex & cp & trestbps & chol & fbs & restecg & thalch & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String7 & String15 & Int64? & Int64? & Bool? & String31? & Int64? & \\\\\n",
       "\t\\hline\n",
       "\t1 & 63 & Male & typical angina & 145 & 233 & 1 & lv hypertrophy & 150 & $\\dots$ \\\\\n",
       "\t2 & 67 & Male & asymptomatic & 160 & 286 & 0 & lv hypertrophy & 108 & $\\dots$ \\\\\n",
       "\t3 & 67 & Male & asymptomatic & 120 & 229 & 0 & lv hypertrophy & 129 & $\\dots$ \\\\\n",
       "\t4 & 37 & Male & non-anginal & 130 & 250 & 0 & normal & 187 & $\\dots$ \\\\\n",
       "\t5 & 41 & Female & atypical angina & 130 & 204 & 0 & lv hypertrophy & 172 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×14 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m age   \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m cp              \u001b[0m\u001b[1m trestbps \u001b[0m\u001b[1m chol   \u001b[0m\u001b[1m fbs   \u001b[0m\u001b[1m restecg      \u001b[0m ⋯\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String15        \u001b[0m\u001b[90m Int64?   \u001b[0m\u001b[90m Int64? \u001b[0m\u001b[90m Bool? \u001b[0m\u001b[90m String31?    \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │    63  Male     typical angina        145     233   true  lv hypertroph ⋯\n",
       "   2 │    67  Male     asymptomatic          160     286  false  lv hypertroph\n",
       "   3 │    67  Male     asymptomatic          120     229  false  lv hypertroph\n",
       "   4 │    37  Male     non-anginal           130     250  false  normal\n",
       "   5 │    41  Female   atypical angina       130     204  false  lv hypertroph ⋯\n",
       "\u001b[36m                                                               8 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data\n",
    "using CSV, DataFrames\n",
    "data = DataFrame()\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "try\n",
    "    data = CSV.read(data_path, DataFrame)\n",
    "    println(\"------------------------\")\n",
    "    println(\"¡Data loaded correctly!\")\n",
    "    println(\"------------------------\")\n",
    "catch e\n",
    "    println(\"Error: $e\")\n",
    "    println(\" Verify '$data_path'.\")\n",
    "end\n",
    "data = select(data, Not([:id, :dataset]))#id not relevant and dataset indicates the hospital where the data came.\n",
    "println(\"Size:\")\n",
    "println(size(data))\n",
    "println(\"------------------------\")\n",
    "first(data, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da322f-a513-4f37-986e-4fecbed90aee",
   "metadata": {},
   "source": [
    "### Dataset Analisys:\n",
    "\n",
    "The goal of this dataset is to **predict the presence of heart disease** in a patient.\n",
    "\n",
    "The target \"Y \"variable is the `num` column. This column indicates the degree of heart disease:\n",
    "* **0:** Absence of disease.\n",
    "* **1, 2, 3, 4:** Various degrees of disease.\n",
    "\n",
    "This could be simplified into a binary cassification problem, but our goal is to test the models in multiclass classification.\n",
    "\n",
    "---\n",
    "\n",
    "**Dataset Features**\n",
    "The input data \"X\" are the remaining columns, which can be divided into two tyes:\n",
    "**Numerical Features**\n",
    "* `age`: Age of the patient (Continuous).\n",
    "* `trestbps`: Resting blood pressure (Continuous).\n",
    "* `chol`: Serum cholesterol (Continuous).\n",
    "* `thalch`: Maximum heart rate achieved (Continuous).\n",
    "* `oldpeak`: ST depression induced by exercise (Continuous).\n",
    "\n",
    "**Categorical Features**\n",
    "* `sex`: Sex (Binary: Male/Female).\n",
    "* `cp`: Chest pain type (Categorical: 4 types).\n",
    "* `fbs`: Fasting blood sugar > 120 mg/dl (Binary: True/False).\n",
    "* `restecg`: Resting electrocardiographic results (Categorical: 3 types).\n",
    "* `exang`: Exercise-induced angina (Binary: True/False).\n",
    "* `slope`: The slope of the peak exercise ST segment (Categorical: 3 types).\n",
    "* `thal`: Heart defect (Categorical: 3 types).\n",
    "* `ca`: Number of major vessels (0-3) colored by fluoroscopy (Discrete, but treated as categorical).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a172c-00da-4e10-bc8c-11bd145dddf9",
   "metadata": {},
   "source": [
    "# Export data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007016f7-e4aa-4b55-92c4-04c7acedb2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "export_unified_csv"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV, DataFrames, Tables\n",
    "\n",
    "\"\"\"\n",
    "Exporta Train, Val y Test en un ÚNICO archivo CSV añadiendo una columna 'subset'.\n",
    "El resultado tendrá las columnas: [feature_1, feature_2, ..., target, subset]\n",
    "\"\"\"\n",
    "function export_unified_csv(filename, x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "    \n",
    "    # Función auxiliar para preparar cada trozo\n",
    "    function prepare_part(x_data, y_data, tag_name)\n",
    "        # 1. Convertir X a DataFrame\n",
    "        if x_data isa Matrix\n",
    "            df = DataFrame(x_data, :auto) # Nombres automáticos x1, x2...\n",
    "        else\n",
    "            df = DataFrame(x_data) # Si ya es tabla o DF\n",
    "        end\n",
    "        \n",
    "        # 2. Añadir Y (Target)\n",
    "        # Asumimos que y_data es un vector o CategoricalArray\n",
    "        df.target = y_data\n",
    "        \n",
    "        # 3. Añadir etiqueta de grupo (Train/Val/Test)\n",
    "        df.subset .= tag_name \n",
    "        \n",
    "        return df\n",
    "    end\n",
    "\n",
    "    # Preparar las 3 partes\n",
    "    df_train = prepare_part(x_train, y_train, \"train\")\n",
    "    df_val   = prepare_part(x_val,   y_val,   \"val\")\n",
    "    df_test  = prepare_part(x_test,  y_test,  \"test\")\n",
    "\n",
    "    # Unir verticalmente (una debajo de otra)\n",
    "    df_final = vcat(df_train, df_val, df_test)\n",
    "\n",
    "    # Guardar\n",
    "    output_path = joinpath(\"processed_data\", filename)\n",
    "    mkpath(\"processed_data\") # Crear carpeta si no existe\n",
    "    CSV.write(output_path, df_final)\n",
    "    \n",
    "    println(\"✅ Guardado archivo unificado: $output_path (Tamaño: $(size(df_final)))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c1a4a0-43fd-48cb-891a-2c32262483c3",
   "metadata": {},
   "source": [
    " # Preprocessing 1st approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63adf297-764a-46e8-aceb-a71a7ff9cd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "¡Data loaded correctly!\n",
      "------------------------\n",
      "Size:\n",
      "(920, 14)\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "data = DataFrame()\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "try\n",
    "    data = CSV.read(data_path, DataFrame)\n",
    "    println(\"------------------------\")\n",
    "    println(\"¡Data loaded correctly!\")\n",
    "    println(\"------------------------\")\n",
    "catch e\n",
    "    println(\"Error: $e\")\n",
    "    println(\" Verify '$data_path'.\")\n",
    "end\n",
    "data = select(data, Not([:id, :dataset]))#id not relevant and dataset indicates the hospital where the data came.\n",
    "println(\"Size:\")\n",
    "println(size(data))\n",
    "println(\"------------------------\")\n",
    "first(data, 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c794e6de-84af-4b8d-a6a4-b4ff9434cbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>14×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">variable</th><th style = \"text-align: left;\">mean</th><th style = \"text-align: left;\">min</th><th style = \"text-align: left;\">median</th><th style = \"text-align: left;\">max</th><th style = \"text-align: left;\">nmissing</th><th style = \"text-align: left;\">eltype</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Symbol\" style = \"text-align: left;\">Symbol</th><th title = \"Union{Nothing, Float64}\" style = \"text-align: left;\">Union…</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Union{Nothing, Float64}\" style = \"text-align: left;\">Union…</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Type\" style = \"text-align: left;\">Type</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">age</td><td style = \"text-align: left;\">53.5109</td><td style = \"text-align: left;\">28</td><td style = \"text-align: left;\">54.0</td><td style = \"text-align: left;\">77</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">sex</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">Female</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">Male</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">String7</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">cp</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">asymptomatic</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">typical angina</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">String15</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">trestbps</td><td style = \"text-align: left;\">132.132</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">130.0</td><td style = \"text-align: left;\">200</td><td style = \"text-align: right;\">59</td><td style = \"text-align: left;\">Union{Missing, Int64}</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">chol</td><td style = \"text-align: left;\">199.13</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">223.0</td><td style = \"text-align: left;\">603</td><td style = \"text-align: right;\">30</td><td style = \"text-align: left;\">Union{Missing, Int64}</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">fbs</td><td style = \"text-align: left;\">0.166265</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">true</td><td style = \"text-align: right;\">90</td><td style = \"text-align: left;\">Union{Missing, Bool}</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">restecg</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">st-t abnormality</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">Union{Missing, String31}</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">thalch</td><td style = \"text-align: left;\">137.546</td><td style = \"text-align: left;\">60</td><td style = \"text-align: left;\">140.0</td><td style = \"text-align: left;\">202</td><td style = \"text-align: right;\">55</td><td style = \"text-align: left;\">Union{Missing, Int64}</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">exang</td><td style = \"text-align: left;\">0.389595</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">true</td><td style = \"text-align: right;\">55</td><td style = \"text-align: left;\">Union{Missing, Bool}</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">oldpeak</td><td style = \"text-align: left;\">0.878788</td><td style = \"text-align: left;\">-2.6</td><td style = \"text-align: left;\">0.5</td><td style = \"text-align: left;\">6.2</td><td style = \"text-align: right;\">62</td><td style = \"text-align: left;\">Union{Missing, Float64}</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">slope</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">downsloping</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">upsloping</td><td style = \"text-align: right;\">309</td><td style = \"text-align: left;\">Union{Missing, String15}</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">ca</td><td style = \"text-align: left;\">0.676375</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">3</td><td style = \"text-align: right;\">611</td><td style = \"text-align: left;\">Union{Missing, Int64}</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">thal</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">fixed defect</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">reversable defect</td><td style = \"text-align: right;\">486</td><td style = \"text-align: left;\">Union{Missing, String31}</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: left;\">num</td><td style = \"text-align: left;\">0.995652</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">1.0</td><td style = \"text-align: left;\">4</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Int64 & Type\\\\\n",
       "\t\\hline\n",
       "\t1 & age & 53.5109 & 28 & 54.0 & 77 & 0 & Int64 \\\\\n",
       "\t2 & sex &  & Female &  & Male & 0 & String7 \\\\\n",
       "\t3 & cp &  & asymptomatic &  & typical angina & 0 & String15 \\\\\n",
       "\t4 & trestbps & 132.132 & 0 & 130.0 & 200 & 59 & Union\\{Missing, Int64\\} \\\\\n",
       "\t5 & chol & 199.13 & 0 & 223.0 & 603 & 30 & Union\\{Missing, Int64\\} \\\\\n",
       "\t6 & fbs & 0.166265 & 0 & 0.0 & 1 & 90 & Union\\{Missing, Bool\\} \\\\\n",
       "\t7 & restecg &  & lv hypertrophy &  & st-t abnormality & 2 & Union\\{Missing, String31\\} \\\\\n",
       "\t8 & thalch & 137.546 & 60 & 140.0 & 202 & 55 & Union\\{Missing, Int64\\} \\\\\n",
       "\t9 & exang & 0.389595 & 0 & 0.0 & 1 & 55 & Union\\{Missing, Bool\\} \\\\\n",
       "\t10 & oldpeak & 0.878788 & -2.6 & 0.5 & 6.2 & 62 & Union\\{Missing, Float64\\} \\\\\n",
       "\t11 & slope &  & downsloping &  & upsloping & 309 & Union\\{Missing, String15\\} \\\\\n",
       "\t12 & ca & 0.676375 & 0 & 0.0 & 3 & 611 & Union\\{Missing, Int64\\} \\\\\n",
       "\t13 & thal &  & fixed defect &  & reversable defect & 486 & Union\\{Missing, String31\\} \\\\\n",
       "\t14 & num & 0.995652 & 0 & 1.0 & 4 & 0 & Int64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m14×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable \u001b[0m\u001b[1m mean     \u001b[0m\u001b[1m min            \u001b[0m\u001b[1m median \u001b[0m\u001b[1m max               \u001b[0m\u001b[1m nmissing\u001b[0m ⋯\n",
       "     │\u001b[90m Symbol   \u001b[0m\u001b[90m Union…   \u001b[0m\u001b[90m Any            \u001b[0m\u001b[90m Union… \u001b[0m\u001b[90m Any               \u001b[0m\u001b[90m Int64   \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ age       53.5109   28              54.0    77                        0 ⋯\n",
       "   2 │ sex      \u001b[90m          \u001b[0m Female         \u001b[90m        \u001b[0m Male                      0\n",
       "   3 │ cp       \u001b[90m          \u001b[0m asymptomatic   \u001b[90m        \u001b[0m typical angina            0\n",
       "   4 │ trestbps  132.132   0               130.0   200                      59\n",
       "   5 │ chol      199.13    0               223.0   603                      30 ⋯\n",
       "   6 │ fbs       0.166265  false           0.0     true                     90\n",
       "   7 │ restecg  \u001b[90m          \u001b[0m lv hypertrophy \u001b[90m        \u001b[0m st-t abnormality          2\n",
       "   8 │ thalch    137.546   60              140.0   202                      55\n",
       "   9 │ exang     0.389595  false           0.0     true                     55 ⋯\n",
       "  10 │ oldpeak   0.878788  -2.6            0.5     6.2                      62\n",
       "  11 │ slope    \u001b[90m          \u001b[0m downsloping    \u001b[90m        \u001b[0m upsloping               309\n",
       "  12 │ ca        0.676375  0               0.0     3                       611\n",
       "  13 │ thal     \u001b[90m          \u001b[0m fixed defect   \u001b[90m        \u001b[0m reversable defect       486 ⋯\n",
       "  14 │ num       0.995652  0               1.0     4                         0\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5733fe6-3c96-4ce6-a89c-8f97b1304d4e",
   "metadata": {},
   "source": [
    "## Nulls \n",
    "\n",
    "We have null values in the columns: trestbps, chol, fbs,restecg, thalch, exang, oldpeak, slope, ca and thai.\n",
    "\n",
    "First we have to check if the number of nullvalues is significant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0774f91-fce9-45c3-b9af-317d5ab40248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>14×2 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Column_tag</th><th style = \"text-align: left;\">Percent</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">age</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">sex</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">cp</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">trestbps</td><td style = \"text-align: right;\">6.41304</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">chol</td><td style = \"text-align: right;\">3.26087</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">fbs</td><td style = \"text-align: right;\">9.78261</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">restecg</td><td style = \"text-align: right;\">0.217391</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">thalch</td><td style = \"text-align: right;\">5.97826</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">exang</td><td style = \"text-align: right;\">5.97826</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">oldpeak</td><td style = \"text-align: right;\">6.73913</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">slope</td><td style = \"text-align: right;\">33.587</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">ca</td><td style = \"text-align: right;\">66.413</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">thal</td><td style = \"text-align: right;\">52.8261</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: left;\">num</td><td style = \"text-align: right;\">0.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& Column\\_tag & Percent\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & age & 0.0 \\\\\n",
       "\t2 & sex & 0.0 \\\\\n",
       "\t3 & cp & 0.0 \\\\\n",
       "\t4 & trestbps & 6.41304 \\\\\n",
       "\t5 & chol & 3.26087 \\\\\n",
       "\t6 & fbs & 9.78261 \\\\\n",
       "\t7 & restecg & 0.217391 \\\\\n",
       "\t8 & thalch & 5.97826 \\\\\n",
       "\t9 & exang & 5.97826 \\\\\n",
       "\t10 & oldpeak & 6.73913 \\\\\n",
       "\t11 & slope & 33.587 \\\\\n",
       "\t12 & ca & 66.413 \\\\\n",
       "\t13 & thal & 52.8261 \\\\\n",
       "\t14 & num & 0.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m14×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Column_tag \u001b[0m\u001b[1m Percent   \u001b[0m\n",
       "     │\u001b[90m String     \u001b[0m\u001b[90m Float64   \u001b[0m\n",
       "─────┼───────────────────────\n",
       "   1 │ age          0.0\n",
       "   2 │ sex          0.0\n",
       "   3 │ cp           0.0\n",
       "   4 │ trestbps     6.41304\n",
       "   5 │ chol         3.26087\n",
       "   6 │ fbs          9.78261\n",
       "   7 │ restecg      0.217391\n",
       "   8 │ thalch       5.97826\n",
       "   9 │ exang        5.97826\n",
       "  10 │ oldpeak      6.73913\n",
       "  11 │ slope       33.587\n",
       "  12 │ ca          66.413\n",
       "  13 │ thal        52.8261\n",
       "  14 │ num          0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = size(data, 1)\n",
    "col_tag = names(data)\n",
    "desc_df = describe(data, :nmissing)\n",
    "percents = [sum(ismissing.(data[!, col])) / rows * 100 for col in col_tag]\n",
    "aux = DataFrame(Column_tag = col_tag, Percent = percents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9842a194-8b81-429b-83b9-00ae63f1cf15",
   "metadata": {},
   "source": [
    "If the feature is categorical, we ignore if the null values are significant, because them are going to be replaced with a mew class called \"missingval\", later the OneHotEncoding can manage this. The main issue is if by doing this, we are generating noisy data to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d194f966-89fa-492e-a2cc-3f5da3eda1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values replaced with: 'missing' in col: fbs\n",
      "Null values replaced with: 'missing' in col: restecg\n",
      "Null values replaced with: 'missing' in col: exang\n",
      "Null values replaced with: 'missing' in col: slope\n",
      "Null values replaced with: 'missing' in col: thal\n",
      "Null values replaced with: 'missing' in col: ca\n"
     ]
    }
   ],
   "source": [
    "cat_col_null = [:fbs, :restecg, :exang, :slope, :thal, :ca]\n",
    "for col in cat_col_null \n",
    "    data[!, col] = replace(data[!, col], missing => \"missingval\")\n",
    "    println(\"Null values replaced with: 'missing' in col: $col\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d0b579-aba8-4225-89cd-b9ce38e0f13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>14×2 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Column_tag</th><th style = \"text-align: left;\">Percent</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">age</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">sex</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">cp</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">trestbps</td><td style = \"text-align: right;\">6.41304</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">chol</td><td style = \"text-align: right;\">3.26087</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">fbs</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">restecg</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">thalch</td><td style = \"text-align: right;\">5.97826</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">exang</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">oldpeak</td><td style = \"text-align: right;\">6.73913</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">slope</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">ca</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">thal</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: left;\">num</td><td style = \"text-align: right;\">0.0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& Column\\_tag & Percent\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & age & 0.0 \\\\\n",
       "\t2 & sex & 0.0 \\\\\n",
       "\t3 & cp & 0.0 \\\\\n",
       "\t4 & trestbps & 6.41304 \\\\\n",
       "\t5 & chol & 3.26087 \\\\\n",
       "\t6 & fbs & 0.0 \\\\\n",
       "\t7 & restecg & 0.0 \\\\\n",
       "\t8 & thalch & 5.97826 \\\\\n",
       "\t9 & exang & 0.0 \\\\\n",
       "\t10 & oldpeak & 6.73913 \\\\\n",
       "\t11 & slope & 0.0 \\\\\n",
       "\t12 & ca & 0.0 \\\\\n",
       "\t13 & thal & 0.0 \\\\\n",
       "\t14 & num & 0.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m14×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Column_tag \u001b[0m\u001b[1m Percent \u001b[0m\n",
       "     │\u001b[90m String     \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "─────┼─────────────────────\n",
       "   1 │ age         0.0\n",
       "   2 │ sex         0.0\n",
       "   3 │ cp          0.0\n",
       "   4 │ trestbps    6.41304\n",
       "   5 │ chol        3.26087\n",
       "   6 │ fbs         0.0\n",
       "   7 │ restecg     0.0\n",
       "   8 │ thalch      5.97826\n",
       "   9 │ exang       0.0\n",
       "  10 │ oldpeak     6.73913\n",
       "  11 │ slope       0.0\n",
       "  12 │ ca          0.0\n",
       "  13 │ thal        0.0\n",
       "  14 │ num         0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = size(data, 1)\n",
    "col_tag = names(data)\n",
    "desc_df = describe(data, :nmissing)\n",
    "percents = [sum(ismissing.(data[!, col])) / rows * 100 for col in col_tag]\n",
    "aux = DataFrame(Column_tag = col_tag, Percent = percents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76417f56-1382-4e5e-a08d-e4affe1529ef",
   "metadata": {},
   "source": [
    "We set as threshold 7.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a7371c-692d-4618-a673-b76b49ce4182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>14×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">variable</th><th style = \"text-align: left;\">mean</th><th style = \"text-align: left;\">min</th><th style = \"text-align: left;\">median</th><th style = \"text-align: left;\">max</th><th style = \"text-align: left;\">nmissing</th><th style = \"text-align: left;\">eltype</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Symbol\" style = \"text-align: left;\">Symbol</th><th title = \"Union{Nothing, Float64}\" style = \"text-align: left;\">Union…</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Union{Nothing, Float64}\" style = \"text-align: left;\">Union…</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"DataType\" style = \"text-align: left;\">DataType</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">age</td><td style = \"text-align: left;\">53.1886</td><td style = \"text-align: left;\">28</td><td style = \"text-align: left;\">54.0</td><td style = \"text-align: left;\">77</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">sex</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">Female</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">Male</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">String7</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">cp</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">asymptomatic</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">typical angina</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">String15</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">trestbps</td><td style = \"text-align: left;\">132.087</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">130.0</td><td style = \"text-align: left;\">200</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">chol</td><td style = \"text-align: left;\">200.944</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">224.0</td><td style = \"text-align: left;\">603</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">fbs</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Any</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">restecg</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">st-t abnormality</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">String</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">thalch</td><td style = \"text-align: left;\">137.742</td><td style = \"text-align: left;\">60</td><td style = \"text-align: left;\">140.0</td><td style = \"text-align: left;\">202</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">exang</td><td style = \"text-align: left;\">0.392987</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">true</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Any</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">oldpeak</td><td style = \"text-align: left;\">0.883313</td><td style = \"text-align: left;\">-2.6</td><td style = \"text-align: left;\">0.5</td><td style = \"text-align: left;\">6.2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">slope</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">downsloping</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">upsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">String</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">ca</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Any</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">thal</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">fixed defect</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">reversable defect</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">String</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: left;\">num</td><td style = \"text-align: left;\">0.973398</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">1.0</td><td style = \"text-align: left;\">4</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & age & 53.1886 & 28 & 54.0 & 77 & 0 & Int64 \\\\\n",
       "\t2 & sex &  & Female &  & Male & 0 & String7 \\\\\n",
       "\t3 & cp &  & asymptomatic &  & typical angina & 0 & String15 \\\\\n",
       "\t4 & trestbps & 132.087 & 0 & 130.0 & 200 & 0 & Int64 \\\\\n",
       "\t5 & chol & 200.944 & 0 & 224.0 & 603 & 0 & Int64 \\\\\n",
       "\t6 & fbs &  &  &  &  & 0 & Any \\\\\n",
       "\t7 & restecg &  & lv hypertrophy &  & st-t abnormality & 0 & String \\\\\n",
       "\t8 & thalch & 137.742 & 60 & 140.0 & 202 & 0 & Int64 \\\\\n",
       "\t9 & exang & 0.392987 & 0 & 0.0 & 1 & 0 & Any \\\\\n",
       "\t10 & oldpeak & 0.883313 & -2.6 & 0.5 & 6.2 & 0 & Float64 \\\\\n",
       "\t11 & slope &  & downsloping &  & upsloping & 0 & String \\\\\n",
       "\t12 & ca &  &  &  &  & 0 & Any \\\\\n",
       "\t13 & thal &  & fixed defect &  & reversable defect & 0 & String \\\\\n",
       "\t14 & num & 0.973398 & 0 & 1.0 & 4 & 0 & Int64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m14×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable \u001b[0m\u001b[1m mean     \u001b[0m\u001b[1m min            \u001b[0m\u001b[1m median \u001b[0m\u001b[1m max               \u001b[0m\u001b[1m nmissing\u001b[0m ⋯\n",
       "     │\u001b[90m Symbol   \u001b[0m\u001b[90m Union…   \u001b[0m\u001b[90m Any            \u001b[0m\u001b[90m Union… \u001b[0m\u001b[90m Any               \u001b[0m\u001b[90m Int64   \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ age       53.1886   28              54.0    77                        0 ⋯\n",
       "   2 │ sex      \u001b[90m          \u001b[0m Female         \u001b[90m        \u001b[0m Male                      0\n",
       "   3 │ cp       \u001b[90m          \u001b[0m asymptomatic   \u001b[90m        \u001b[0m typical angina            0\n",
       "   4 │ trestbps  132.087   0               130.0   200                       0\n",
       "   5 │ chol      200.944   0               224.0   603                       0 ⋯\n",
       "   6 │ fbs      \u001b[90m          \u001b[0m\u001b[90m                \u001b[0m\u001b[90m        \u001b[0m\u001b[90m                   \u001b[0m        0\n",
       "   7 │ restecg  \u001b[90m          \u001b[0m lv hypertrophy \u001b[90m        \u001b[0m st-t abnormality          0\n",
       "   8 │ thalch    137.742   60              140.0   202                       0\n",
       "   9 │ exang     0.392987  false           0.0     true                      0 ⋯\n",
       "  10 │ oldpeak   0.883313  -2.6            0.5     6.2                       0\n",
       "  11 │ slope    \u001b[90m          \u001b[0m downsloping    \u001b[90m        \u001b[0m upsloping                 0\n",
       "  12 │ ca       \u001b[90m          \u001b[0m\u001b[90m                \u001b[0m\u001b[90m        \u001b[0m\u001b[90m                   \u001b[0m        0\n",
       "  13 │ thal     \u001b[90m          \u001b[0m fixed defect   \u001b[90m        \u001b[0m reversable defect         0 ⋯\n",
       "  14 │ num       0.973398  0               1.0     4                         0\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFramesMeta\n",
    "cols_to_clean = @rsubset(aux, 0 < :Percent < 7.5)\n",
    "cols_to_clean = Symbol.(cols_to_clean.Column_tag) #dropmissing works better with Symbol\n",
    "data = dropmissing(data, cols_to_clean)\n",
    "describe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc575ae1-2e92-459f-9ceb-8481a94b9b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×14 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">age</th><th style = \"text-align: left;\">trestbps</th><th style = \"text-align: left;\">chol</th><th style = \"text-align: left;\">thalch</th><th style = \"text-align: left;\">oldpeak</th><th style = \"text-align: left;\">sex</th><th style = \"text-align: left;\">cp</th><th style = \"text-align: left;\">fbs</th><th style = \"text-align: left;\">restecg</th><th style = \"text-align: left;\">exang</th><th style = \"text-align: left;\">slope</th><th style = \"text-align: left;\">ca</th><th style = \"text-align: left;\">thal</th><th style = \"text-align: left;\">num</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String7\" style = \"text-align: left;\">String7</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">63</td><td style = \"text-align: right;\">145</td><td style = \"text-align: right;\">233</td><td style = \"text-align: right;\">150</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">typical angina</td><td style = \"text-align: left;\">true</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">fixed defect</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">67</td><td style = \"text-align: right;\">160</td><td style = \"text-align: right;\">286</td><td style = \"text-align: right;\">108</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">true</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: left;\">3</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">67</td><td style = \"text-align: right;\">120</td><td style = \"text-align: right;\">229</td><td style = \"text-align: right;\">129</td><td style = \"text-align: right;\">2.6</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">true</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: left;\">2</td><td style = \"text-align: left;\">reversable defect</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">37</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">250</td><td style = \"text-align: right;\">187</td><td style = \"text-align: right;\">3.5</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">non-anginal</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">204</td><td style = \"text-align: right;\">172</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: left;\">Female</td><td style = \"text-align: left;\">atypical angina</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">upsloping</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& age & trestbps & chol & thalch & oldpeak & sex & cp & fbs & restecg & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Float64 & String7 & String15 & Any & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & 63 & 145 & 233 & 150 & 2.3 & Male & typical angina & 1 & lv hypertrophy & $\\dots$ \\\\\n",
       "\t2 & 67 & 160 & 286 & 108 & 1.5 & Male & asymptomatic & 0 & lv hypertrophy & $\\dots$ \\\\\n",
       "\t3 & 67 & 120 & 229 & 129 & 2.6 & Male & asymptomatic & 0 & lv hypertrophy & $\\dots$ \\\\\n",
       "\t4 & 37 & 130 & 250 & 187 & 3.5 & Male & non-anginal & 0 & normal & $\\dots$ \\\\\n",
       "\t5 & 41 & 130 & 204 & 172 & 1.4 & Female & atypical angina & 0 & lv hypertrophy & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×14 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m age   \u001b[0m\u001b[1m trestbps \u001b[0m\u001b[1m chol  \u001b[0m\u001b[1m thalch \u001b[0m\u001b[1m oldpeak \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m cp              \u001b[0m\u001b[1m fbs \u001b[0m ⋯\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String15        \u001b[0m\u001b[90m Any \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │    63       145    233     150      2.3  Male     typical angina   true ⋯\n",
       "   2 │    67       160    286     108      1.5  Male     asymptomatic     fals\n",
       "   3 │    67       120    229     129      2.6  Male     asymptomatic     fals\n",
       "   4 │    37       130    250     187      3.5  Male     non-anginal      fals\n",
       "   5 │    41       130    204     172      1.4  Female   atypical angina  fals ⋯\n",
       "\u001b[36m                                                               7 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_col =  [:age, :trestbps, :chol, :thalch, :oldpeak]\n",
    "cat_col = [:sex, :cp, :fbs, :restecg, :exang, :slope, :ca, :thal]\n",
    "target_col = :num\n",
    "data = select(data, num_col, cat_col, target_col);\n",
    "show = data[1:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0fea1b8-3b6d-40c6-820b-1038ed91249c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Init aproach 1 (MinMax)...\n",
      "\n",
      "--- init Preprocess ---\n",
      "   Normalization: minmax\n",
      "    HoldOut split: 579 train, 124 val, 124 test\n",
      "    Normalizing numerical features...\n",
      "    ...Normalization completed.\n",
      "    Encoding categorical features (OHE)...\n",
      "    ...OHE completed.\n",
      "    Concatenate numerical and categorical matrices...\n",
      "    Classes stored for the target: [0, 1, 2, 3, 4]\n",
      "--- PREPROCESS END SUCCESFULLY ---\n",
      "\n",
      "--- Approach 1 ---\n",
      "To acces data:\n",
      "approach_1.x_train\n",
      "approach_1.y_train_cat (for SVM/DT/kNN)\n",
      "approach_1.y_train_ohe (for ANN)\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# (Aproach 1: MinMax)\n",
    "# -----------------------------------------------------------------\n",
    "# Use the predifined variables 'data', 'num_col', 'cat_col' and 'target_col' \n",
    "\n",
    "println(\"\\n Init aproach 1 (MinMax)...\")\n",
    "Random.seed!(1234);#fix the seed as holdout induces randomness (needed for reproducibility)\n",
    "approach_1 = prepare_data(\n",
    "    data,          # Clean DataFrame without Nulls\n",
    "    num_col,       # numerical features\n",
    "    cat_col,       # caetgorical features\n",
    "    target_col,    # target feature\n",
    "    norm_method=:minmax #norm metghod, either :minmax or :zscore\n",
    ")\n",
    "\n",
    "println(\"\\n--- Approach 1 ---\")\n",
    "println(\"To acces data:\")\n",
    "println(\"approach_1.x_train\")\n",
    "println(\"approach_1.y_train_cat (for SVM/DT/kNN)\")\n",
    "println(\"approach_1.y_train_ohe (for ANN)\")\n",
    "println(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "272d9e8e-ee62-480c-897e-5b1b5a2f79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = approach_1.x_train\n",
    "y_train = approach_1.y_train_cat\n",
    "#y_train_ann = approach_1.y_train_ohe\n",
    "\n",
    "x_test = approach_1.x_test\n",
    "y_test = approach_1.y_test_cat\n",
    "#y_test_ann = aproach_1.y_test_ohe\n",
    "\n",
    "x_val = approach_1.x_val\n",
    "y_val = approach_1.y_val_cat;\n",
    "#y_val_ann = approach_1.y_val_ohe;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e57e2d68-864b-4551-ad42-f525f1a7a00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 78.23 %\n",
      "LR: 57.26 %\n",
      "DT: 59.68 %\n",
      " 17.180431 seconds (59.33 M allocations: 2.902 GiB, 5.71% gc time, 99.67% compilation time)\n",
      "\n",
      " ... Aproach 1 example of use END\n"
     ]
    }
   ],
   "source": [
    "# Example of use for models that not need the val set\n",
    "\n",
    "# prepare the complete training set\n",
    "# (Train + Val)\n",
    "x_train_val_combined = vcat(x_train, x_val)\n",
    "y_train_val_combined = vcat(y_train, y_val)\n",
    "\n",
    "# 'x_test_final' and 'y_test_final' keep the same, because if we want to compare with the ANN model (uses val set) the test set must be the same\n",
    "\n",
    "models_final = Dict(\n",
    "    \"SVM\" => SVC(cost=10.0), \n",
    "    \"LR\"  => LogisticClassifier(),\n",
    "    \"DT\"  => DecisionTreeClassifier(max_depth=4), \n",
    ")\n",
    "\n",
    "\n",
    "@time begin\n",
    "    for (name, model) in models_final\n",
    "        # Train\n",
    "        mach = machine(model, MLJ.table(x_train_val_combined), y_train_val_combined)\n",
    "        MLJ.fit!(mach, verbosity=0)\n",
    "        \n",
    "        # Predict\n",
    "        ŷ = MLJ.predict(mach, MLJ.table(x_test)) # Usamos x_test_final original\n",
    "        \n",
    "        if name != \"SVM\"\n",
    "            ŷ = mode.(ŷ)\n",
    "        end\n",
    "\n",
    "        # Measure Accuracy\n",
    "        acc = MLJ.accuracy(ŷ, y_test) # Usamos y_test_final original\n",
    "        println(\"$name: $(round(acc*100, digits=2)) %\")\n",
    "    end\n",
    "end\n",
    "println(\"\\n ... Aproach 1 example of use END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65666fa4-a2f8-4066-bac0-51336203aaf8",
   "metadata": {},
   "source": [
    "# 2rd approach\n",
    "\n",
    "Manage the Null as 1st aproach. Then use pca and z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c86e566-4e64-46b4-9a79-3aeef7dd1356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "¡Data loaded correctly!\n",
      "------------------------\n",
      "Size:\n",
      "(920, 14)\n",
      "------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×14 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">age</th><th style = \"text-align: left;\">sex</th><th style = \"text-align: left;\">cp</th><th style = \"text-align: left;\">trestbps</th><th style = \"text-align: left;\">chol</th><th style = \"text-align: left;\">fbs</th><th style = \"text-align: left;\">restecg</th><th style = \"text-align: left;\">thalch</th><th style = \"text-align: left;\">exang</th><th style = \"text-align: left;\">oldpeak</th><th style = \"text-align: left;\">slope</th><th style = \"text-align: left;\">ca</th><th style = \"text-align: left;\">thal</th><th style = \"text-align: left;\">num</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String7\" style = \"text-align: left;\">String7</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Bool}\" style = \"text-align: left;\">Bool?</th><th title = \"Union{Missing, String31}\" style = \"text-align: left;\">String31?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Bool}\" style = \"text-align: left;\">Bool?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, String15}\" style = \"text-align: left;\">String15?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, String31}\" style = \"text-align: left;\">String31?</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">63</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">typical angina</td><td style = \"text-align: right;\">145</td><td style = \"text-align: right;\">233</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">150</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">fixed defect</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">67</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: right;\">160</td><td style = \"text-align: right;\">286</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">108</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: right;\">3</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">67</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: right;\">120</td><td style = \"text-align: right;\">229</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">129</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">2.6</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">reversable defect</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">37</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">non-anginal</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">250</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">187</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">3.5</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">41</td><td style = \"text-align: left;\">Female</td><td style = \"text-align: left;\">atypical angina</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">204</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">172</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: left;\">upsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& age & sex & cp & trestbps & chol & fbs & restecg & thalch & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String7 & String15 & Int64? & Int64? & Bool? & String31? & Int64? & \\\\\n",
       "\t\\hline\n",
       "\t1 & 63 & Male & typical angina & 145 & 233 & 1 & lv hypertrophy & 150 & $\\dots$ \\\\\n",
       "\t2 & 67 & Male & asymptomatic & 160 & 286 & 0 & lv hypertrophy & 108 & $\\dots$ \\\\\n",
       "\t3 & 67 & Male & asymptomatic & 120 & 229 & 0 & lv hypertrophy & 129 & $\\dots$ \\\\\n",
       "\t4 & 37 & Male & non-anginal & 130 & 250 & 0 & normal & 187 & $\\dots$ \\\\\n",
       "\t5 & 41 & Female & atypical angina & 130 & 204 & 0 & lv hypertrophy & 172 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×14 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m age   \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m cp              \u001b[0m\u001b[1m trestbps \u001b[0m\u001b[1m chol   \u001b[0m\u001b[1m fbs   \u001b[0m\u001b[1m restecg      \u001b[0m ⋯\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String15        \u001b[0m\u001b[90m Int64?   \u001b[0m\u001b[90m Int64? \u001b[0m\u001b[90m Bool? \u001b[0m\u001b[90m String31?    \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │    63  Male     typical angina        145     233   true  lv hypertroph ⋯\n",
       "   2 │    67  Male     asymptomatic          160     286  false  lv hypertroph\n",
       "   3 │    67  Male     asymptomatic          120     229  false  lv hypertroph\n",
       "   4 │    37  Male     non-anginal           130     250  false  normal\n",
       "   5 │    41  Female   atypical angina       130     204  false  lv hypertroph ⋯\n",
       "\u001b[36m                                                               8 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DataFrame()\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "try\n",
    "    data = CSV.read(data_path, DataFrame)\n",
    "    println(\"------------------------\")\n",
    "    println(\"¡Data loaded correctly!\")\n",
    "    println(\"------------------------\")\n",
    "catch e\n",
    "    println(\"Error: $e\")\n",
    "    println(\" Verify '$data_path'.\")\n",
    "end\n",
    "data = select(data, Not([:id, :dataset]))#id not relevant and dataset indicates the hospital where the data came.\n",
    "println(\"Size:\")\n",
    "println(size(data))\n",
    "println(\"------------------------\")\n",
    "first(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deb38901-df5c-4b66-8f8a-c9e057ae0f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values replaced with: 'missing' in col: fbs\n",
      "Null values replaced with: 'missing' in col: restecg\n",
      "Null values replaced with: 'missing' in col: exang\n",
      "Null values replaced with: 'missing' in col: slope\n",
      "Null values replaced with: 'missing' in col: thal\n",
      "Null values replaced with: 'missing' in col: ca\n",
      "Data size: (827, 14)"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×14 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">age</th><th style = \"text-align: left;\">trestbps</th><th style = \"text-align: left;\">chol</th><th style = \"text-align: left;\">thalch</th><th style = \"text-align: left;\">oldpeak</th><th style = \"text-align: left;\">sex</th><th style = \"text-align: left;\">cp</th><th style = \"text-align: left;\">fbs</th><th style = \"text-align: left;\">restecg</th><th style = \"text-align: left;\">exang</th><th style = \"text-align: left;\">slope</th><th style = \"text-align: left;\">ca</th><th style = \"text-align: left;\">thal</th><th style = \"text-align: left;\">num</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String7\" style = \"text-align: left;\">String7</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">63</td><td style = \"text-align: right;\">145</td><td style = \"text-align: right;\">233</td><td style = \"text-align: right;\">150</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">typical angina</td><td style = \"text-align: left;\">true</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">fixed defect</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">67</td><td style = \"text-align: right;\">160</td><td style = \"text-align: right;\">286</td><td style = \"text-align: right;\">108</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">true</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: left;\">3</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">67</td><td style = \"text-align: right;\">120</td><td style = \"text-align: right;\">229</td><td style = \"text-align: right;\">129</td><td style = \"text-align: right;\">2.6</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">true</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: left;\">2</td><td style = \"text-align: left;\">reversable defect</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">37</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">250</td><td style = \"text-align: right;\">187</td><td style = \"text-align: right;\">3.5</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">non-anginal</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">204</td><td style = \"text-align: right;\">172</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: left;\">Female</td><td style = \"text-align: left;\">atypical angina</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">upsloping</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& age & trestbps & chol & thalch & oldpeak & sex & cp & fbs & restecg & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Float64 & String7 & String15 & Any & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & 63 & 145 & 233 & 150 & 2.3 & Male & typical angina & 1 & lv hypertrophy & $\\dots$ \\\\\n",
       "\t2 & 67 & 160 & 286 & 108 & 1.5 & Male & asymptomatic & 0 & lv hypertrophy & $\\dots$ \\\\\n",
       "\t3 & 67 & 120 & 229 & 129 & 2.6 & Male & asymptomatic & 0 & lv hypertrophy & $\\dots$ \\\\\n",
       "\t4 & 37 & 130 & 250 & 187 & 3.5 & Male & non-anginal & 0 & normal & $\\dots$ \\\\\n",
       "\t5 & 41 & 130 & 204 & 172 & 1.4 & Female & atypical angina & 0 & lv hypertrophy & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×14 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m age   \u001b[0m\u001b[1m trestbps \u001b[0m\u001b[1m chol  \u001b[0m\u001b[1m thalch \u001b[0m\u001b[1m oldpeak \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m cp              \u001b[0m\u001b[1m fbs \u001b[0m ⋯\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String15        \u001b[0m\u001b[90m Any \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │    63       145    233     150      2.3  Male     typical angina   true ⋯\n",
       "   2 │    67       160    286     108      1.5  Male     asymptomatic     fals\n",
       "   3 │    67       120    229     129      2.6  Male     asymptomatic     fals\n",
       "   4 │    37       130    250     187      3.5  Male     non-anginal      fals\n",
       "   5 │    41       130    204     172      1.4  Female   atypical angina  fals ⋯\n",
       "\u001b[36m                                                               7 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manage nulls as in Approach 1\n",
    "rows = size(data, 1)\n",
    "col_tag = names(data)\n",
    "desc_df = describe(data, :nmissing)\n",
    "percents = [sum(ismissing.(data[!, col])) / rows * 100 for col in col_tag]\n",
    "aux = DataFrame(Column_tag = col_tag, Percent = percents)\n",
    "cat_col_null = [:fbs, :restecg, :exang, :slope, :thal, :ca]\n",
    "\n",
    "for col in cat_col_null \n",
    "    data[!, col] = replace(data[!, col], missing => \"missingval\")\n",
    "    println(\"Null values replaced with: 'missing' in col: $col\")\n",
    "end\n",
    "\n",
    "rows = size(data, 1)\n",
    "col_tag = names(data)\n",
    "desc_df = describe(data, :nmissing)\n",
    "percents = [sum(ismissing.(data[!, col])) / rows * 100 for col in col_tag]\n",
    "aux = DataFrame(Column_tag = col_tag, Percent = percents)\n",
    "using DataFramesMeta\n",
    "cols_to_clean = @rsubset(aux, 0 < :Percent < 7.5)\n",
    "cols_to_clean = Symbol.(cols_to_clean.Column_tag) #dropmissing works better with Symbol\n",
    "data = dropmissing(data, cols_to_clean)\n",
    "describe(data)\n",
    "num_col =  [:age, :trestbps, :chol, :thalch, :oldpeak]\n",
    "cat_col = [:sex, :cp, :fbs, :restecg, :exang, :slope, :ca, :thal]\n",
    "target_col = :num\n",
    "data = select(data, num_col, cat_col, target_col);\n",
    "print(\"Data size: \",size(data))\n",
    "show = data[1:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4717315-c5fd-4bc5-9b87-741768fc869a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJMultivariateStatsInterface ✔\n",
      "\n",
      "Init approach 3, PCA (Z-Score)...\n",
      "\n",
      "--- init Preprocess ---\n",
      "   Normalization: zscore\n",
      "    HoldOut split: 579 train, 124 val, 124 test\n",
      "    Normalizing numerical features...\n",
      "    ...Normalization completed.\n",
      "    Encoding categorical features (OHE)...\n",
      "    ...OHE completed.\n",
      "    Concatenate numerical and categorical matrices...\n",
      "    Classes stored for the target: [0, 1, 2, 3, 4]\n",
      "--- PREPROCESS END SUCCESFULLY ---\n",
      "\n",
      "---data preprocessed---\n",
      " Train set size: (703, 31)\n",
      "Train set size: after PCA: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(703, 17)\n"
     ]
    }
   ],
   "source": [
    "using MLJMultivariateStatsInterface\n",
    "PCA = @load PCA pkg=MultivariateStats\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 1. Approach 2 PCA (Z-SCORE)\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "\n",
    "println(\"\\nInit approach 3, PCA (Z-Score)...\")\n",
    "Random.seed!(1234);#fix the seed as holdout induces randomness (needed for reproducibility)\n",
    "approach_pca = prepare_data(\n",
    "    data,         \n",
    "    num_col,       \n",
    "    cat_col,       \n",
    "    target_col,    \n",
    "    norm_method=:zscore \n",
    ")\n",
    "\n",
    "println(\"\\n---data preprocessed---\")\n",
    "\n",
    "\n",
    "#Unpack variables for MLJ\n",
    "x_train = approach_pca.x_train\n",
    "x_val = approach_pca.x_val\n",
    "x_test = approach_pca.x_test\n",
    "\n",
    "y_train = approach_pca.y_train_cat \n",
    "y_val = approach_pca.y_val_cat     \n",
    "y_test = approach_pca.y_test_cat     \n",
    "\n",
    "# Combine Train + Val (to adjust PCA) as our models are not ANN, for ANN take this into account\n",
    "x_train_val_combined = vcat(x_train, x_val)\n",
    "y_train_val_combined = vcat(y_train, y_val)\n",
    "\n",
    "println(\" Train set size: \", size(x_train_val_combined))\n",
    "\n",
    "\n",
    "# Use PCA to select the components that explain 95% of the variance\n",
    "pca_model = PCA(variance_ratio=0.95)\n",
    "\n",
    "#1 Adjust the PCA only with the training data\n",
    "pca_machine = machine(pca_model, MLJ.table(x_train_val_combined))\n",
    "MLJ.fit!(pca_machine, verbosity=0)\n",
    "\n",
    "#2 transform data\n",
    "x_train_val_pca = MLJ.transform(pca_machine, MLJ.table(x_train_val_combined))\n",
    "\n",
    "x_test_pca = MLJ.transform(pca_machine, MLJ.table(x_test))\n",
    "\n",
    "#For MLJ is better to pass the data as table\n",
    "#To see data as matrix use: mat_train_pca = MLJ.matrix(x_train_val_pca)\n",
    "# Para ver los datos transformados como matriz:\n",
    "mat_train_pca = MLJ.matrix(x_train_val_pca)\n",
    "println(\"Train set size: after PCA: \", size(mat_train_pca))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbfc8bcf-6c2a-4069-b87d-4bca379e3108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 84.68 %\n",
      "LR: 55.65 %\n",
      "DT: 62.1 %\n",
      "  1.073953 seconds (1.45 M allocations: 73.605 MiB, 95.37% compilation time)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------\n",
    "# example of use with PCA and models that don't use val set\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "models_final = Dict(\n",
    "    \"SVM\" => SVC(cost=10.0), \n",
    "    \"LR\"  => LogisticClassifier(),\n",
    "    \"DT\"  => DecisionTreeClassifier(max_depth=4), \n",
    ")\n",
    "\n",
    "@time begin\n",
    "    for (name, model) in models_final\n",
    "    \n",
    "        mach = machine(model, x_train_val_pca, y_train_val_combined)\n",
    "        MLJ.fit!(mach, verbosity=0)\n",
    "        \n",
    "        \n",
    "        ŷ = MLJ.predict(mach, x_test_pca) \n",
    "        \n",
    "        if name != \"SVM\"\n",
    "            ŷ = mode.(ŷ)\n",
    "        end\n",
    "\n",
    "        acc = MLJ.accuracy(ŷ, y_test)\n",
    "        println(\"$name: $(round(acc*100, digits=2)) %\")\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5102d66e-7514-4759-8140-570e4ff61cc2",
   "metadata": {},
   "source": [
    "# 3th approach\n",
    "\n",
    "Use ICA instead of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5471b7d7-8402-4e2d-a661-6e9e578e4594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "¡Data loaded correctly!\n",
      "------------------------\n",
      "Size:\n",
      "(920, 14)\n",
      "------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×14 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">age</th><th style = \"text-align: left;\">sex</th><th style = \"text-align: left;\">cp</th><th style = \"text-align: left;\">trestbps</th><th style = \"text-align: left;\">chol</th><th style = \"text-align: left;\">fbs</th><th style = \"text-align: left;\">restecg</th><th style = \"text-align: left;\">thalch</th><th style = \"text-align: left;\">exang</th><th style = \"text-align: left;\">oldpeak</th><th style = \"text-align: left;\">slope</th><th style = \"text-align: left;\">ca</th><th style = \"text-align: left;\">thal</th><th style = \"text-align: left;\">num</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String7\" style = \"text-align: left;\">String7</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Bool}\" style = \"text-align: left;\">Bool?</th><th title = \"Union{Missing, String31}\" style = \"text-align: left;\">String31?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Bool}\" style = \"text-align: left;\">Bool?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, String15}\" style = \"text-align: left;\">String15?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, String31}\" style = \"text-align: left;\">String31?</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">63</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">typical angina</td><td style = \"text-align: right;\">145</td><td style = \"text-align: right;\">233</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">150</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">fixed defect</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">67</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: right;\">160</td><td style = \"text-align: right;\">286</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">108</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: right;\">3</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">67</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: right;\">120</td><td style = \"text-align: right;\">229</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">129</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">2.6</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">reversable defect</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">37</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">non-anginal</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">250</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">187</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">3.5</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">41</td><td style = \"text-align: left;\">Female</td><td style = \"text-align: left;\">atypical angina</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">204</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">172</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: left;\">upsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& age & sex & cp & trestbps & chol & fbs & restecg & thalch & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String7 & String15 & Int64? & Int64? & Bool? & String31? & Int64? & \\\\\n",
       "\t\\hline\n",
       "\t1 & 63 & Male & typical angina & 145 & 233 & 1 & lv hypertrophy & 150 & $\\dots$ \\\\\n",
       "\t2 & 67 & Male & asymptomatic & 160 & 286 & 0 & lv hypertrophy & 108 & $\\dots$ \\\\\n",
       "\t3 & 67 & Male & asymptomatic & 120 & 229 & 0 & lv hypertrophy & 129 & $\\dots$ \\\\\n",
       "\t4 & 37 & Male & non-anginal & 130 & 250 & 0 & normal & 187 & $\\dots$ \\\\\n",
       "\t5 & 41 & Female & atypical angina & 130 & 204 & 0 & lv hypertrophy & 172 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×14 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m age   \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m cp              \u001b[0m\u001b[1m trestbps \u001b[0m\u001b[1m chol   \u001b[0m\u001b[1m fbs   \u001b[0m\u001b[1m restecg      \u001b[0m ⋯\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String15        \u001b[0m\u001b[90m Int64?   \u001b[0m\u001b[90m Int64? \u001b[0m\u001b[90m Bool? \u001b[0m\u001b[90m String31?    \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │    63  Male     typical angina        145     233   true  lv hypertroph ⋯\n",
       "   2 │    67  Male     asymptomatic          160     286  false  lv hypertroph\n",
       "   3 │    67  Male     asymptomatic          120     229  false  lv hypertroph\n",
       "   4 │    37  Male     non-anginal           130     250  false  normal\n",
       "   5 │    41  Female   atypical angina       130     204  false  lv hypertroph ⋯\n",
       "\u001b[36m                                                               8 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DataFrame()\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "try\n",
    "    data = CSV.read(data_path, DataFrame)\n",
    "    println(\"------------------------\")\n",
    "    println(\"¡Data loaded correctly!\")\n",
    "    println(\"------------------------\")\n",
    "catch e\n",
    "    println(\"Error: $e\")\n",
    "    println(\" Verify '$data_path'.\")\n",
    "end\n",
    "data = select(data, Not([:id, :dataset]))#id not relevant and dataset indicates the hospital where the data came.\n",
    "println(\"Size:\")\n",
    "println(size(data))\n",
    "println(\"------------------------\")\n",
    "first(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5e76ea4-5e6c-4f1f-829d-13c3b4464618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values replaced with: 'missing' in col: fbs\n",
      "Null values replaced with: 'missing' in col: restecg\n",
      "Null values replaced with: 'missing' in col: exang\n",
      "Null values replaced with: 'missing' in col: slope\n",
      "Null values replaced with: 'missing' in col: thal\n",
      "Null values replaced with: 'missing' in col: ca\n",
      "Data size: (827, 14)"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×14 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">age</th><th style = \"text-align: left;\">trestbps</th><th style = \"text-align: left;\">chol</th><th style = \"text-align: left;\">thalch</th><th style = \"text-align: left;\">oldpeak</th><th style = \"text-align: left;\">sex</th><th style = \"text-align: left;\">cp</th><th style = \"text-align: left;\">fbs</th><th style = \"text-align: left;\">restecg</th><th style = \"text-align: left;\">exang</th><th style = \"text-align: left;\">slope</th><th style = \"text-align: left;\">ca</th><th style = \"text-align: left;\">thal</th><th style = \"text-align: left;\">num</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String7\" style = \"text-align: left;\">String7</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">63</td><td style = \"text-align: right;\">145</td><td style = \"text-align: right;\">233</td><td style = \"text-align: right;\">150</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">typical angina</td><td style = \"text-align: left;\">true</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">fixed defect</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">67</td><td style = \"text-align: right;\">160</td><td style = \"text-align: right;\">286</td><td style = \"text-align: right;\">108</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">true</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: left;\">3</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">67</td><td style = \"text-align: right;\">120</td><td style = \"text-align: right;\">229</td><td style = \"text-align: right;\">129</td><td style = \"text-align: right;\">2.6</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">true</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: left;\">2</td><td style = \"text-align: left;\">reversable defect</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">37</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">250</td><td style = \"text-align: right;\">187</td><td style = \"text-align: right;\">3.5</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">non-anginal</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">204</td><td style = \"text-align: right;\">172</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: left;\">Female</td><td style = \"text-align: left;\">atypical angina</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">upsloping</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& age & trestbps & chol & thalch & oldpeak & sex & cp & fbs & restecg & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Float64 & String7 & String15 & Any & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & 63 & 145 & 233 & 150 & 2.3 & Male & typical angina & 1 & lv hypertrophy & $\\dots$ \\\\\n",
       "\t2 & 67 & 160 & 286 & 108 & 1.5 & Male & asymptomatic & 0 & lv hypertrophy & $\\dots$ \\\\\n",
       "\t3 & 67 & 120 & 229 & 129 & 2.6 & Male & asymptomatic & 0 & lv hypertrophy & $\\dots$ \\\\\n",
       "\t4 & 37 & 130 & 250 & 187 & 3.5 & Male & non-anginal & 0 & normal & $\\dots$ \\\\\n",
       "\t5 & 41 & 130 & 204 & 172 & 1.4 & Female & atypical angina & 0 & lv hypertrophy & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×14 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m age   \u001b[0m\u001b[1m trestbps \u001b[0m\u001b[1m chol  \u001b[0m\u001b[1m thalch \u001b[0m\u001b[1m oldpeak \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m cp              \u001b[0m\u001b[1m fbs \u001b[0m ⋯\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String15        \u001b[0m\u001b[90m Any \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │    63       145    233     150      2.3  Male     typical angina   true ⋯\n",
       "   2 │    67       160    286     108      1.5  Male     asymptomatic     fals\n",
       "   3 │    67       120    229     129      2.6  Male     asymptomatic     fals\n",
       "   4 │    37       130    250     187      3.5  Male     non-anginal      fals\n",
       "   5 │    41       130    204     172      1.4  Female   atypical angina  fals ⋯\n",
       "\u001b[36m                                                               7 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manage nulls as in Approach 1\n",
    "rows = size(data, 1)\n",
    "col_tag = names(data)\n",
    "desc_df = describe(data, :nmissing)\n",
    "percents = [sum(ismissing.(data[!, col])) / rows * 100 for col in col_tag]\n",
    "aux = DataFrame(Column_tag = col_tag, Percent = percents)\n",
    "cat_col_null = [:fbs, :restecg, :exang, :slope, :thal, :ca]\n",
    "\n",
    "for col in cat_col_null \n",
    "    data[!, col] = replace(data[!, col], missing => \"missingval\")\n",
    "    println(\"Null values replaced with: 'missing' in col: $col\")\n",
    "end\n",
    "\n",
    "rows = size(data, 1)\n",
    "col_tag = names(data)\n",
    "desc_df = describe(data, :nmissing)\n",
    "percents = [sum(ismissing.(data[!, col])) / rows * 100 for col in col_tag]\n",
    "aux = DataFrame(Column_tag = col_tag, Percent = percents)\n",
    "using DataFramesMeta\n",
    "cols_to_clean = @rsubset(aux, 0 < :Percent < 7.5)\n",
    "cols_to_clean = Symbol.(cols_to_clean.Column_tag) #dropmissing works better with Symbol\n",
    "data = dropmissing(data, cols_to_clean)\n",
    "describe(data)\n",
    "num_col =  [:age, :trestbps, :chol, :thalch, :oldpeak]\n",
    "cat_col = [:sex, :cp, :fbs, :restecg, :exang, :slope, :ca, :thal]\n",
    "target_col = :num\n",
    "data = select(data, num_col, cat_col, target_col);\n",
    "print(\"Data size: \",size(data))\n",
    "show = data[1:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9893080-ad2b-4736-b51d-4a4ea3659386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJMultivariateStatsInterface ✔\n",
      "\n",
      "Init approach 3, ICA (Numerical features only)...\n",
      "\n",
      "--- init Preprocess ---\n",
      "   Normalization: zscore\n",
      "    HoldOut split: 579 train, 124 val, 124 test\n",
      "    Normalizing numerical features...\n",
      "    ...Normalization completed.\n",
      "    Encoding categorical features (OHE)...\n",
      "    ...OHE completed.\n",
      "    Concatenate numerical and categorical matrices...\n",
      "    Classes stored for the target: [0, 1, 2, 3, 4]\n",
      "--- PREPROCESS END SUCCESFULLY ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n"
     ]
    }
   ],
   "source": [
    "using MLJMultivariateStatsInterface\n",
    "ICA = @load ICA pkg=MultivariateStats\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 1. Approach 3 ICA ( Just in numerical features ¡, if we use it with the caegorical ones it wouldn't find a solution)\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "println(\"\\nInit approach 3, ICA (Numerical features only)...\")\n",
    "\n",
    "# 1. Preprocess as previous aproach ( Z-Score, ideal for ICA)\n",
    "approach_ica = prepare_data(\n",
    "    data,          \n",
    "    num_col,       \n",
    "    cat_col,       \n",
    "    target_col,    \n",
    "    norm_method=:zscore \n",
    ")\n",
    "\n",
    "# 2. Unpack results\n",
    "x_train = approach_ica.x_train\n",
    "x_val = approach_ica.x_val\n",
    "x_test = approach_ica.x_test\n",
    "\n",
    "y_train_ica = approach_ica.y_train_cat \n",
    "y_val_ica = approach_ica.y_val_cat     \n",
    "y_test_ica = approach_ica.y_test_cat;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89ea5736-9de8-4847-9992-5cb568e1b1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ICA with k=2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ICA(outdim = 2, …), …).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape (ICA Nums + OHE Cats): (579, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"# 3. Previous version combine Train + Val to train ICA, but i don't know if this is a good idea since, validation is used in ANN as a \"test\" set so maybe here is data leakage.\n",
    "x_train_val_combined = vcat(x_train, x_val)\n",
    "y_train_val_combined = vcat(y_train, y_val)\n",
    "\n",
    "println(\" Matriz completa inicial: \", size(x_train_val_combined))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Our function  'prepare_data'order first numerical fetures and then categorical ones.\n",
    "\n",
    "n_num = length(num_col) # Should be (age, trestbps, chol, thalch, oldpeak)\n",
    "\n",
    "#Split \n",
    "x_num_train = x_train[:, 1:n_num]      # Just numerical \n",
    "x_cat_train = x_train[:, n_num+1:end]  # Just categorical OHE\n",
    "\n",
    "x_num_val = x_val[:, 1:n_num]\n",
    "x_cat_val = x_val[:, n_num+1:end]\n",
    "x_num_test = x_test[:, 1:n_num]\n",
    "x_cat_test = x_test[:, n_num+1:end]\n",
    "\n",
    "\n",
    "# --- ICA just for numerical ---\n",
    "\n",
    "# k should be less or equal than umber of features (5)\n",
    "k_components = 2\n",
    "\n",
    "Random.seed!(1234)#ICA is a no deterministic method so we fix the seed for reproducibility, but sometimes still fail ;-|\n",
    "# Give some tolerance for the solution\n",
    "ica_model = ICA(outdim=k_components, maxiter=50000, tol=0.005) \n",
    "\n",
    "println(\" ICA with k=$k_components ...\")\n",
    "\n",
    "# Fit only the numerical data from training set\n",
    "ica_machine = machine(ica_model, MLJ.table(x_num_train))\n",
    "MLJ.fit!(ica_machine, verbosity=1) # verbosity=1 for debug\n",
    "\n",
    "# Transform and return to matrix\n",
    "x_num_train_ica = MLJ.transform(ica_machine, MLJ.table(x_num_train))\n",
    "x_num_val_ica  = MLJ.transform(ica_machine, MLJ.table(x_num_val))\n",
    "x_num_test_ica  = MLJ.transform(ica_machine, MLJ.table(x_num_test))\n",
    "\n",
    "\n",
    "mat_train_ica = MLJ.matrix(x_num_train_ica)\n",
    "mat_val_ica  = MLJ.matrix(x_num_val_ica)\n",
    "mat_test_ica  = MLJ.matrix(x_num_test_ica)\n",
    "\n",
    "#Add the categorical OHE \n",
    "x_train_ica = hcat(mat_train_ica, x_cat_train)\n",
    "x_val_ica = hcat(mat_val_ica, x_cat_val)\n",
    "x_test_ica     = hcat(mat_test_ica, x_cat_test)\n",
    "\n",
    "println(\"Final shape (ICA Nums + OHE Cats): \", size(x_train_ica))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48940816-525a-4629-95e6-e8efcf0ebb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados tras ICA:\n",
      "SVM: 32.26 %\n",
      "LR: 45.97 %\n",
      "DT: 47.58 %\n",
      "  0.470410 seconds (1.92 M allocations: 96.842 MiB, 83.95% compilation time)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# EXample of usage with models that don't use val set.\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "models_final = Dict(\n",
    "    \"SVM\" => SVC(cost=10.0), \n",
    "    \"LR\"  => LogisticClassifier(),\n",
    "    \"DT\"  => DecisionTreeClassifier(max_depth=4), \n",
    ")\n",
    "\n",
    "x_train_val = vcat(x_train_ica, x_val_ica)\n",
    "y_train_val= vcat(y_train, y_val)\n",
    "println(\"\\nResultados tras ICA:\")\n",
    "@time begin\n",
    "    for (name, model) in models_final\n",
    "        # Entrenamos con la matriz reconstruida\n",
    "        mach = machine(model, MLJ.table(x_train_val), y_train_val)\n",
    "        MLJ.fit!(mach, verbosity=0)\n",
    "        \n",
    "        # Predecimos\n",
    "        ŷ = MLJ.predict(mach, MLJ.table(x_test_ica))\n",
    "        \n",
    "        if name != \"SVM\"\n",
    "            ŷ = mode.(ŷ)\n",
    "        end\n",
    "\n",
    "        acc = MLJ.accuracy(ŷ, y_test)\n",
    "        println(\"$name: $(round(acc*100, digits=2)) %\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad2b17-9bfd-4a34-b94a-b8eb953207ea",
   "metadata": {},
   "source": [
    "# 4th Approach, Same as 1 but  with crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30d1c0ef-7361-489b-ad97-6a8445ccb3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "¡Data loaded correctly!\n",
      "------------------------\n",
      "Size:\n",
      "(920, 14)\n",
      "------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×14 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">age</th><th style = \"text-align: left;\">sex</th><th style = \"text-align: left;\">cp</th><th style = \"text-align: left;\">trestbps</th><th style = \"text-align: left;\">chol</th><th style = \"text-align: left;\">fbs</th><th style = \"text-align: left;\">restecg</th><th style = \"text-align: left;\">thalch</th><th style = \"text-align: left;\">exang</th><th style = \"text-align: left;\">oldpeak</th><th style = \"text-align: left;\">slope</th><th style = \"text-align: left;\">ca</th><th style = \"text-align: left;\">thal</th><th style = \"text-align: left;\">num</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String7\" style = \"text-align: left;\">String7</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Bool}\" style = \"text-align: left;\">Bool?</th><th title = \"Union{Missing, String31}\" style = \"text-align: left;\">String31?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, Bool}\" style = \"text-align: left;\">Bool?</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Union{Missing, String15}\" style = \"text-align: left;\">String15?</th><th title = \"Union{Missing, Int64}\" style = \"text-align: left;\">Int64?</th><th title = \"Union{Missing, String31}\" style = \"text-align: left;\">String31?</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">63</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">typical angina</td><td style = \"text-align: right;\">145</td><td style = \"text-align: right;\">233</td><td style = \"text-align: right;\">true</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">150</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">fixed defect</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">67</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: right;\">160</td><td style = \"text-align: right;\">286</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">108</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: right;\">3</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">67</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: right;\">120</td><td style = \"text-align: right;\">229</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">129</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">2.6</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">reversable defect</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">37</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">non-anginal</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">250</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">187</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">3.5</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">41</td><td style = \"text-align: left;\">Female</td><td style = \"text-align: left;\">atypical angina</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">204</td><td style = \"text-align: right;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: right;\">172</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: left;\">upsloping</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& age & sex & cp & trestbps & chol & fbs & restecg & thalch & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String7 & String15 & Int64? & Int64? & Bool? & String31? & Int64? & \\\\\n",
       "\t\\hline\n",
       "\t1 & 63 & Male & typical angina & 145 & 233 & 1 & lv hypertrophy & 150 & $\\dots$ \\\\\n",
       "\t2 & 67 & Male & asymptomatic & 160 & 286 & 0 & lv hypertrophy & 108 & $\\dots$ \\\\\n",
       "\t3 & 67 & Male & asymptomatic & 120 & 229 & 0 & lv hypertrophy & 129 & $\\dots$ \\\\\n",
       "\t4 & 37 & Male & non-anginal & 130 & 250 & 0 & normal & 187 & $\\dots$ \\\\\n",
       "\t5 & 41 & Female & atypical angina & 130 & 204 & 0 & lv hypertrophy & 172 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×14 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m age   \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m cp              \u001b[0m\u001b[1m trestbps \u001b[0m\u001b[1m chol   \u001b[0m\u001b[1m fbs   \u001b[0m\u001b[1m restecg      \u001b[0m ⋯\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String15        \u001b[0m\u001b[90m Int64?   \u001b[0m\u001b[90m Int64? \u001b[0m\u001b[90m Bool? \u001b[0m\u001b[90m String31?    \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │    63  Male     typical angina        145     233   true  lv hypertroph ⋯\n",
       "   2 │    67  Male     asymptomatic          160     286  false  lv hypertroph\n",
       "   3 │    67  Male     asymptomatic          120     229  false  lv hypertroph\n",
       "   4 │    37  Male     non-anginal           130     250  false  normal\n",
       "   5 │    41  Female   atypical angina       130     204  false  lv hypertroph ⋯\n",
       "\u001b[36m                                                               8 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DataFrame()\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "try\n",
    "    data = CSV.read(data_path, DataFrame)\n",
    "    println(\"------------------------\")\n",
    "    println(\"¡Data loaded correctly!\")\n",
    "    println(\"------------------------\")\n",
    "catch e\n",
    "    println(\"Error: $e\")\n",
    "    println(\" Verify '$data_path'.\")\n",
    "end\n",
    "data = select(data, Not([:id, :dataset]))#id not relevant and dataset indicates the hospital where the data came.\n",
    "println(\"Size:\")\n",
    "println(size(data))\n",
    "println(\"------------------------\")\n",
    "first(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "031e5e69-666b-4db5-a9f4-e9822bee497f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values replaced with: 'missing' in col: fbs\n",
      "Null values replaced with: 'missing' in col: restecg\n",
      "Null values replaced with: 'missing' in col: exang\n",
      "Null values replaced with: 'missing' in col: slope\n",
      "Null values replaced with: 'missing' in col: thal\n",
      "Null values replaced with: 'missing' in col: ca\n",
      "Data size: (827, 14)"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×14 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">age</th><th style = \"text-align: left;\">trestbps</th><th style = \"text-align: left;\">chol</th><th style = \"text-align: left;\">thalch</th><th style = \"text-align: left;\">oldpeak</th><th style = \"text-align: left;\">sex</th><th style = \"text-align: left;\">cp</th><th style = \"text-align: left;\">fbs</th><th style = \"text-align: left;\">restecg</th><th style = \"text-align: left;\">exang</th><th style = \"text-align: left;\">slope</th><th style = \"text-align: left;\">ca</th><th style = \"text-align: left;\">thal</th><th style = \"text-align: left;\">num</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String7\" style = \"text-align: left;\">String7</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">63</td><td style = \"text-align: right;\">145</td><td style = \"text-align: right;\">233</td><td style = \"text-align: right;\">150</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">typical angina</td><td style = \"text-align: left;\">true</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">fixed defect</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">67</td><td style = \"text-align: right;\">160</td><td style = \"text-align: right;\">286</td><td style = \"text-align: right;\">108</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">true</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: left;\">3</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">67</td><td style = \"text-align: right;\">120</td><td style = \"text-align: right;\">229</td><td style = \"text-align: right;\">129</td><td style = \"text-align: right;\">2.6</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">asymptomatic</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">true</td><td style = \"text-align: left;\">flat</td><td style = \"text-align: left;\">2</td><td style = \"text-align: left;\">reversable defect</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">37</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">250</td><td style = \"text-align: right;\">187</td><td style = \"text-align: right;\">3.5</td><td style = \"text-align: left;\">Male</td><td style = \"text-align: left;\">non-anginal</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">downsloping</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">204</td><td style = \"text-align: right;\">172</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: left;\">Female</td><td style = \"text-align: left;\">atypical angina</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">lv hypertrophy</td><td style = \"text-align: left;\">false</td><td style = \"text-align: left;\">upsloping</td><td style = \"text-align: left;\">0</td><td style = \"text-align: left;\">normal</td><td style = \"text-align: right;\">0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& age & trestbps & chol & thalch & oldpeak & sex & cp & fbs & restecg & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Float64 & String7 & String15 & Any & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & 63 & 145 & 233 & 150 & 2.3 & Male & typical angina & 1 & lv hypertrophy & $\\dots$ \\\\\n",
       "\t2 & 67 & 160 & 286 & 108 & 1.5 & Male & asymptomatic & 0 & lv hypertrophy & $\\dots$ \\\\\n",
       "\t3 & 67 & 120 & 229 & 129 & 2.6 & Male & asymptomatic & 0 & lv hypertrophy & $\\dots$ \\\\\n",
       "\t4 & 37 & 130 & 250 & 187 & 3.5 & Male & non-anginal & 0 & normal & $\\dots$ \\\\\n",
       "\t5 & 41 & 130 & 204 & 172 & 1.4 & Female & atypical angina & 0 & lv hypertrophy & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×14 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m age   \u001b[0m\u001b[1m trestbps \u001b[0m\u001b[1m chol  \u001b[0m\u001b[1m thalch \u001b[0m\u001b[1m oldpeak \u001b[0m\u001b[1m sex     \u001b[0m\u001b[1m cp              \u001b[0m\u001b[1m fbs \u001b[0m ⋯\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m String15        \u001b[0m\u001b[90m Any \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │    63       145    233     150      2.3  Male     typical angina   true ⋯\n",
       "   2 │    67       160    286     108      1.5  Male     asymptomatic     fals\n",
       "   3 │    67       120    229     129      2.6  Male     asymptomatic     fals\n",
       "   4 │    37       130    250     187      3.5  Male     non-anginal      fals\n",
       "   5 │    41       130    204     172      1.4  Female   atypical angina  fals ⋯\n",
       "\u001b[36m                                                               7 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manage nulls as in Approach 1\n",
    "rows = size(data, 1)\n",
    "col_tag = names(data)\n",
    "desc_df = describe(data, :nmissing)\n",
    "percents = [sum(ismissing.(data[!, col])) / rows * 100 for col in col_tag]\n",
    "aux = DataFrame(Column_tag = col_tag, Percent = percents)\n",
    "cat_col_null = [:fbs, :restecg, :exang, :slope, :thal, :ca]\n",
    "\n",
    "for col in cat_col_null \n",
    "    data[!, col] = replace(data[!, col], missing => \"missingval\")\n",
    "    println(\"Null values replaced with: 'missing' in col: $col\")\n",
    "end\n",
    "\n",
    "rows = size(data, 1)\n",
    "col_tag = names(data)\n",
    "desc_df = describe(data, :nmissing)\n",
    "percents = [sum(ismissing.(data[!, col])) / rows * 100 for col in col_tag]\n",
    "aux = DataFrame(Column_tag = col_tag, Percent = percents)\n",
    "using DataFramesMeta\n",
    "cols_to_clean = @rsubset(aux, 0 < :Percent < 7.5)\n",
    "cols_to_clean = Symbol.(cols_to_clean.Column_tag) #dropmissing works better with Symbol\n",
    "data = dropmissing(data, cols_to_clean)\n",
    "describe(data)\n",
    "num_col =  [:age, :trestbps, :chol, :thalch, :oldpeak]\n",
    "cat_col = [:sex, :cp, :fbs, :restecg, :exang, :slope, :ca, :thal]\n",
    "target_col = :num\n",
    "data = select(data, num_col, cat_col, target_col);\n",
    "print(\"Data size: \",size(data))\n",
    "show = data[1:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6219617-9fd5-46a2-97a5-86eb487fc90d",
   "metadata": {},
   "source": [
    "# Explicacion de Gemini que me gusto para el flujo de trabajo en crossvalidation\n",
    "\n",
    "Aquí te confirmo y explico detalladamente por qué tu planteamiento es correcto y cómo encaja con el código que has subido.\n",
    "\n",
    "1. ¿Por qué no hay Data Leakage en SVM, KNN o DT?\n",
    "Efectivamente, es tal como dices: el modelo se \"resetea\".\n",
    "\n",
    "En tu función modelCrossValidation (archivo unit6-modelcrossvalidation.jl), dentro del bucle for k in 1:numFolds, ocurre lo siguiente:\n",
    "\n",
    "\n",
    "Instanciación nueva: Se crea una nueva instancia del modelo (ej. model = SVMClassifier(...)) en cada vuelta del bucle.\n",
    "\n",
    "\n",
    "Entrenamiento desde cero: Al llamar a MLJ.fit!(mach), el modelo aprende únicamente usando los datos Xtrain de ese fold específico. No guarda \"memoria\" de los folds anteriores.\n",
    "\n",
    "\n",
    "Evaluación: Se prueba con Xtest (que el modelo nunca ha visto en esta vuelta).\n",
    "\n",
    "Por eso es seguro: en cada iteración, el modelo es un \"bebé\" que nace, aprende con unos datos y se examina con otros distintos.\n",
    "\n",
    "2. El caso especial de las ANNs: El riesgo del \"Early Stopping\"\n",
    "Las Redes Neuronales son más delicadas porque tienen un mecanismo interno que los otros modelos no usan por defecto: el Early Stopping (parar cuando deja de mejorar).\n",
    "\n",
    "El peligro: Si usas el set de Test del fold para decidir cuándo parar el entrenamiento, estás cometiendo Data Leakage. El modelo estaría \"viendo\" el examen para saber cuándo dejar de estudiar.\n",
    "\n",
    "La solución (que ya tienes en tu código): En tu archivo unit5-crossvalidation.jl, la función ANNCrossValidation implementa un Split Anidado.\n",
    "\n",
    "Mira las líneas: Si validationRatio > 0, tu código toma el trainingInputs del fold y lo vuelve a dividir para sacar un pequeño set de validación (valInputs).\n",
    "\n",
    "Luego, entrena la ANN usando ese subconjunto para el Early Stopping.\n",
    "\n",
    "Finalmente, evalúa el modelo con el testInputs del fold (que se mantuvo totalmente aislado).\n",
    "\n",
    "Conclusión: Mientras uses validationRatio > 0 en tus hiperparámetros, tu código de ANN ya está protegido contra el leakage dentro del Cross-Validation.\n",
    "\n",
    "3. Tu estrategia del 15% de Test Final (\"Hold-Out\")\n",
    "Tu idea de dejar un 15% \"intocable\" al principio es la estrategia profesional estándar.\n",
    "\n",
    "El flujo de trabajo correcto sería:\n",
    "\n",
    "- Corte Inicial: Separas el 15% de tus datos originales y los guardas bajo llave (archivo final_test_set_raw.csv que creamos antes). NUNCA usas esto durante el diseño o ajuste de modelos.\n",
    "\n",
    "- Cross-Validation (con el 85% restante):\n",
    "\n",
    "- Usas este 85% para correr tu Cross-Validation (con 5 o 10 folds).\n",
    "\n",
    "- Aquí pruebas arquitecturas, hiperparámetros, PCA vs ICA, etc.\n",
    "\n",
    "- Calculas el \"Accuracy Promedio\" para decidir cuál es el mejor modelo.\n",
    "\n",
    "- Entrenamiento Final:\n",
    "\n",
    "    Tomas el mejor modelo y la mejor configuración que encontraste en el paso 2.\n",
    "\n",
    "    Lo re-entrenas usando todo el 85% de los datos (sin dividir en folds).\n",
    "\n",
    "- Evaluación Definitiva:\n",
    "\n",
    "    Ahora sí, sacas tu 15% de Test Final.\n",
    "\n",
    "    Lo procesas (usando los parámetros aprendidos en el paso 3) y evalúas.\n",
    "\n",
    "    Ese número es el que reportas como la \"efectividad real\" del modelo en el mundo real.\n",
    "\n",
    "Resumen: Sí, en ANN debes reiniciar los pesos en cada fold (tu código trainClassANN ya lo hace porque crea una buildClassANN nueva cada vez ). Y sí, mantener ese 15% fuera desde el principio es la mejor práctica para evitar engañarte a ti mismo con los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5db83b80-ea36-4f3e-8f03-65deac70be4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelCV_Approach1 (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics, MLJ, DataFrames, Random\n",
    "\n",
    "# Función auxiliar para preprocesar un fold específico sin Data Leakage\n",
    "function preprocess_fold_v1(x_train_num, x_train_cat, x_test_num, x_test_cat)\n",
    "    \n",
    "    # --- 1. Numéricas: MinMax ---\n",
    "    # Calculamos parámetros SOLO con Train\n",
    "    norm_params = calculateMinMaxNormalizationParameters(Matrix(x_train_num))\n",
    "    \n",
    "    # Aplicamos a Train y Test\n",
    "    # (Si hay valores en test fuera del rango min-max de train, se extrapolarán, lo cual es correcto)\n",
    "    proc_train_num = normalizeMinMax(Matrix(x_train_num), norm_params)\n",
    "    proc_test_num  = normalizeMinMax(Matrix(x_test_num), norm_params)\n",
    "    \n",
    "    # --- 2. Categóricas: One-Hot Encoding ---\n",
    "    # Necesitamos acumular las columnas procesadas\n",
    "    list_train = []\n",
    "    list_test  = []\n",
    "    \n",
    "    # Iteramos por cada columna categórica (asumimos DataFrames)\n",
    "    for col_name in names(x_train_cat)\n",
    "        col_tr = x_train_cat[!, col_name]\n",
    "        col_te = x_test_cat[!, col_name]\n",
    "        \n",
    "        # Aprendemos las clases presentes en este fold\n",
    "        classes = unique(col_tr)\n",
    "        \n",
    "        # \"Parche\" de seguridad: Si en Test aparece una clase que no estaba en Train,\n",
    "        # la añadimos a la lista de clases para que oneHotEncoding no lance error.\n",
    "        # (En un sistema real estricto, esto debería ir a una clase \"Other\", \n",
    "        # pero para este dataset académico es aceptable).\n",
    "        for v in unique(col_te)\n",
    "            if !(v in classes) push!(classes, v) end\n",
    "        end\n",
    "        \n",
    "        # Codificamos\n",
    "        push!(list_train, oneHotEncoding(col_tr, classes))\n",
    "        push!(list_test, oneHotEncoding(col_te, classes))\n",
    "    end\n",
    "    \n",
    "    # Unimos horizontalmente todas las matrices OHE\n",
    "    proc_train_cat = hcat(list_train...)\n",
    "    proc_test_cat  = hcat(list_test...)\n",
    "    \n",
    "    # --- 3. Concatenación Final ---\n",
    "    X_train_final = hcat(proc_train_num, proc_train_cat)\n",
    "    X_test_final  = hcat(proc_test_num, proc_test_cat)\n",
    "    \n",
    "    return X_train_final, X_test_final\n",
    "end\n",
    "\n",
    "function modelCV_Approach1(\n",
    "        modelType::Symbol, \n",
    "        hyperparams::Dict,\n",
    "        data_num::DataFrame,    # Dataframe solo numéricas\n",
    "        data_cat::DataFrame,    # Dataframe solo categóricas\n",
    "        targets::AbstractArray, # Vector de targets\n",
    "        folds_indices::Array{Int64,1}) # Indices del CV\n",
    "    \n",
    "    num_folds = maximum(folds_indices)\n",
    "    classes = unique(targets) # Clases del target (0, 1, 2...)\n",
    "    \n",
    "    accuracies = zeros(num_folds)\n",
    "    \n",
    "    # Bucle de Folds\n",
    "    for k in 1:num_folds\n",
    "        # 1. Separar Índices\n",
    "        idx_train = folds_indices .!= k\n",
    "        idx_test  = folds_indices .== k\n",
    "        \n",
    "        # 2. Separar Datos CRUDOS (Raw)\n",
    "        # Aquí es donde evitamos el leakage: pasamos datos crudos al procesador\n",
    "        x_tr_num = data_num[idx_train, :]\n",
    "        x_tr_cat = data_cat[idx_train, :]\n",
    "        \n",
    "        x_te_num = data_num[idx_test, :]\n",
    "        x_te_cat = data_cat[idx_test, :]\n",
    "        \n",
    "        y_train = targets[idx_train]\n",
    "        y_test  = targets[idx_test]\n",
    "        \n",
    "        # 3. Preprocesamiento \"On-the-fly\"\n",
    "        X_train_proc, X_test_proc = preprocess_fold_v1(x_tr_num, x_tr_cat, x_te_num, x_te_cat)\n",
    "        \n",
    "        # 4. Configurar Modelo (Igual que en tu unit6)\n",
    "        model = nothing\n",
    "        if modelType == :SVC\n",
    "            C = get(hyperparams, :C, 1.0)\n",
    "            model = SVMClassifier(cost=Float64(C)) # Añade kernel/gamma si quieres\n",
    "        elseif modelType == :DT\n",
    "            depth = get(hyperparams, :max_depth, 5)\n",
    "            model = DTClassifier(max_depth=Int(depth), rng=Random.MersenneTwister(1234))\n",
    "        elseif modelType == :KNN\n",
    "            K = get(hyperparams, :K, 5)\n",
    "            model = kNNClassifier(K=Int(K))\n",
    "        end\n",
    "        \n",
    "        # 5. Entrenar y Predecir\n",
    "        # MLJ necesita targets categóricos\n",
    "        mach = machine(model, MLJ.table(X_train_proc), MLJ.categorical(y_train))\n",
    "        MLJ.fit!(mach, verbosity=0)\n",
    "        \n",
    "        y_pred = MLJ.predict(mach, MLJ.table(X_test_proc))\n",
    "        \n",
    "        # Manejo de predicciones (SVC devuelve clase, otros probab.)\n",
    "        final_pred = (modelType == :SVC) ? y_pred : mode.(y_pred)\n",
    "        \n",
    "        # 6. Métricas (Usamos tu función accuracy de unit4)\n",
    "        # Convertimos a string para asegurar compatibilidad si usas confusionMatrix complejo\n",
    "        # O usamos accuracy directo de MLJ para simplificar:\n",
    "        acc = MLJ.accuracy(final_pred, MLJ.categorical(y_test))\n",
    "        accuracies[k] = acc\n",
    "    end\n",
    "    \n",
    "    return mean(accuracies), std(accuracies)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bb8541c-f761-47ee-b8ee-fd05762b60f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Cross-Validation Seguro (Approach 1) ---\n",
      "Evaluando SVC ...\n",
      "   -> Acc: 57.34% ± 3.89\n",
      "Evaluando DT ...\n",
      "   -> Acc: 55.28% ± 3.41\n",
      "Evaluando KNN ...\n",
      "   -> Acc: 55.84% ± 4.18\n",
      "\n",
      "--- Resumen de Resultados (Approach 1) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>3×3 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Model</th><th style = \"text-align: left;\">Mean_Acc</th><th style = \"text-align: left;\">Std_Acc</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">57.3401</td><td style = \"text-align: left;\">3.88967</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">DT</td><td style = \"text-align: left;\">55.2766</td><td style = \"text-align: left;\">3.40606</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">KNN</td><td style = \"text-align: left;\">55.8368</td><td style = \"text-align: left;\">4.18349</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& Model & Mean\\_Acc & Std\\_Acc\\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & Any\\\\\n",
       "\t\\hline\n",
       "\t1 & SVC & 57.3401 & 3.88967 \\\\\n",
       "\t2 & DT & 55.2766 & 3.40606 \\\\\n",
       "\t3 & KNN & 55.8368 & 4.18349 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Model \u001b[0m\u001b[1m Mean_Acc \u001b[0m\u001b[1m Std_Acc \u001b[0m\n",
       "     │\u001b[90m Any   \u001b[0m\u001b[90m Any      \u001b[0m\u001b[90m Any     \u001b[0m\n",
       "─────┼──────────────────────────\n",
       "   1 │ SVC    57.3401   3.88967\n",
       "   2 │ DT     55.2766   3.40606\n",
       "   3 │ KNN    55.8368   4.18349"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "println(\"--- Ejecutando Cross-Validation Seguro (Approach 1) ---\")\n",
    "\n",
    "# 1. Preparar los datos CRUDOS (Separados en Num y Cat)\n",
    "# data ya tiene los nulos gestionados (\"missingval\") y filas numéricas borradas\n",
    "df_num = select(data, num_col)\n",
    "df_cat = select(data, cat_col)\n",
    "targets = data[!, target_col]\n",
    "\n",
    "# 2. Generar índices de CV (Stratified es mejor si tienes unit5 cargado)\n",
    "# Si targets es numérico (0-4), unit5.crossvalidation funciona bien.\n",
    "k_folds = 10\n",
    "Random.seed!(1234)\n",
    "# Usamos tu función de unit5 para generar índices estratificados\n",
    "cv_indices = crossvalidation(targets, k_folds) \n",
    "\n",
    "# 3. Definir Modelos a Probar\n",
    "experiments = [\n",
    "    (:SVC, Dict(:C => 1.0)),\n",
    "    (:DT,  Dict(:max_depth => 4)),\n",
    "    (:KNN, Dict(:K => 5))\n",
    "]\n",
    "\n",
    "# 4. Ejecutar Experimentos\n",
    "results_df = DataFrame(Model=[], Mean_Acc=[], Std_Acc=[])\n",
    "\n",
    "for (m_type, params) in experiments\n",
    "    println(\"Evaluando $m_type ...\")\n",
    "    \n",
    "    mu, sigma = modelCV_Approach1(m_type, params, df_num, df_cat, targets, cv_indices)\n",
    "    \n",
    "    push!(results_df, (string(m_type), mu*100, sigma*100))\n",
    "    println(\"   -> Acc: $(round(mu*100, digits=2))% ± $(round(sigma*100, digits=2))\")\n",
    "end\n",
    "\n",
    "println(\"\\n--- Resumen de Resultados (Approach 1) ---\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b11a89f6-6606-45a6-ab9e-c0f64bc7e5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelCV_Approach1_ANN (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics, MLJ, DataFrames, Random, Flux\n",
    "\n",
    "# Asumimos que has cargado:\n",
    "# include(\"unit2-multilayer-perceptron.jl\")\n",
    "# include(\"unit3-overfitting.jl\")\n",
    "\n",
    "function modelCV_Approach1_ANN(\n",
    "        hyperparams::Dict,\n",
    "        data_num::DataFrame, \n",
    "        data_cat::DataFrame, \n",
    "        targets::AbstractArray, \n",
    "        folds_indices::Array{Int64,1})\n",
    "    \n",
    "    num_folds = maximum(folds_indices)\n",
    "    classes = unique(targets)\n",
    "    \n",
    "    # Arrays para guardar resultados\n",
    "    accuracies = zeros(num_folds)\n",
    "    # Puedes añadir arrays para F1, sensibilidad, etc. si lo necesitas\n",
    "    \n",
    "    # Extraer hiperparámetros\n",
    "    topology = get(hyperparams, :topology, [10]) \n",
    "    lr       = get(hyperparams, :learningRate, 0.01)\n",
    "    max_ep   = get(hyperparams, :maxEpochs, 1000)\n",
    "    # Porcentaje del Train del Fold que se usará para Early Stopping\n",
    "    val_ratio_internal = get(hyperparams, :validationRatio, 0.2) \n",
    "    \n",
    "    println(\"Iniciando CV para ANN con $num_folds folds...\")\n",
    "\n",
    "    for k in 1:num_folds\n",
    "        # --- A. SEPARACIÓN DEL FOLD ---\n",
    "        idx_train_global = folds_indices .!= k\n",
    "        idx_test         = folds_indices .== k\n",
    "        \n",
    "        # Datos crudos del fold\n",
    "        x_tr_glob_num = data_num[idx_train_global, :]\n",
    "        x_tr_glob_cat = data_cat[idx_train_global, :]\n",
    "        y_tr_global   = targets[idx_train_global]\n",
    "        \n",
    "        x_te_num_raw = data_num[idx_test, :]\n",
    "        x_te_cat_raw = data_cat[idx_test, :]\n",
    "        y_test       = targets[idx_test]\n",
    "        \n",
    "        # --- B. SPLIT INTERNO (Para Early Stopping) ---\n",
    "        # Usamos tu función holdOut de unit3 [cite: 87]\n",
    "        n_global = length(y_tr_global)\n",
    "        (idx_tr_real, idx_val_internal) = holdOut(n_global, val_ratio_internal)\n",
    "        \n",
    "        # 1. Train Real (Donde aprendemos params)\n",
    "        x_tr_real_num = x_tr_glob_num[idx_tr_real, :]\n",
    "        x_tr_real_cat = x_tr_glob_cat[idx_tr_real, :]\n",
    "        y_tr_real     = y_tr_global[idx_tr_real]\n",
    "        \n",
    "        # 2. Validation (Para detener la ANN)\n",
    "        x_val_num_raw = x_tr_glob_num[idx_val_internal, :]\n",
    "        x_val_cat_raw = x_tr_glob_cat[idx_val_internal, :]\n",
    "        y_val         = y_tr_global[idx_val_internal]\n",
    "        \n",
    "        # --- C. PREPROCESAMIENTO SEGURO (Approach 1) ---\n",
    "        \n",
    "        # 1. Numéricas: MinMax calculado en Train Real [cite: 75]\n",
    "        norm_params = calculateMinMaxNormalizationParameters(Matrix(x_tr_real_num))\n",
    "        \n",
    "        X_tr_proc_num = normalizeMinMax(Matrix(x_tr_real_num), norm_params)\n",
    "        X_val_proc_num= normalizeMinMax(Matrix(x_val_num_raw), norm_params)\n",
    "        X_te_proc_num = normalizeMinMax(Matrix(x_te_num_raw), norm_params)\n",
    "        \n",
    "        # 2. Categóricas: OHE calculado en Train Real [cite: 72]\n",
    "        # Acumulamos matrices bitarray/float\n",
    "        list_tr, list_val, list_te = [], [], []\n",
    "        \n",
    "        for col_name in names(data_cat)\n",
    "            c_tr  = x_tr_real_cat[!, col_name]\n",
    "            c_val = x_val_cat_raw[!, col_name]\n",
    "            c_te  = x_te_cat_raw[!, col_name]\n",
    "            \n",
    "            learn_cls = unique(c_tr)\n",
    "            # Manejo defensivo de clases nuevas (Approach 1)\n",
    "            for v in unique(c_val) if !(v in learn_cls) push!(learn_cls, v) end end\n",
    "            for v in unique(c_te)  if !(v in learn_cls) push!(learn_cls, v) end end\n",
    "            \n",
    "            push!(list_tr, oneHotEncoding(c_tr, learn_cls))\n",
    "            push!(list_val, oneHotEncoding(c_val, learn_cls))\n",
    "            push!(list_te, oneHotEncoding(c_te, learn_cls))\n",
    "        end\n",
    "        \n",
    "        X_tr_proc_cat = hcat(list_tr...)\n",
    "        X_val_proc_cat= hcat(list_val...)\n",
    "        X_te_proc_cat = hcat(list_te...)\n",
    "        \n",
    "        # 3. Unificar\n",
    "        inputsTrain = Float32.(hcat(X_tr_proc_num, X_tr_proc_cat))\n",
    "        inputsVal   = Float32.(hcat(X_val_proc_num, X_val_proc_cat))\n",
    "        inputsTest  = Float32.(hcat(X_te_proc_num, X_te_proc_cat))\n",
    "        \n",
    "        # 4. Targets (OHE necesario para ANN)\n",
    "        targetsTrain = oneHotEncoding(y_tr_real, classes)\n",
    "        targetsVal   = oneHotEncoding(y_val, classes)\n",
    "        targetsTest  = oneHotEncoding(y_test, classes)\n",
    "        \n",
    "        # --- D. ENTRENAMIENTO ---\n",
    "        # Llamamos a trainClassANN de unit3 [cite: 90]\n",
    "        # Pasamos explícitamente validationDataset para que haga early stopping\n",
    "        ann, _, _, _ = trainClassANN(\n",
    "            topology,\n",
    "            (inputsTrain, targetsTrain);\n",
    "            validationDataset = (inputsVal, targetsVal),\n",
    "            testDataset = (inputsTest, targetsTest), # Opcional, solo para ver loss\n",
    "            learningRate = lr,\n",
    "            maxEpochs = max_ep,\n",
    "            maxEpochsVal = 20, # Paciencia\n",
    "            showText = false\n",
    "        )\n",
    "        \n",
    "        # --- E. EVALUACIÓN DEL FOLD ---\n",
    "        # Flux requiere inputs traspuestos (features x samples) para predecir [cite: 67]\n",
    "        testOutputs = ann(inputsTest')' \n",
    "        \n",
    "        # Usamos tu función accuracy [cite: 82]\n",
    "        # Nota: oneHotEncoding(y_test) devuelve matriz booleana\n",
    "        acc = accuracy(testOutputs, targetsTest)\n",
    "        accuracies[k] = acc\n",
    "    end\n",
    "    \n",
    "    return mean(accuracies), std(accuracies)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8654976b-8a96-4da0-bf62-be42e9bfb061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ejecución ANN con Cross-Validation (Approach 1) ---\n"
     ]
    }
   ],
   "source": [
    "println(\"\\n--- Ejecución ANN con Cross-Validation (Approach 1) ---\")\n",
    "\n",
    "# 1. PREPARACIÓN INICIAL (Hold-Out Global 15%)\n",
    "Random.seed!(1234)\n",
    "rows = size(data, 1)\n",
    "# Reservamos el 15% para el TEST FINAL (No se toca en el CV)\n",
    "(idx_cv, idx_test_final) = holdOut(rows, 0.15) \n",
    "\n",
    "# Datos para Cross-Validation (85%)\n",
    "data_cv = data[idx_cv, :]\n",
    "\n",
    "# Separamos en Numéricos y Categóricos (Raw)\n",
    "df_num_cv = select(data_cv, num_col)\n",
    "df_cat_cv = select(data_cv, cat_col)\n",
    "targets_cv = data_cv[!, target_col]\n",
    "\n",
    "# 2. GENERAR INDICES DE CV\n",
    "k_folds = 10\n",
    "# Usamos tu función de unit5 para estratificar [cite: 56]\n",
    "cv_indices = crossvalidation(targets_cv, k_folds)\n",
    "\n",
    "# 3. CONFIGURAR EXPERIMENTO ANN\n",
    "ann_hyperparams = Dict(\n",
    "    :topology => [16, 8],     # Arquitectura: 2 capas ocultas\n",
    "    :learningRate => 0.005,   # Learning Rate\n",
    "    :maxEpochs => 1000,       # Máximo épocas\n",
    "    :validationRatio => 0.2   # 20% del train de cada fold para validación interna\n",
    ")\n",
    "\n",
    "# 4. EJECUTAR\n",
    "mu_ann, sigma_ann = modelCV_Approach1_ANN(\n",
    "    ann_hyperparams, \n",
    "    df_num_cv, \n",
    "    df_cat_cv, \n",
    "    targets_cv, \n",
    "    cv_indices\n",
    ")\n",
    "\n",
    "println(\"Resultados ANN (Approach 1):\")\n",
    "println(\"Accuracy Promedio (CV): $(round(mu_ann*100, digits=2))% ± $(round(sigma_ann*100, digits=2))\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PASO FINAL (Solo para el reporte final, una vez decidido el modelo)\n",
    "# ---------------------------------------------------------\n",
    "# Si este modelo te gusta, lo re-entrenas con TODO data_cv \n",
    "# y evalúas contra data[idx_test_final, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed88451-a5a3-4e3e-b562-f8f80fea23e9",
   "metadata": {},
   "source": [
    "# Mejor que guardar y cargar los folds casi es mejor aplicar las funciones a los datos cargados en memoria, ya que si cambia el numero de folds tenemos que guardarlos de nuevo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59004d26-0a52-4587-918c-25cdfb7fc86e",
   "metadata": {},
   "source": [
    "# 5th approach PCA and crossval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77a8bbc-454c-47f4-88bc-a91ca68f205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics, MLJ, DataFrames, Random, Flux\n",
    "import MultivariateStats # Usamos 'import' para evitar conflictos de nombres\n",
    "\n",
    "# Asumimos que las funciones de unit2 (calculateZeroMean..., normalizeZeroMean) están cargadas\n",
    "\n",
    "function modelCV_Approach2_PCA_ANN(\n",
    "        hyperparams::Dict,\n",
    "        data_num::DataFrame, \n",
    "        data_cat::DataFrame, \n",
    "        targets::AbstractArray, \n",
    "        folds_indices::Array{Int64,1})\n",
    "    \n",
    "    num_folds = maximum(folds_indices)\n",
    "    classes = unique(targets)\n",
    "    \n",
    "    accuracies = zeros(num_folds)\n",
    "    \n",
    "    # Hiperparámetros\n",
    "    topology = get(hyperparams, :topology, [10]) \n",
    "    lr       = get(hyperparams, :learningRate, 0.01)\n",
    "    max_ep   = get(hyperparams, :maxEpochs, 1000)\n",
    "    val_ratio_internal = get(hyperparams, :validationRatio, 0.2)\n",
    "    n_components_pca   = get(hyperparams, :pca_components, 17) \n",
    "    \n",
    "    println(\"Iniciando CV (Approach 2: PCA + Z-Score) con $num_folds folds...\")\n",
    "\n",
    "    for k in 1:num_folds\n",
    "        # --- A. SEPARACIÓN DEL FOLD (Train Global vs Test) ---\n",
    "        idx_train_global = folds_indices .!= k\n",
    "        idx_test         = folds_indices .== k\n",
    "        \n",
    "        # Datos Crudos del Fold\n",
    "        x_tr_glob_num = data_num[idx_train_global, :]\n",
    "        x_tr_glob_cat = data_cat[idx_train_global, :]\n",
    "        y_tr_global   = targets[idx_train_global]\n",
    "        \n",
    "        x_te_num_raw = data_num[idx_test, :]\n",
    "        x_te_cat_raw = data_cat[idx_test, :]\n",
    "        y_test       = targets[idx_test]\n",
    "        \n",
    "        # --- B. SPLIT INTERNO (Train Real vs Validation para Early Stopping) ---\n",
    "        n_global = length(y_tr_global)\n",
    "        (idx_tr_real, idx_val_internal) = holdOut(n_global, val_ratio_internal)\n",
    "        \n",
    "        # Train Real (80% del fold)\n",
    "        x_tr_real_num = x_tr_glob_num[idx_tr_real, :]\n",
    "        x_tr_real_cat = x_tr_glob_cat[idx_tr_real, :]\n",
    "        y_tr_real     = y_tr_global[idx_tr_real]\n",
    "        \n",
    "        # Validation (20% del fold)\n",
    "        x_val_num_raw = x_tr_glob_num[idx_val_internal, :]\n",
    "        x_val_cat_raw = x_tr_glob_cat[idx_val_internal, :]\n",
    "        y_val         = y_tr_global[idx_val_internal]\n",
    "        \n",
    "        # --- C. PREPROCESAMIENTO ---\n",
    "        \n",
    "        # [cite_start]1. Numéricas: Z-SCORE (Media 0, Desv 1) [cite: 76, 77]\n",
    "        # Calculamos parámetros SOLO con el Train Real para evitar data leakage\n",
    "        norm_params = calculateZeroMeanNormalizationParameters(Matrix(x_tr_real_num))\n",
    "        \n",
    "        # Aplicamos Z-Score a los 3 conjuntos\n",
    "        X_tr_num = normalizeZeroMean(Matrix(x_tr_real_num), norm_params)\n",
    "        X_val_num= normalizeZeroMean(Matrix(x_val_num_raw), norm_params)\n",
    "        X_te_num = normalizeZeroMean(Matrix(x_te_num_raw), norm_params)\n",
    "        \n",
    "        # [cite_start]2. Categóricas: One-Hot Encoding [cite: 72]\n",
    "        list_tr, list_val, list_te = [], [], []\n",
    "        for col in names(data_cat)\n",
    "            c_tr, c_val, c_te = x_tr_real_cat[!,col], x_val_cat_raw[!,col], x_te_cat_raw[!,col]\n",
    "            \n",
    "            # Aprendemos clases solo de Train Real\n",
    "            learn_cls = unique(c_tr)\n",
    "            # Añadimos clases nuevas de Val/Test solo para evitar errores técnicos\n",
    "            union!(learn_cls, unique(c_val))\n",
    "            union!(learn_cls, unique(c_te))\n",
    "            \n",
    "            push!(list_tr, oneHotEncoding(c_tr, learn_cls))\n",
    "            push!(list_val, oneHotEncoding(c_val, learn_cls))\n",
    "            push!(list_te, oneHotEncoding(c_te, learn_cls))\n",
    "        end\n",
    "        \n",
    "        X_tr_cat = hcat(list_tr...)\n",
    "        X_val_cat = hcat(list_val...)\n",
    "        X_te_cat = hcat(list_te...)\n",
    "        \n",
    "        # 3. Unificar en Matrices Híbridas (Antes de PCA)\n",
    "        X_tr_full  = Float64.(hcat(X_tr_num, X_tr_cat))\n",
    "        X_val_full = Float64.(hcat(X_val_num, X_val_cat))\n",
    "        X_te_full  = Float64.(hcat(X_te_num, X_te_cat))\n",
    "        \n",
    "        # --- D. APLICAR PCA ---\n",
    "        # Ajustamos PCA solo con Train Real. Usamos la transpuesta (features x samples)\n",
    "        pca_model = MultivariateStats.fit(MultivariateStats.PCA, X_tr_full'; maxoutdim=n_components_pca)\n",
    "        \n",
    "        # Proyectamos (Transformamos) y transponemos de vuelta a (samples x features)\n",
    "        # Convertimos a Float32 para Flux\n",
    "        inputsTrain = Float32.(MultivariateStats.transform(pca_model, X_tr_full')')\n",
    "        inputsVal   = Float32.(MultivariateStats.transform(pca_model, X_val_full')')\n",
    "        inputsTest  = Float32.(MultivariateStats.transform(pca_model, X_te_full')')\n",
    "        \n",
    "        # --- E. TARGETS ---\n",
    "        targetsTrain = oneHotEncoding(y_tr_real, classes)\n",
    "        targetsVal   = oneHotEncoding(y_val, classes)\n",
    "        targetsTest  = oneHotEncoding(y_test, classes)\n",
    "        \n",
    "        # --- F. ENTRENAMIENTO ANN ---\n",
    "        # inputsTrain ahora tiene 'n_components_pca' columnas (ej. 17)\n",
    "        ann, _, _, _ = trainClassANN(\n",
    "            topology,\n",
    "            (inputsTrain, targetsTrain);\n",
    "            validationDataset = (inputsVal, targetsVal),\n",
    "            # No pasamos testDataset al entrenamiento, evaluamos fuera\n",
    "            learningRate = lr,\n",
    "            maxEpochs = max_ep,\n",
    "            maxEpochsVal = 20, # Paciencia Early Stopping\n",
    "            showText = false\n",
    "        )\n",
    "        \n",
    "        # --- G. EVALUACIÓN ---\n",
    "        testOutputs = ann(inputsTest')' \n",
    "        acc = accuracy(testOutputs, targetsTest)\n",
    "        accuracies[k] = acc\n",
    "    end\n",
    "    \n",
    "    return mean(accuracies), std(accuracies)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ebdffe-f6e0-4893-b8b4-38d032cfeb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"\\n--- Ejecución ANN con Cross-Validation (Approach 2: PCA Z-Score) ---\")\n",
    "\n",
    "pca_hyperparams = Dict(\n",
    "    :topology => [10],        # Ajusta según complejidad (ej. [16, 8] si 10 es poco)\n",
    "    :learningRate => 0.01,\n",
    "    :maxEpochs => 1000,\n",
    "    :validationRatio => 0.2,\n",
    "    :pca_components => 17     \n",
    ")\n",
    "\n",
    "mu_pca, sigma_pca = modelCV_Approach2_PCA_ANN(\n",
    "    pca_hyperparams, \n",
    "    df_num_cv, \n",
    "    df_cat_cv, \n",
    "    targets_cv, \n",
    "    cv_indices\n",
    ")\n",
    "\n",
    "println(\"Resultados ANN (Approach 2 - PCA Z-Score):\")\n",
    "println(\"Accuracy Promedio (CV): $(round(mu_pca*100, digits=2))% ± $(round(sigma_pca*100, digits=2))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34771f7-8329-411a-b6c6-b20bb05760ba",
   "metadata": {},
   "source": [
    "# Analisys of the data, cov matrix and stats for the different approaches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd8bfa-2e72-4f63-a2c8-4318bf1ed30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics, Random, MLJ, DataFrames, Plots, Measures\n",
    "\n",
    "# =============================================================================\n",
    "# 1. PLOTTING FUNCTION (Adjusted Visualization)\n",
    "# =============================================================================\n",
    "function plot_correlation_final(X_mat::Matrix, feat_names::Vector{String})\n",
    "    \n",
    "    cor_matrix = cor(X_mat)\n",
    "    n_rows, n_cols = size(cor_matrix)\n",
    "    seaborn_palette = cgrad([:white, :aquamarine, :teal, :midnightblue])\n",
    "    \n",
    "    p = heatmap(\n",
    "        1:n_cols, \n",
    "        1:n_rows, \n",
    "        cor_matrix,\n",
    "        title = \"Correlation Matrix (Approach 1)\",\n",
    "        color = seaborn_palette,\n",
    "        clims = (-1, 1),\n",
    "        aspect_ratio = :equal,\n",
    "        yflip = true,\n",
    "        \n",
    "        # --- CRITICAL VISUAL ADJUSTMENTS ---\n",
    "        # 1. Force labels on all ticks\n",
    "        xticks = (1:n_cols, feat_names),\n",
    "        yticks = (1:n_rows, feat_names),\n",
    "        \n",
    "        xrotation = 90,\n",
    "        \n",
    "        # 2. Small font size to fit 31 names\n",
    "        tickfontsize = 6, \n",
    "        \n",
    "        # 3. Generous image size\n",
    "        size = (1000, 900), \n",
    "        \n",
    "        # 4. Margins to prevent cutting off text\n",
    "        bottom_margin = 20mm, \n",
    "        left_margin = 20mm    \n",
    "    )\n",
    "    \n",
    "    return p\n",
    "end\n",
    "\n",
    "# =============================================================================\n",
    "# 2. MAIN PROCESSING FUNCTION (Approach 1)\n",
    "# =============================================================================\n",
    "function analyze_approach1(data::DataFrame, num_col::Vector{Symbol}, cat_col::Vector{Symbol})\n",
    "    \n",
    "    println(\"\\n--- Starting Analysis Approach 1 ---\")\n",
    "    \n",
    "    # 1. Initial Setup and HoldOut\n",
    "    Random.seed!(1234)\n",
    "    rows = size(data, 1)\n",
    "    (train_idx, val_idx, test_idx) = holdOut(rows, 0.15, 0.15)\n",
    "\n",
    "    train_data = data[train_idx, :]\n",
    "    val_data   = data[val_idx, :]\n",
    "    test_data_raw = data[test_idx, :] # Only to check for new classes\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. NUMERICAL PROCESSING\n",
    "    # ---------------------------------------------------------\n",
    "    println(\"Processing numerical variables...\")\n",
    "    x_train_num = Matrix{Float64}(train_data[!, num_col])\n",
    "    x_val_num   = Matrix{Float64}(val_data[!, num_col])\n",
    "\n",
    "    norm_params = calculateMinMaxNormalizationParameters(x_train_num)\n",
    "    normalizeMinMax!(x_train_num, norm_params)\n",
    "    normalizeMinMax!(x_val_num, norm_params)\n",
    "\n",
    "    # List of names (starts with numerical ones)\n",
    "    nombres_reales = string.(num_col)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. CATEGORICAL PROCESSING (With Smart Logic)\n",
    "    # ---------------------------------------------------------\n",
    "    println(\"Processing categorical variables (OHE)...\")\n",
    "    \n",
    "    # Initialize empty matrices\n",
    "    x_train_cat_mat = BitArray{2}(undef, size(train_data, 1), 0)\n",
    "    x_val_cat_mat   = BitArray{2}(undef, size(val_data, 1), 0)\n",
    "\n",
    "    for col in cat_col\n",
    "        feature_train = train_data[!, col]\n",
    "        feature_val   = val_data[!, col]\n",
    "        \n",
    "        # A. Collect all possible classes\n",
    "        learn_classes = unique(feature_train)\n",
    "        # Add from test\n",
    "        for v in unique(test_data_raw[!, col])\n",
    "            if !(v in learn_classes) push!(learn_classes, v) end\n",
    "        end\n",
    "        # Add from val\n",
    "        for v in unique(feature_val)\n",
    "            if !(v in learn_classes) push!(learn_classes, v) end\n",
    "        end\n",
    "        \n",
    "        # B. Apply OHE\n",
    "        encoded_train = oneHotEncoding(feature_train, learn_classes)\n",
    "        encoded_val   = oneHotEncoding(feature_val, learn_classes)\n",
    "        \n",
    "        # C. Concatenate matrices\n",
    "        x_train_cat_mat = hcat(x_train_cat_mat, encoded_train)\n",
    "        x_val_cat_mat   = hcat(x_val_cat_mat, encoded_val)\n",
    "        \n",
    "        # D. SMART NAME GENERATION\n",
    "        cols_generadas = size(encoded_train, 2)\n",
    "        n_clases_teoricas = length(learn_classes)\n",
    "        \n",
    "        if cols_generadas == 1 && n_clases_teoricas == 2\n",
    "            # Reduced Binary Case (e.g., Sex: Male/Female -> 1 col)\n",
    "            # Use the original column name\n",
    "            push!(nombres_reales, string(col))\n",
    "            \n",
    "        elseif cols_generadas == n_clases_teoricas\n",
    "            # Multiclass Case (e.g., CP: 4 types -> 4 cols)\n",
    "            for clase in learn_classes\n",
    "                push!(nombres_reales, \"$(col)_$(clase)\")\n",
    "            end\n",
    "        else\n",
    "            # Fallback for safety\n",
    "            for k in 1:cols_generadas\n",
    "                push!(nombres_reales, \"$(col)_Gen_$k\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. UNIFICATION AND RESULT\n",
    "    # ---------------------------------------------------------\n",
    "    X_train_final = hcat(x_train_num, x_train_cat_mat)\n",
    "    X_val_final   = hcat(x_val_num, x_val_cat_mat)\n",
    "    \n",
    "    # Merge Train and Val for analysis\n",
    "    X_analysis_sync = Matrix{Float64}(vcat(X_train_final, X_val_final))\n",
    "\n",
    "    println(\"--- Summary ---\")\n",
    "    println(\"Generated names: \", length(nombres_reales))\n",
    "    println(\"Columns in matrix: \", size(X_analysis_sync, 2))\n",
    "\n",
    "    if length(nombres_reales) == size(X_analysis_sync, 2)\n",
    "        println(\"Perfect Synchronization!\")\n",
    "        # Call the plotting function\n",
    "        return plot_correlation_final(X_analysis_sync, nombres_reales)\n",
    "    else\n",
    "        println(\"Error: Dimensions do not match.\")\n",
    "        return nothing\n",
    "    end\n",
    "end\n",
    "\n",
    "# =============================================================================\n",
    "# EXECUTION\n",
    "# =============================================================================\n",
    "# Simply call this function with your DataFrame and column lists\n",
    "p_result = analyze_approach1(data, num_col, cat_col)\n",
    "display(p_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12371d3d-8e5a-4706-9345-d1b6fcc56bd0",
   "metadata": {},
   "source": [
    "**Corr matrix, it shows that mixing OHE categorical features with numerical ones is valid and some interesting info may be induced by this result. For PCA and ICA it didn't make sense to do this representation, for PCA we will see the reason why its valid in the next plots**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f380bddd-1d25-4f27-8c13-82b0b0f0a1bb",
   "metadata": {},
   "source": [
    "### Correlation Matrix Analysis (Approach 1)\n",
    "\n",
    "The correlation heatmap reveals the relationships between the 31 features resulting from the mixing of numerical variables and One-Hot Encoded (OHE) categorical variables.\n",
    "\n",
    "**Key Insights:**\n",
    "\n",
    "* **Structural Multicollinearity (OHE Effect):**\n",
    "    * The matrix displays distinct blocks of **strong negative correlation** (light cyan/white squares). This is expected and structural. For example, within the Chest Pain (`cp`) group, if a patient has `cp_typical_angina`, they cannot simultaneously have `cp_asymptomatic`.\n",
    "    * This confirms that the One-Hot Encoding was applied correctly, but it also highlights that the dataset now contains redundant information (multicollinearity), which motivates the need for dimensionality reduction techniques like PCA.\n",
    "\n",
    "* **Physiological Relationships:**\n",
    "    * Beyond the artificial correlations from OHE, we observe meaningful patterns between numerical and categorical features. For instance, **`oldpeak`** (ST depression) shows positive correlations with certain types of **`slope`** and **`thal`** defects, aligning with medical expectations for heart disease indicators.\n",
    "    * **`thalch`** (maximum heart rate) shows a negative correlation with **`age`**, which is a standard physiological trait (max heart rate decreases with age).\n",
    "\n",
    "* **Analysis of \"Missing\" Categories:**\n",
    "    * The columns created for imputation, such as **`thal_missingval`**, **`slope_missingval`**, and **`ca_missingval`**, do not show strong correlations (dark blue) with demographic features like `age` or `sex`.\n",
    "    * This suggests that the \"missingness\" of the data is not heavily biased towards a specific demographic group in this subset. Keeping these as separate categories allows the model to learn if the *absence* of a test result is itself a predictor of heart disease.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "While **Approach 1** preserves all granular information, it expands the feature space significantly and introduces high multicollinearity. This visualization validates the necessity of **Approach 2**, where **PCA** will be used to distill these 31 correlated features into a smaller set of independent components, capturing the variance without the redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9f21d-42b8-49ee-a817-2df26b9575c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics, Random, MLJ, DataFrames, Plots, Measures, MultivariateStats, DecisionTree\n",
    "\n",
    "\"\"\"\n",
    "    justify_pca_and_features(data, num_col, cat_col)\n",
    "\n",
    "Generates two key plots to justify using PCA (Approach 2):\n",
    "1. PCA Scree Plot: Demonstrates the ability to compress data.\n",
    "2. Feature Importance (RF): Shows which variables are vital (and why we shouldn't just drop them).\n",
    "\"\"\"\n",
    "function justify_pca_and_features(data::DataFrame, num_col::Vector{Symbol}, cat_col::Vector{Symbol})\n",
    "    \n",
    "    println(\"\\n--- Starting PCA Justification (Approach 2) ---\")\n",
    "    \n",
    "    # =========================================================\n",
    "    # 1. DATA PREPARATION (Using Smart Logic)\n",
    "    # =========================================================\n",
    "    Random.seed!(1234)\n",
    "    rows = size(data, 1)\n",
    "    (train_idx, val_idx, test_idx) = holdOut(rows, 0.15, 0.15)\n",
    "\n",
    "    # Use Train + Val for the variance analysis\n",
    "    train_data = data[train_idx, :]\n",
    "    val_data   = data[val_idx, :]\n",
    "    test_data_raw = data[test_idx, :] \n",
    "\n",
    "    # --- Numerical Features ---\n",
    "    println(\"Processing numerical features...\")\n",
    "    x_train_num = Matrix{Float64}(train_data[!, num_col])\n",
    "    x_val_num   = Matrix{Float64}(val_data[!, num_col])\n",
    "    norm_params = calculateMinMaxNormalizationParameters(x_train_num)\n",
    "    normalizeMinMax!(x_train_num, norm_params)\n",
    "    normalizeMinMax!(x_val_num, norm_params)\n",
    "    \n",
    "    nombres_reales = string.(num_col)\n",
    "\n",
    "    # --- Categorical Features (OHE) ---\n",
    "    println(\"Processing categorical features (Smart OHE)...\")\n",
    "    x_train_cat_mat = BitArray{2}(undef, size(train_data, 1), 0)\n",
    "    x_val_cat_mat   = BitArray{2}(undef, size(val_data, 1), 0)\n",
    "\n",
    "    for col in cat_col\n",
    "        feature_train = train_data[!, col]\n",
    "        feature_val   = val_data[!, col]\n",
    "        \n",
    "        # Learn classes\n",
    "        learn_classes = unique(feature_train)\n",
    "        for v in unique(test_data_raw[!, col])\n",
    "            if !(v in learn_classes) push!(learn_classes, v) end\n",
    "        end\n",
    "        for v in unique(feature_val)\n",
    "            if !(v in learn_classes) push!(learn_classes, v) end\n",
    "        end\n",
    "        \n",
    "        # Apply OHE\n",
    "        encoded_train = oneHotEncoding(feature_train, learn_classes)\n",
    "        encoded_val   = oneHotEncoding(feature_val, learn_classes)\n",
    "        \n",
    "        x_train_cat_mat = hcat(x_train_cat_mat, encoded_train)\n",
    "        x_val_cat_mat   = hcat(x_val_cat_mat, encoded_val)\n",
    "        \n",
    "        # Smart Naming Logic\n",
    "        cols_gen = size(encoded_train, 2)\n",
    "        n_clases = length(learn_classes)\n",
    "        if cols_gen == 1 && n_clases == 2\n",
    "            # Binary case reduced to 1 column\n",
    "            push!(nombres_reales, string(col))\n",
    "        elseif cols_gen == n_clases\n",
    "            # Multiclass case\n",
    "            for c in learn_classes push!(nombres_reales, \"$(col)_$(c)\") end\n",
    "        else\n",
    "            # Fallback\n",
    "            for k in 1:cols_gen push!(nombres_reales, \"$(col)_Gen_$k\") end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Unify Matrices (Train + Val)\n",
    "    X_full = hcat(x_train_num, x_train_cat_mat)\n",
    "    X_full_val = hcat(x_val_num, x_val_cat_mat)\n",
    "    X_analysis = Matrix{Float64}(vcat(X_full, X_full_val))\n",
    "    \n",
    "    # Prepare Target for RF\n",
    "    y_train = train_data[!, :num] # Assuming target column is :num\n",
    "    y_val   = val_data[!, :num]\n",
    "    y_analysis = vcat(y_train, y_val)\n",
    "\n",
    "    println(\"Data ready. Cols: $(size(X_analysis, 2)). Names: $(length(nombres_reales))\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 2. PLOT A: PCA SCREE PLOT\n",
    "    # =========================================================\n",
    "    println(\"Calculating PCA...\")\n",
    "    # fit expects (features x samples), so we use transpose X'\n",
    "    pca_model = MultivariateStats.fit(MultivariateStats.PCA, X_analysis'; maxoutdim=length(nombres_reales))\n",
    "    \n",
    "    var_expl = principalvars(pca_model)\n",
    "    var_total = tprincipalvar(pca_model)\n",
    "    ratio_acumulado = cumsum(var_expl) / var_total\n",
    "\n",
    "    # Find 95% cutoff\n",
    "    idx_95 = findfirst(x -> x >= 0.95, ratio_acumulado)\n",
    "    idx_95_val = isnothing(idx_95) ? length(ratio_acumulado) : idx_95\n",
    "\n",
    "    p1 = plot(\n",
    "        1:length(ratio_acumulado), ratio_acumulado,\n",
    "        xlabel = \"Number of Components\", \n",
    "        ylabel = \"Accumulated Variance\",\n",
    "        title = \"PCA Justification (Scree Plot)\",\n",
    "        label = \"Acc. Var.\",\n",
    "        \n",
    "        marker = :circle,   \n",
    "        color = :cyan,      \n",
    "        linewidth = 2,      \n",
    "        \n",
    "        legend = :bottomright,\n",
    "        ylim = (0, 1.1)\n",
    "    )\n",
    " \n",
    "    # Cutoff lines\n",
    "    hline!(p1, [0.95], label=\"95% Threshold\", color=:red, ls=:dash)\n",
    "    vline!(p1, [idx_95_val], label=\"Cutoff ($idx_95_val comps)\", color=:orange)\n",
    "    scatter!(p1, [idx_95_val], [ratio_acumulado[idx_95_val]], color=:orange, label=\"\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 3. PLOT B: FEATURE IMPORTANCE (Random Forest)\n",
    "    # =========================================================\n",
    "    println(\"Calculating Feature Importance...\")\n",
    "    # Building Random Forest directly using DecisionTree.jl native API for speed\n",
    "    # Parameters: labels, features, n_subfeatures, n_trees, partial_sampling, max_depth\n",
    "    model_nativo = build_forest(y_analysis, X_analysis, 2, 50, 0.7, 10) \n",
    "    \n",
    "    importancias = DecisionTree.impurity_importance(model_nativo)\n",
    "    importancias = importancias ./ sum(importancias) # Normalize to %\n",
    "\n",
    "    # Sort Top 15\n",
    "    perm = sortperm(importancias, rev=true)\n",
    "    top_n = min(15, length(nombres_reales))\n",
    "    \n",
    "    p2 = bar(\n",
    "        nombres_reales[perm][1:top_n], \n",
    "        importancias[perm][1:top_n],\n",
    "        title = \"Feature Importance (Random Forest)\",\n",
    "        ylabel = \"Relative Importance\",\n",
    "        color = :teal, legend = false,\n",
    "        xrotation = 45,\n",
    "        bottom_margin = 15mm\n",
    "    )\n",
    "\n",
    "    # =========================================================\n",
    "    # 4. FINAL LAYOUT\n",
    "    # =========================================================\n",
    "    p_final = plot(p1, p2, layout=(2, 1), size=(800, 1000), margin=10mm)\n",
    "    return p_final\n",
    "end\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# Generate the combined plot\n",
    "p_justification = justify_pca_and_features(data, num_col, cat_col)\n",
    "display(p_justification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039ff8ed-ae7d-4941-9dca-cf7b5bf7c7b7",
   "metadata": {},
   "source": [
    "### Analysis & Justification for Approach 2 (PCA)\n",
    "\n",
    "The **Feature Importance analysis** (bottom chart) reveals that categorical variables derived from One-Hot Encoding, such as `cp_asymptomatic` and `thal_reversable_defect`, possess high predictive capacity, comparable to physiological variables like blood pressure (`trestbps`). Even imputation categories like `thal_missingval` contribute useful information to the model.\n",
    "\n",
    "Therefore, removing these features simply due to their null values would be a mistake. However, keeping all 31 resulting columns creates a high-dimensional and correlated feature space.\n",
    "\n",
    "The **Scree Plot** (top chart) demonstrates that we can capture **95%** of this complex information using only **17 Principal Components**. This justifies **Approach 2**: preserving all data through OHE and imputation, while efficiently compressing it via PCA to feed models like SVM or Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398970f7-5ba2-4ad8-9ef7-8a98a5196f28",
   "metadata": {},
   "source": [
    "# ICA Analisys\n",
    "\n",
    "As the results opf our tests the ICA aproach was the wosrt one, this can simply be explained by the number of numeric vs categorical features. In our case we have 5 numerical features and 26 categorical OHEncoded. The ICA only can be aplied to the numerical ones and therefore we apply it in order to reduce that 5 components into 2. However we still have the 26 categorical ones, by doing this we may induce noise to the model instead of reducing it, as we can see in the plots below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09be92-4490-4dff-b538-12f0d2b578c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "function plot_ica_scatter(X_ica_2d, y_targets)\n",
    "    \n",
    "    clases = string.(y_targets) #for legend\n",
    "    \n",
    "    p = scatter(\n",
    "        X_ica_2d[:, 1], \n",
    "        X_ica_2d[:, 2], \n",
    "        group = clases,\n",
    "        title = \"Inseparabilidad en el Espacio ICA (k=2)\",\n",
    "        xlabel = \"Componente Independiente 1\",\n",
    "        ylabel = \"Componente Independiente 2\",\n",
    "        marker = (:circle, 6, 0.6), # Transparencia para ver solapamiento\n",
    "        palette = [:blue, :red, :green, :orange, :purple], # Ajusta según tus clases\n",
    "        legend = :outertopright,\n",
    "        size = (800, 600)\n",
    "    )\n",
    "    return p\n",
    "end\n",
    "\n",
    "# Example with training data\n",
    "display(plot_ica_scatte(x_train_ica, y_train_ica))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b9df05-35be-4e3b-8e40-3347d1642ab8",
   "metadata": {},
   "source": [
    "**Del grafico de dispersion de las dos compnentes de ICA podemos ver que efectivamente no hace un buen trabajos separando las clases a clasificar**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a0f48-a923-4ed1-ad8b-001326b594e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DecisionTree, Plots\n",
    "\n",
    "# Nombres: 2 de ICA + las de OHE que tengas\n",
    "nombres_ica = [\"IC_1\", \"IC_2\"]\n",
    "# Asumiendo que tienes los nombres de las categóricas en 'cat_names_ohe'\n",
    "# Si no, usa genéricos:\n",
    "nombres_ohe = [\"OHE_$i\" for i in 1:(size(x_train_ica, 2)-2)]\n",
    "nombres_todos = vcat(nombres_ica, nombres_ohe)\n",
    "\n",
    "# Entrenar RF Rápido\n",
    "model_rf = build_forest(y_train_ica, x_train_ica, 2, 50, 0.7, -1)\n",
    "imps = DecisionTree.impurity_importance(model_rf)\n",
    "imps = imps ./ sum(imps) # Normalizar\n",
    "\n",
    "# Graficar\n",
    "perm = sortperm(imps, rev=true)\n",
    "top_n = 15\n",
    "\n",
    "bar(\n",
    "    nombres_todos[perm][1:top_n], \n",
    "    imps[perm][1:top_n],\n",
    "    title = \"Feature Importance (ICA vs OHE)\",\n",
    "    label = \"\",\n",
    "    xrotation = 45,\n",
    "    color = :darkred # Color \"peligro\" para denotar que algo va mal\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f5e92-ceb7-469e-9072-e84a5d7c287f",
   "metadata": {},
   "source": [
    "**\"El análisis de importancia de características (Feature Importance) revela un hallazgo sorprendente: las dos componentes independientes (IC_1 y IC_2) dominan completamente la capacidad predictiva del modelo, superando por mucho a cualquier variable categórica.\\\n",
    "Esto indica que el algoritmo ICA fue técnicamente exitoso en comprimir la varianza de las 5 variables numéricas originales. Sin embargo, el bajo rendimiento del modelo final (Accuracy ~X%) sugiere que el problema no es la falta de información en las componentes, sino la pérdida de relaciones no lineales. Al forzar la independencia estadística y reducir la dimensionalidad tan agresivamente (de 5 a 2), hemos creado un \"cuello de botella\" donde, aunque conservamos la señal principal, perdimos las interacciones sutiles entre variables (ej. la relación específica entre Edad y Colesterol) que son necesarias para distinguir los casos difíciles.\"**\n",
    "\n",
    "Resumiendo, ICA extrajo la señal fuerte, pero mató los detalles finos necesarios para una alta precisión a la hora de clasificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cd734-7ea5-41cd-9969-0549f8630748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0c03e-9d4c-43d7-9212-b4463acbc74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d2e8e-e91f-471c-8a22-561d270439a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59bb193-efbd-4174-879b-19e471c291d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baece967-b331-4f5e-821a-a611ffa899af",
   "metadata": {},
   "source": [
    "# Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760df756-bc09-4c0f-a3d2-bb894919e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2, MLJ, FileIO\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if !isdir(\"data_checkpoints\")\n",
    "    mkdir(\"data_checkpoints\")\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    save_checkpoint(filename, x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "\n",
    "Saves an exact snapshot of the processed data into a .jld2 file.\n",
    "\"\"\"\n",
    "function save_checkpoint(name, x_tr, y_tr, x_val, y_val, x_te, y_te)\n",
    "    path = joinpath(\"data_checkpoints\", name)\n",
    "    save(path, Dict(\n",
    "        \"x_train\" => x_tr, \"y_train\" => y_tr,\n",
    "        \"x_val\"   => x_val, \"y_val\"   => y_val,\n",
    "        \"x_test\"  => x_te,  \"y_test\"  => y_te\n",
    "    ))\n",
    "    println(\"✅ Saved: $path\")\n",
    "end\n",
    "\n",
    "println(\"--- Starting Dataset Export (No Folds) ---\\n\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. SAVE APPROACH 1 (MinMax + Full OHE)\n",
    "# =============================================================================\n",
    "# Original variables: approach_1.x_train, approach_1.y_train_cat, etc.\n",
    "\n",
    "save_checkpoint(\"approach_1_minmax.jld2\",\n",
    "    approach_1.x_train, approach_1.y_train_cat,\n",
    "    approach_1.x_val,   approach_1.y_val_cat,\n",
    "    approach_1.x_test,  approach_1.y_test_cat\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. SAVE APPROACH 2 (PCA)\n",
    "# =============================================================================\n",
    "# We need to transform the data using the PCA machine trained earlier.\n",
    "# Assuming 'pca_model' (or the machine) exists from the justification step.\n",
    "# If not, we recreate it quickly here using approach 1 data:\n",
    "\n",
    "println(\"... Processing PCA for export ...\")\n",
    "# Quick re-train to ensure consistency (using x_train from app 1)\n",
    "pca_mach_export = machine(PCA(maxoutdim=17), MLJ.table(approach_1.x_train))\n",
    "MLJ.fit!(pca_mach_export, verbosity=0)\n",
    "\n",
    "# Transform everything to matrices\n",
    "x_train_pca = MLJ.matrix(MLJ.transform(pca_mach_export, MLJ.table(approach_1.x_train)))\n",
    "x_val_pca   = MLJ.matrix(MLJ.transform(pca_mach_export, MLJ.table(approach_1.x_val)))\n",
    "x_test_pca  = MLJ.matrix(MLJ.transform(pca_mach_export, MLJ.table(approach_1.x_test)))\n",
    "\n",
    "save_checkpoint(\"approach_2_pca.jld2\",\n",
    "    x_train_pca, approach_1.y_train_cat,\n",
    "    x_val_pca,   approach_1.y_val_cat,\n",
    "    x_test_pca,  approach_1.y_test_cat\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. SAVE APPROACH 3 (ICA)\n",
    "# =============================================================================\n",
    "# We use the final variables created in the corrected ICA code block.\n",
    "# Variables: X_final_train, X_final_val, X_final_test\n",
    "# Targets: y_train, y_val, y_test (extracted at the start of the ICA block)\n",
    "\n",
    "save_checkpoint(\"approach_3_ica.jld2\",\n",
    "    x_train_ica, y_train_ica,\n",
    "    x_val_ica,   y_val_ica,\n",
    "    x_test_ica,  y_test_ica\n",
    ")\n",
    "\n",
    "println(\"\\nAll set! Data is safe in the 'data_checkpoints' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9dcb09-9103-4f63-adc6-6f2b47aaf243",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2\n",
    "\n",
    "\"\"\"\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = load_checkpoint(filename)\n",
    "\n",
    "Loads a processed dataset and returns 6 variables ready to use.\n",
    "\"\"\"\n",
    "function load_checkpoint(filename)\n",
    "    path = joinpath(\"data_checkpoints\", filename)\n",
    "    if !isfile(path)\n",
    "        error(\"File $path does not exist.\")\n",
    "    end\n",
    "    \n",
    "    d = JLD2.load(path)\n",
    "    \n",
    "    return d[\"x_train\"], d[\"y_train\"], d[\"x_val\"], d[\"y_val\"], d[\"x_test\"], d[\"y_test\"]\n",
    "end\n",
    "\n",
    "# --- REAL USAGE EXAMPLE ---\n",
    "\n",
    "# 1. Load PCA data\n",
    "xt, yt, xv, yv, xtest, ytest = load_checkpoint(\"approach_2_pca.jld2\")\n",
    "\n",
    "# 2. Train a model directly\n",
    "println(\"Training SVM with loaded data...\")\n",
    "model = SVC()\n",
    "mach = machine(model, MLJ.table(xt), yt) # MLJ.table if model requires a table\n",
    "MLJ.fit!(mach, verbosity=0)\n",
    "\n",
    "# 3. Validate\n",
    "acc = MLJ.accuracy(MLJ.predict(mach, MLJ.table(xv)), yv)\n",
    "println(\"Validation Accuracy: $acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c8690-920c-4a2a-8537-8465ca40ae27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7f93c-ed05-4deb-b31b-6786a18a8433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.7",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

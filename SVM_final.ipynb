{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da8823b-ab43-4e1f-9320-076c4b571ad8",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)\n",
    "## Heart Disease Detection\n",
    "\n",
    "In this notebook, we explore the use of **SVM (Support Vector Machines)** to classify patients with heart disease. The main objective is to find the model that maximizes **Sensitivity (Recall)**, as in medical diagnosis, it is critical to minimize **False Negatives** (failing to detect a sick patient).\n",
    "\n",
    "We will evaluate performance across three preprocessed datasets:\n",
    "1.  **MinMax:** Standard normalization.\n",
    "2.  **PCA:** Linear dimensionality reduction.\n",
    "3.  **ICA:** Independent Component Analysis.\n",
    "4.  **MinMax + Cross-Validation:** Robust validation for the baseline.\n",
    "5.  **PCA + Cross-Validation:** Robust validation for the reduced set.\n",
    "\n",
    "**Optimization:**\n",
    "We employ **Class Weighting** to handle class imbalance, forcing the SVM to penalize errors on sick patients more heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58664df1-b20c-4124-af9e-e7168c8f4359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "universalCrossValidation_PCA"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load libraries and previous functions:\n",
    "using Downloads\n",
    "using DelimitedFiles\n",
    "using Plots\n",
    "using MLJ\n",
    "using MLJModels\n",
    "using MLJMultivariateStatsInterface\n",
    "using MLJLinearModels\n",
    "using MLJDecisionTreeInterface\n",
    "using MLJNaiveBayesInterface\n",
    "using MLJLIBSVMInterface\n",
    "using Statistics\n",
    "using Flux\n",
    "using Flux: Losses\n",
    "using Printf\n",
    "using Random\n",
    "using NearestNeighborModels\n",
    "using CSV\n",
    "using DataFrames\n",
    "using DataFramesMeta\n",
    "import MultivariateStats\n",
    "using LIBSVM\n",
    "using JLD2, FileIO\n",
    "using CategoricalArrays\n",
    "\n",
    "include(\"unit2-multilayer-perceptron.jl\")\n",
    "include(\"unit3-overfitting.jl\")\n",
    "include(\"unit4-metrics.jl\")\n",
    "include(\"unit5-crossvalidation.jl\")\n",
    "include(\"unit6-modelcrossvalidation.jl\")\n",
    "include(\"SVM_final_utils.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced50bae-10e9-4100-85ab-22054e7a6754",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Grid Search\n",
    "SVMs are powerful but highly sensitive to their hyperparameters. We perform a search over different **Kernels** to find the best decision boundary geometry.\n",
    "\n",
    "### Parameters Tested:\n",
    "* **Kernels:**\n",
    "    * **Linear:** For simple, linearly separable data.\n",
    "    * **RBF (Radial Basis Function):** The standard for non-linear data. Maps samples to infinite dimensions.\n",
    "    * **Polynomial:** Captures specific degree interactions between features.\n",
    "    * **Sigmoid:** Mimics neural network activation patterns.\n",
    "    \n",
    "* **C (Cost/Regularization):**\n",
    "    * Controls the trade-off between a smooth boundary and classifying training points correctly.\n",
    "    * **High C:** Strict (Hard Margin), risks overfitting.\n",
    "    * **Low C:** Tolerant (Soft Margin), generalizes better but might miss edge cases.\n",
    "\n",
    "* **Gamma ($\\gamma$):** (For RBF/Poly/Sigmoid)\n",
    "    * Defines the \"reach\" of a single training example.\n",
    "    * **High $\\gamma$:** Only close points affect the boundary (complex islands).\n",
    "    * **Low $\\gamma$:** Distant points have influence (smooth curvature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ce2269-9770-4b53-9dfc-0ec43ec8697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Tuple{String, LIBSVM.Kernel.KERNEL, Float64, Float64, Int64}}:\n",
       " (\"RBF (C=1000000, G=0.03)\", LIBSVM.Kernel.RadialBasis, 1.0e6, 0.03, 0)\n",
       " (\"RBF (C=5000, G=0.07)\", LIBSVM.Kernel.RadialBasis, 5000.0, 0.07, 0)\n",
       " (\"RBF (C=100000.0, G=0.5)\", LIBSVM.Kernel.RadialBasis, 100000.0, 0.5, 0)\n",
       " (\"Linear (C=1000)\", LIBSVM.Kernel.Linear, 1000.0, 0.0, 0)\n",
       " (\"Poly (Deg=2, C=10000.0, Coef=1.0)\", LIBSVM.Kernel.Polynomial, 10000.0, 1.0, 2)\n",
       " (\"Poly (Deg=5, C=10000.0, Coef=1.0)\", LIBSVM.Kernel.Polynomial, 10000.0, 1.0, 5)\n",
       " (\"Sigmoid (C=100.0, G=0.01)\", LIBSVM.Kernel.Linear, 100.0, 0.01, 0)\n",
       " (\"Sigmoid (C=1000.0, G=0.01)\", LIBSVM.Kernel.RadialBasis, 1000.0, 0.01, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define SVM configurations (Hyperparameters) to test\n",
    "# Format: (Name, Kernel, Cost, Gamma, Degree)\n",
    "svm_configs = [\n",
    "    (\"RBF (C=1000000, G=0.03)\",           Kernel.RadialBasis, 1000000.0, 0.03, 0),\n",
    "    (\"RBF (C=5000, G=0.07)\",              Kernel.RadialBasis, 5000.0,    0.07, 0),\n",
    "    (\"RBF (C=100000.0, G=0.5)\",           Kernel.RadialBasis, 100000.0,  0.5,  0),\n",
    "    (\"Linear (C=1000)\",                   Kernel.Linear,      1000.0,    0.0,  0),\n",
    "    (\"Poly (Deg=2, C=10000.0, Coef=1.0)\", Kernel.Polynomial,  10000.0,   1.0,  2),\n",
    "    (\"Poly (Deg=5, C=10000.0, Coef=1.0)\", Kernel.Polynomial,  10000.0,   1.0,  5),\n",
    "    (\"Sigmoid (C=100.0, G=0.01)\",         Kernel.Linear,      100.0,     0.01, 0),\n",
    "    (\"Sigmoid (C=1000.0, G=0.01)\",        Kernel.RadialBasis, 1000.0,    0.01, 0),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6a8db-05ef-4c85-8a08-8b5fb41ac74a",
   "metadata": {},
   "source": [
    "# MULTICALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3eb988-7001-4661-9445-2c258098d2f0",
   "metadata": {},
   "source": [
    "## Approach 1: MinMax Normalization (Baseline)\n",
    "\n",
    "**Objective:** Establish a baseline performance using the full set of features.\n",
    "\n",
    "**Methodology:**\n",
    "1.  **Preprocessing:** We apply **MinMax Normalization** to scale all numerical features to the range $[0, 1]$. This is crucial for SVMs, as they are distance-based algorithms and sensitive to features with different scales.\n",
    "2.  **Validation:** We use a simple **Holdout** strategy (Train/Test split) to evaluate the model.\n",
    "3.  **Training:** We train SVMs with various kernels and class weights to handle imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebccf41f-f092-4fa4-b30f-8ba0097d1eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading data from: heart_disease_uci.csv\n",
      "  Original Size: (920, 14)\n",
      " Categorical Null values replaced with ---> 'missingval'.\n",
      "  Deleted rows in features: [:trestbps, :chol, :thalch, :oldpeak]\n",
      "  Final shape: (827, 14)\n",
      "------------------------\n",
      "\n",
      " Init aproach 1 (MinMax)...\n",
      "\n",
      "--- init Preprocess ---\n",
      "   Normalization: minmax\n",
      "    Stratigfied HoldOut split: 577 train, 125 val, 125 test\n",
      "    Normalizing numerical features...\n",
      "    ...Normalization completed.\n",
      "    Encoding categorical features (OHE)...\n",
      "    ...OHE completed.\n",
      "    Concatenate numerical and categorical matrices...\n",
      "    Classes stored for the target: [0, 1, 2, 3, 4]\n",
      "--- PREPROCESS END SUCCESFULLY ---\n",
      ">> Ejecutando SVM - Approach 1 (MinMax)\n",
      "\n",
      "=================================================================\n",
      " EXPERIMENT: APPROACH 1: MINMAX (Manual Train/Test)\n",
      "=================================================================\n",
      "   [Auto-Fix] Transponiendo matriz para formato LIBSVM (Features x Samples)...\n",
      "   Dimensiones finales X_train: (31, 577)\n",
      " Testing Config 1/8: RBF (C=1000000, G=0.03) ... Done. Sens: 0.3394 | Acc: 52.0%\n",
      " Testing Config 2/8: RBF (C=5000, G=0.07) ... Done. Sens: 0.3519 | Acc: 51.2%\n",
      " Testing Config 3/8: RBF (C=100000.0, G=0.5) ... Done. Sens: 0.3094 | Acc: 46.4%\n",
      " Testing Config 4/8: Linear (C=1000) ... Done. Sens: 0.3872 | Acc: 51.2%\n",
      " Testing Config 5/8: Poly (Deg=2, C=10000.0, Coef=1.0) ... Done. Sens: 0.38 | Acc: 53.6%\n",
      " Testing Config 6/8: Poly (Deg=5, C=10000.0, Coef=1.0) ... Done. Sens: 0.3296 | Acc: 52.8%\n",
      " Testing Config 7/8: Sigmoid (C=100.0, G=0.01) ... Done. Sens: 0.3836 | Acc: 50.4%\n",
      " Testing Config 8/8: Sigmoid (C=1000.0, G=0.01) ... Done. Sens: 0.3668 | Acc: 52.8%\n",
      "\n",
      "\n",
      "****************************************************************\n",
      "      WINNER FOR APPROACH 1: MINMAX\n",
      "****************************************************************\n",
      "Approach: MinMax\n",
      "Best Config:(\"Linear (C=1000)\", LIBSVM.Kernel.Linear, 1000.0, 0.0, 0)\n",
      "Sensib:0.3871933471933472\n",
      "Acc(%):51.2\n",
      "Time(s):4.2348551750183105\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# (Aproach 1) minmax\n",
    "# -----------------------------------------------------------------\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "\n",
    "data, num_col, cat_col, target_col = load_and_clean_data(data_path)\n",
    "\n",
    "println(\"\\n Init aproach 1 (MinMax)...\")\n",
    "approach_1 = prepare_data(\n",
    "    data,          # Clean DataFrame without Nulls\n",
    "    num_col,       # numerical features\n",
    "    cat_col,       # caetgorical features\n",
    "    target_col,    # target feature\n",
    "    norm_method=:minmax #norm metghod, either :minmax or :zscore\n",
    ")\n",
    "\n",
    "#println(\"\\n--- Approach 1 ---\")\n",
    "#println(\"To acces data:\")\n",
    "#println(\"approach_1.x_train\")\n",
    "#println(\"approach_1.y_train_cat (for SVM/DT/kNN)\")\n",
    "#println(\"approach_1.y_train_ohe (for ANN)\")\n",
    "#println(\"...\")\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------\n",
    "println(\">> Ejecutando SVM - Approach 1 (MinMax)\")\n",
    "\n",
    "winner_minmax = run_svm_experiment(\n",
    "    approach_1.x_train,      # Matriz de Training\n",
    "    approach_1.y_train_cat,  # Etiquetas de Training (si son categóricas, la función las convierte)\n",
    "    approach_1.x_test,       # Matriz de Test\n",
    "    approach_1.y_test_cat,   # Etiquetas de Test\n",
    "    \"APPROACH 1: MINMAX\",\n",
    "    svm_configs\n",
    ")\n",
    "\n",
    "# Final Summary\n",
    "println(\"\\n\\n****************************************************************\")\n",
    "println(\"      WINNER FOR APPROACH 1: MINMAX\")\n",
    "println(\"****************************************************************\")\n",
    "println(\"Approach: MinMax\")\n",
    "println(\"Best Config:\",winner_minmax.config)\n",
    "println(\"Sensib:\",winner_minmax.sens)\n",
    "println(\"Acc(%):\",winner_minmax.acc)\n",
    "println(\"Time(s):\",winner_minmax.time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3908785-e5d4-4d6a-815a-85c8c410477a",
   "metadata": {},
   "source": [
    "## Approach 2: Principal Component Analysis (PCA)\n",
    "\n",
    "**Objective:** Reduce the dimensionality of the dataset to remove noise and improve training speed, while retaining the most important information.\n",
    "\n",
    "**Methodology:**\n",
    "1.  **Z-Score Normalization:** Data is centered (mean=0) and scaled (std=1), which is a prerequisite for PCA.\n",
    "2.  **Dimensionality Reduction:** We apply **PCA** to project the original features into a smaller set of **Principal Components** that explain 95% of the variance.\n",
    "3.  **SVM Training:** The SVM is trained on these transformed components. This often creates smoother decision boundaries and reduces the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d2170e-7b53-44a4-abd4-0ee648568dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJMultivariateStatsInterface ✔\n",
      ">>> Loading data from: heart_disease_uci.csv\n",
      "  Original Size: (920, 14)\n",
      " Categorical Null values replaced with ---> 'missingval'.\n",
      "  Deleted rows in features: [:trestbps, :chol, :thalch, :oldpeak]\n",
      "  Final shape: (827, 14)\n",
      "------------------------\n",
      "\n",
      "--- init Preprocess ---\n",
      "   Normalization: zscore\n",
      "    Stratigfied HoldOut split: 577 train, 125 val, 125 test\n",
      "    Normalizing numerical features...\n",
      "    ...Normalization completed.\n",
      "    Encoding categorical features (OHE)...\n",
      "    ...OHE completed.\n",
      "    Concatenate numerical and categorical matrices...\n",
      "    Classes stored for the target: [0, 1, 2, 3, 4]\n",
      "--- PREPROCESS END SUCCESFULLY ---\n",
      "\n",
      "---data preprocessed---\n",
      "\n",
      "---Init PCA transformation---\n",
      " Train set size: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(702, 31)\n",
      "Train set size: after PCA: (702, 17)\n",
      ">> Ejecutando SVM - Approach 2 (PCA)\n",
      "\n",
      "=================================================================\n",
      " EXPERIMENT: APPROACH 2: PCA (Manual Train/Test)\n",
      "=================================================================\n",
      "   [Auto-Fix] Transponiendo matriz para formato LIBSVM (Features x Samples)...\n",
      "   Dimensiones finales X_train: (17, 702)\n",
      " Testing Config 1/8: RBF (C=1000000, G=0.03) ... Done. Sens: 0.3207 | Acc: 50.4%\n",
      " Testing Config 2/8: RBF (C=5000, G=0.07) ... Done. Sens: 0.383 | Acc: 53.6%\n",
      " Testing Config 3/8: RBF (C=100000.0, G=0.5) ... Done. Sens: 0.3511 | Acc: 56.8%\n",
      " Testing Config 4/8: Linear (C=1000) ... Done. Sens: 0.4201 | Acc: 50.4%\n",
      " Testing Config 5/8: Poly (Deg=2, C=10000.0, Coef=1.0) ... Done. Sens: 0.2725 | Acc: 44.8%\n",
      " Testing Config 6/8: Poly (Deg=5, C=10000.0, Coef=1.0) ... Done. Sens: 0.2984 | Acc: 48.0%\n",
      " Testing Config 7/8: Sigmoid (C=100.0, G=0.01) ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: reaching max number of iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Sens: 0.4201 | Acc: 50.4%\n",
      " Testing Config 8/8: Sigmoid (C=1000.0, G=0.01) ... Done. Sens: 0.3358 | Acc: 52.0%\n",
      "\n",
      "\n",
      "****************************************************************\n",
      "      WINNER FOR APPROACH 2: PCA\n",
      "****************************************************************\n",
      "Approach: MinMax\n",
      "Best Config:(\"Linear (C=1000)\", LIBSVM.Kernel.Linear, 1000.0, 0.0, 0)\n",
      "Sensib:0.42007128007128003\n",
      "Acc(%):50.4\n",
      "Time(s):14.636384963989258\n"
     ]
    }
   ],
   "source": [
    "using MLJMultivariateStatsInterface\n",
    "PCA = MLJ.@load PCA pkg=MultivariateStats\n",
    "\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "\n",
    "data, num_col, cat_col, target_col = load_and_clean_data(data_path)\n",
    "\n",
    "approach_2 = prepare_data(\n",
    "    data,         \n",
    "    num_col,       \n",
    "    cat_col,       \n",
    "    target_col,    \n",
    "    norm_method=:zscore \n",
    ")\n",
    "\n",
    "println(\"\\n---data preprocessed---\")\n",
    "\n",
    "println(\"\\n---Init PCA transformation---\")\n",
    "\n",
    "\n",
    "#Unpack variables for MLJ\n",
    "x_train = approach_2.x_train\n",
    "x_val = approach_2.x_val\n",
    "x_test = approach_2.x_test\n",
    "\n",
    "y_train_pca = approach_2.y_train_cat \n",
    "y_val_pca = approach_2.y_val_cat     \n",
    "y_test_pca = approach_2.y_test_cat     \n",
    "\n",
    "# Combine Train + Val (to adjust PCA) for models != ANN, for ANN take this into account\n",
    "x_train_val_combined = vcat(x_train, x_val)\n",
    "y_train_val_combined = vcat(y_train_pca, y_val_pca)\n",
    "\n",
    "println(\" Train set size: \", size(x_train_val_combined))\n",
    "\n",
    "\n",
    "# Use PCA to select the components that explain 95% of the variance\n",
    "pca_model = PCA(variance_ratio=0.95)\n",
    "\n",
    "#1 Adjust the PCA only with the training data\n",
    "pca_machine = machine(pca_model, MLJ.table(x_train_val_combined))\n",
    "MLJ.fit!(pca_machine, verbosity=0)\n",
    "\n",
    "#2 transform data\n",
    "x_train_val_pca = MLJ.transform(pca_machine, MLJ.table(x_train_val_combined))\n",
    "\n",
    "x_test_pca = MLJ.transform(pca_machine, MLJ.table(x_test))\n",
    "\n",
    "#For MLJ is better to pass the data as table\n",
    "#To see data as matrix use: mat_train_pca = MLJ.matrix(x_train_val_pca)\n",
    "# Para ver los datos transformados como matriz:\n",
    "mat_train_pca = MLJ.matrix(x_train_val_pca)\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------\n",
    "mat_test_pca = MLJ.matrix(x_test_pca)\n",
    "println(\"Train set size: after PCA: \", size(mat_train_pca))\n",
    "\n",
    "\n",
    "println(\">> Ejecutando SVM - Approach 2 (PCA)\")\n",
    "\n",
    "winner_pca = run_svm_experiment(\n",
    "    mat_train_pca,      # Matriz de Training\n",
    "    y_train_val_combined,  # Etiquetas de Training (si son categóricas, la función las convierte)\n",
    "    mat_test_pca,       # Matriz de Test\n",
    "    y_test_pca,   # Etiquetas de Test\n",
    "    \"APPROACH 2: PCA\",\n",
    "    svm_configs\n",
    ")\n",
    "\n",
    "# Final Summary\n",
    "println(\"\\n\\n****************************************************************\")\n",
    "println(\"      WINNER FOR APPROACH 2: PCA\")\n",
    "println(\"****************************************************************\")\n",
    "println(\"Approach: MinMax\")\n",
    "println(\"Best Config:\",winner_pca.config)\n",
    "println(\"Sensib:\",winner_pca.sens)\n",
    "println(\"Acc(%):\",winner_pca.acc)\n",
    "println(\"Time(s):\",winner_pca.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a543009c-f27c-4afd-b43e-3858b628b0b2",
   "metadata": {},
   "source": [
    "## Approach 3: Independent Component Analysis (ICA)\n",
    "\n",
    "**Objective:** Transform the feature space to find statistically independent sources, which might correspond to underlying physiological factors of heart disease.\n",
    "\n",
    "**Methodology:**\n",
    "1.  **Transformation:** We use **ICA (FastICA)** to decompose the multivariate signal into independent non-Gaussian components.\n",
    "2.  **Rationale:** Unlike PCA (which focuses on variance/correlation), ICA focuses on independence. In medical datasets, this can sometimes reveal hidden structures or \"causes\" that are useful for classification.\n",
    "3.  **Kernel Selection:** Since ICA transforms the geometry of the data significantly, we test kernels like **Polynomial** and **Sigmoid** in addition to RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "598c32a5-c408-4c5f-b33e-7243f9a4ea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJMultivariateStatsInterface ✔\n",
      ">>> Loading data from: heart_disease_uci.csv\n",
      "  Original Size: (920, 14)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Categorical Null values replaced with ---> 'missingval'.\n",
      "  Deleted rows in features: [:trestbps, :chol, :thalch, :oldpeak]\n",
      "  Final shape: (827, 14)\n",
      "------------------------\n",
      "\n",
      "Init approach 3, ICA (Numerical features only)...\n",
      "\n",
      "--- init Preprocess ---\n",
      "   Normalization: zscore\n",
      "    Stratigfied HoldOut split: 577 train, 125 val, 125 test\n",
      "    Normalizing numerical features...\n",
      "    ...Normalization completed.\n",
      "    Encoding categorical features (OHE)...\n",
      "    ...OHE completed.\n",
      "    Concatenate numerical and categorical matrices...\n",
      "    Classes stored for the target: [0, 1, 2, 3, 4]\n",
      "--- PREPROCESS END SUCCESFULLY ---\n",
      " ICA with k=2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ICA(outdim = 2, …), …).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Preparando datos ICA para LIBSVM...\n",
      "\n",
      ">> Ejecutando SVM - Approach 3 (ICA)\n",
      "\n",
      "=================================================================\n",
      " EXPERIMENT: APPROACH 3: ICA + ZSCORE (Manual Train/Test)\n",
      "=================================================================\n",
      "   Dimensiones finales X_train: (28, 702)\n",
      " Testing Config 1/8: RBF (C=1000000, G=0.03) ... Done. Sens: 0.3123 | Acc: 51.2%\n",
      " Testing Config 2/8: RBF (C=5000, G=0.07) ... Done. Sens: 0.3158 | Acc: 52.8%\n",
      " Testing Config 3/8: RBF (C=100000.0, G=0.5) ... Done. Sens: 0.2994 | Acc: 49.6%\n",
      " Testing Config 4/8: Linear (C=1000) ... Done. Sens: 0.3546 | Acc: 55.2%\n",
      " Testing Config 5/8: Poly (Deg=2, C=10000.0, Coef=1.0) ... Done. Sens: 0.3015 | Acc: 49.6%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: reaching max number of iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing Config 6/8: Poly (Deg=5, C=10000.0, Coef=1.0) ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: reaching max number of iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Sens: 0.2817 | Acc: 42.4%\n",
      " Testing Config 7/8: Sigmoid (C=100.0, G=0.01) ... Done. Sens: 0.3546 | Acc: 55.2%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: reaching max number of iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing Config 8/8: Sigmoid (C=1000.0, G=0.01) ... Done. Sens: 0.3545 | Acc: 54.4%\n",
      "\n",
      "\n",
      "****************************************************************\n",
      "      WINNER FOR APPROACH 3: ICA\n",
      "****************************************************************\n",
      "Approach: MinMax\n",
      "Best Config:(\"Linear (C=1000)\", LIBSVM.Kernel.Linear, 1000.0, 0.0, 0)\n",
      "Sensib:0.3545792495792496\n",
      "Acc(%):55.2\n",
      "Time(s):16.113850831985474\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# (Aproach 3) ICA and z-score (ICA just in numerical features , if we use it with the caegorical ones it wouldn't find a solution) \n",
    "# -----------------------------------------------------------------\n",
    "using MLJMultivariateStatsInterface\n",
    "ICA = MLJ.@load ICA pkg=MultivariateStats\n",
    "\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "\n",
    "data, num_col, cat_col, target_col = load_and_clean_data(data_path)\n",
    "\n",
    "\n",
    "println(\"\\nInit approach 3, ICA (Numerical features only)...\")\n",
    "\n",
    "# 1. Preprocess as previous aproach ( Z-Score, ideal for ICA\n",
    "approach_ica = prepare_data(\n",
    "    data,          \n",
    "    num_col,       \n",
    "    cat_col,       \n",
    "    target_col,    \n",
    "    norm_method=:zscore \n",
    ")\n",
    "\n",
    "# 2. Unpack results\n",
    "x_train = approach_ica.x_train\n",
    "x_val = approach_ica.x_val\n",
    "x_test = approach_ica.x_test\n",
    "\n",
    "y_train_ica = approach_ica.y_train_cat \n",
    "y_val_ica = approach_ica.y_val_cat     \n",
    "y_test_ica = approach_ica.y_test_cat;\n",
    "\n",
    "# Our function  'prepare_data'order first numerical fetures and then categorical ones.\n",
    "\n",
    "n_num = length(num_col) # Should be (age, trestbps, chol, thalch, oldpeak)\n",
    "\n",
    "#Split \n",
    "x_num_train = x_train[:, 1:n_num]      # Just numerical \n",
    "x_cat_train = x_train[:, n_num+1:end]  # Just categorical OHE\n",
    "\n",
    "x_num_val = x_val[:, 1:n_num]\n",
    "x_cat_val = x_val[:, n_num+1:end]\n",
    "x_num_test = x_test[:, 1:n_num]\n",
    "x_cat_test = x_test[:, n_num+1:end]\n",
    "\n",
    "\n",
    "# --- ICA just for numerical ---\n",
    "\n",
    "# k should be less or equal than umber of features (5)\n",
    "k_components = 2\n",
    "\n",
    "#Random.seed!(1234)#ICA is a no deterministic method so we fix the seed for reproducibility. But somehow fail \n",
    "# Give some tolerance for the solution\n",
    "ica_model = ICA(outdim=k_components, maxiter=100000, tol=0.2) \n",
    "\n",
    "println(\" ICA with k=$k_components ...\")\n",
    "\n",
    "# Fit only the numerical data from training set, for ANN\n",
    "ica_machine = machine(ica_model, MLJ.table(x_num_train))\n",
    "MLJ.fit!(ica_machine, verbosity=1) # verbosity=1 for debug\n",
    "\n",
    "\"\"\"\n",
    "#for models != ANN:\n",
    "x_train_val_num=vcat(x_num_train, x_num_val)\n",
    "#fit on both, training and validation\n",
    "ica_machine = machine(ica_model, MLJ.table(x_train_val_num))\n",
    "MLJ.fit!(ica_machine, verbosity=1) # verbosity=1 for debug\n",
    "\"\"\"\n",
    "\n",
    "# Transform and return to matrix\n",
    "x_num_train_ica = MLJ.transform(ica_machine, MLJ.table(x_num_train))\n",
    "x_num_val_ica  = MLJ.transform(ica_machine, MLJ.table(x_num_val))\n",
    "x_num_test_ica  = MLJ.transform(ica_machine, MLJ.table(x_num_test))\n",
    "\n",
    "\n",
    "mat_train_ica = MLJ.matrix(x_num_train_ica)\n",
    "mat_val_ica  = MLJ.matrix(x_num_val_ica)\n",
    "mat_test_ica  = MLJ.matrix(x_num_test_ica)\n",
    "\n",
    "#Add the categorical OHE \n",
    "x_train_ica = hcat(mat_train_ica, x_cat_train)\n",
    "x_val_ica = hcat(mat_val_ica, x_cat_val)\n",
    "x_test_ica     = hcat(mat_test_ica, x_cat_test)\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# PREPARACIÓN FINAL PARA SVM (APPROACH 3: ICA)\n",
    "# ==============================================================================\n",
    "\n",
    "println(\"\\n>> Preparando datos ICA para LIBSVM...\")\n",
    "\n",
    "# 1. Combinar Train + Validation\n",
    "# SVM funciona mejor con más datos. Unimos las matrices que ya procesaste.\n",
    "x_train_val_ica_combined = vcat(x_train_ica, x_val_ica)\n",
    "y_train_val_ica_combined = vcat(y_train_ica, y_val_ica)\n",
    "\n",
    "# 2. Transponer Matrices (Features x Samples)\n",
    "# LIBSVM es estricto con esto. Convertimos a Float64 y transponemos.\n",
    "x_train_svm_ica = Float64.(permutedims(x_train_val_ica_combined))\n",
    "x_test_svm_ica  = Float64.(permutedims(x_test_ica))\n",
    "\n",
    "# 3. Limpiar Etiquetas\n",
    "# Nos aseguramos de que sean enteros simples (sin envoltorios CategoricalValue)\n",
    "get_val(x) = (typeof(x) <: CategoricalValue) ? unwrap(x) : x\n",
    "\n",
    "y_train_final_ica = vec(Int.(get_val.(y_train_val_ica_combined)))\n",
    "y_test_final_ica  = vec(Int.(get_val.(y_test_ica)))\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURACIÓN Y EJECUCIÓN\n",
    "# ==============================================================================\n",
    "\n",
    "println(\"\\n>> Ejecutando SVM - Approach 3 (ICA)\")\n",
    "\n",
    "winner_ica = run_svm_experiment(\n",
    "    x_train_svm_ica,      # X Train (Combinado y transpuesto)\n",
    "    y_train_final_ica,    # Y Train (Combinado y limpio)\n",
    "    x_test_svm_ica,       # X Test (Transpuesto)\n",
    "    y_test_final_ica,     # Y Test (Limpio)\n",
    "    \"APPROACH 3: ICA + ZSCORE\",\n",
    "    svm_configs\n",
    ")\n",
    "\n",
    "# Final Summary\n",
    "println(\"\\n\\n****************************************************************\")\n",
    "println(\"      WINNER FOR APPROACH 3: ICA\")\n",
    "println(\"****************************************************************\")\n",
    "println(\"Approach: MinMax\")\n",
    "println(\"Best Config:\",winner_ica.config)\n",
    "println(\"Sensib:\",winner_ica.sens)\n",
    "println(\"Acc(%):\",winner_ica.acc)\n",
    "println(\"Time(s):\",winner_ica.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27b842b-d681-49a4-a4bf-d32a6188ef63",
   "metadata": {},
   "source": [
    "## Approach 4: MinMax + Stratified Cross-Validation\n",
    "\n",
    "**Objective:** Validate the robustness of our Baseline (Approach 1) and ensure the results are not due to a lucky train/test split.\n",
    "\n",
    "**Methodology:**\n",
    "* **Stratified K-Fold CV ($k=5$):** The dataset is divided into 5 folds, ensuring each fold maintains the same proportion of Sick/Healthy patients.\n",
    "* **Process:** For each fold, we re-apply MinMax normalization and One-Hot Encoding from scratch to avoid data leakage.\n",
    "* **Selection:** We average the metrics across all folds to find the most stable hyperparameter configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "641e7dd1-2aaf-4b77-9a43-d5b41a19d740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading data from: heart_disease_uci.csv\n",
      "  Original Size: (920, 14)\n",
      " Categorical Null values replaced with ---> 'missingval'.\n",
      "  Deleted rows in features: [:trestbps, :chol, :thalch, :oldpeak]\n",
      "  Final shape: (827, 14)\n",
      "------------------------\n",
      "  Data split: 702 dev(85%), 125 test(15%)\n",
      "Indices generated for 5 stratified folds.\n",
      "Evaluando 8 configuraciones...\n",
      "Evaluando 8 configuraciones...\n",
      "[1/8] Probando SVC con RBF (C=1000000, G=0.03) ... -> Acc: 54.73%\n",
      "[2/8] Probando SVC con RBF (C=5000, G=0.07) ... -> Acc: 54.57%\n",
      "[3/8] Probando SVC con RBF (C=100000.0, G=0.5) ... -> Acc: 55.99%\n",
      "[4/8] Probando SVC con Linear (C=1000) ... -> Acc: 55.0%\n",
      "[5/8] Probando SVC con Poly (Deg=2, C=10000.0, Coef=1.0) ... -> Acc: 54.15%\n",
      "[6/8] Probando SVC con Poly (Deg=5, C=10000.0, Coef=1.0) ... -> Acc: 55.13%\n",
      "[7/8] Probando SVC con Sigmoid (C=100.0, G=0.01) ... -> Acc: 55.0%\n",
      "[8/8] Probando SVC con Sigmoid (C=1000.0, G=0.01) ... -> Acc: 55.14%\n",
      "\n",
      "--- TOP 10 MEJORES MODELOS ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>8×4 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">ModelType</th><th style = \"text-align: left;\">Hyperparams</th><th style = \"text-align: left;\">Mean_Accuracy</th><th style = \"text-align: left;\">Std_Accuracy</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 0.5, :degree =&gt; 0, :kernel =&gt; &quot;rbf&quot;, :C =&gt; 100000.0)</td><td style = \"text-align: right;\">55.986</td><td style = \"text-align: right;\">3.23921</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 0.01, :degree =&gt; 0, :kernel =&gt; &quot;rbf&quot;, :C =&gt; 1000.0)</td><td style = \"text-align: right;\">55.139</td><td style = \"text-align: right;\">1.85978</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 1.0, :degree =&gt; 5, :kernel =&gt; &quot;poly&quot;, :C =&gt; 10000.0)</td><td style = \"text-align: right;\">55.1318</td><td style = \"text-align: right;\">3.90574</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 0.01, :degree =&gt; 0, :kernel =&gt; &quot;linear&quot;, :C =&gt; 100.0)</td><td style = \"text-align: right;\">55.0022</td><td style = \"text-align: right;\">2.73517</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 0.0, :degree =&gt; 0, :kernel =&gt; &quot;linear&quot;, :C =&gt; 1000.0)</td><td style = \"text-align: right;\">55.0002</td><td style = \"text-align: right;\">2.53162</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 0.03, :degree =&gt; 0, :kernel =&gt; &quot;rbf&quot;, :C =&gt; 1.0e6)</td><td style = \"text-align: right;\">54.7285</td><td style = \"text-align: right;\">5.85846</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 0.07, :degree =&gt; 0, :kernel =&gt; &quot;rbf&quot;, :C =&gt; 5000.0)</td><td style = \"text-align: right;\">54.5705</td><td style = \"text-align: right;\">3.58129</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 1.0, :degree =&gt; 2, :kernel =&gt; &quot;poly&quot;, :C =&gt; 10000.0)</td><td style = \"text-align: right;\">54.15</td><td style = \"text-align: right;\">4.97851</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& ModelType & Hyperparams & \\\\\n",
       "\t\\hline\n",
       "\t& String & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 0.5, :degree => 0, :kernel => \"rbf\", :C => 100000.0) & $\\dots$ \\\\\n",
       "\t2 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 0.01, :degree => 0, :kernel => \"rbf\", :C => 1000.0) & $\\dots$ \\\\\n",
       "\t3 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 1.0, :degree => 5, :kernel => \"poly\", :C => 10000.0) & $\\dots$ \\\\\n",
       "\t4 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 0.01, :degree => 0, :kernel => \"linear\", :C => 100.0) & $\\dots$ \\\\\n",
       "\t5 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 0.0, :degree => 0, :kernel => \"linear\", :C => 1000.0) & $\\dots$ \\\\\n",
       "\t6 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 0.03, :degree => 0, :kernel => \"rbf\", :C => 1.0e6) & $\\dots$ \\\\\n",
       "\t7 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 0.07, :degree => 0, :kernel => \"rbf\", :C => 5000.0) & $\\dots$ \\\\\n",
       "\t8 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 1.0, :degree => 2, :kernel => \"poly\", :C => 10000.0) & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m8×4 DataFrame\n",
       "\u001b[1m Row │\u001b[1m ModelType \u001b[1m Hyperparams                       \u001b[1m Mean_Accuracy \u001b[1m Std_Accura ⋯\n",
       "     │\u001b[90m String    \u001b[90m String                            \u001b[90m Float64       \u001b[90m Float64    ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ SVC        Dict{Symbol, Any}(:coef0 => 0.0,…        55.986        3.239 ⋯\n",
       "   2 │ SVC        Dict{Symbol, Any}(:coef0 => 0.0,…        55.139        1.859\n",
       "   3 │ SVC        Dict{Symbol, Any}(:coef0 => 0.0,…        55.1318       3.905\n",
       "   4 │ SVC        Dict{Symbol, Any}(:coef0 => 0.0,…        55.0022       2.735\n",
       "   5 │ SVC        Dict{Symbol, Any}(:coef0 => 0.0,…        55.0002       2.531 ⋯\n",
       "   6 │ SVC        Dict{Symbol, Any}(:coef0 => 0.0,…        54.7285       5.858\n",
       "   7 │ SVC        Dict{Symbol, Any}(:coef0 => 0.0,…        54.5705       3.581\n",
       "   8 │ SVC        Dict{Symbol, Any}(:coef0 => 0.0,…        54.15         4.978\n",
       "\u001b[36m                                                                1 column omitted"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GANADOR DEL APPROACH 4:\n",
      "Modelo: SVC\n",
      "Config: Dict{Symbol, Any}(:coef0 => 0.0, :gamma => 0.5, :degree => 0, :kernel => \"rbf\", :C => 100000.0)\n",
      "Accuracy CV: 55.99% ± 3.24\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# (Aproach 4) Same as approach 1 with corssvalidation \n",
    "# -----------------------------------------------------------------\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "data, num_col, cat_col, target_col = load_and_clean_data(data_path)\n",
    "Random.seed!(1234)\n",
    "#---split training data and final test data---\n",
    "Pval = 0.15\n",
    "Ptest = 0.15\n",
    "rows, columns = size(data)\n",
    "N = rows\n",
    "(train_indices, val_indices, test_indices) = stratified_holdOut(data[!,target_col], Pval, Ptest)\n",
    "train_data = data[train_indices, :]\n",
    "val_data = data[val_indices, :]\n",
    "dev_data = vcat(train_data, val_data)\n",
    "test_data = data[test_indices, :]\n",
    "println(\"  Data split: $(size(dev_data,1)) dev(85%), $(size(test_data,1)) test(15%)\")\n",
    "\n",
    "#---split for crossvalidation---\n",
    "dev_num = select(dev_data, num_col)\n",
    "dev_cat = select(dev_data, cat_col)\n",
    "dev_targets = dev_data[!, target_col];\n",
    "\n",
    "#---make cv indices---\n",
    "k_folds=5 #numebr of folds, set to 5 as our dataset is small\n",
    "cv_indices = crossvalidation(dev_targets, k_folds);\n",
    "println(\"Indices generated for $k_folds stratified folds.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "println(\"Evaluando $(length(svm_configs)) configuraciones...\")\n",
    "\n",
    "# ... (código anterior de carga de datos igual) ...\n",
    "\n",
    "results_grid = DataFrame(\n",
    "    ModelType = String[], \n",
    "    Hyperparams = String[], \n",
    "    Mean_Accuracy = Float64[], \n",
    "    Std_Accuracy = Float64[]\n",
    ")\n",
    "\n",
    "println(\"Evaluando $(length(svm_configs)) configuraciones...\")\n",
    "\n",
    "for (i, conf) in enumerate(svm_configs)\n",
    "    # Desempaquetar tu tupla de configuración\n",
    "    # Asumiendo formato: (Nombre, Kernel, C, Gamma, Degree)\n",
    "    # Si tienes 6 elementos (con coef0), ajusta esto.\n",
    "    if length(conf) == 5\n",
    "        (name, k_type, c_val, g_val, deg_val) = conf\n",
    "        coef_val = 0.0\n",
    "    else\n",
    "        (name, k_type, c_val, g_val, deg_val, coef_val) = conf\n",
    "    end\n",
    "    \n",
    "    # CONVERSIÓN CRÍTICA: Crear el Diccionario que espera la función\n",
    "    # Necesitamos mapear tus tipos de Kernel de LIBSVM a Strings si la función interna lo requiere,\n",
    "    # o pasarlos tal cual si la función sabe manejarlos.\n",
    "    # Viendo el código de universalCrossValidation1, parece esperar :C, :kernel, etc.\n",
    "    \n",
    "    # Mapeo inverso de Kernel a String (por si acaso la función usa strings)\n",
    "    k_str = if k_type == Kernel.Linear; \"linear\"\n",
    "            elseif k_type == Kernel.RadialBasis; \"rbf\"\n",
    "            elseif k_type == Kernel.Polynomial; \"poly\"\n",
    "            elseif k_type == Kernel.Sigmoid; \"sigmoid\"\n",
    "            else; \"rbf\"; end\n",
    "\n",
    "    params_dict = Dict(\n",
    "        :C => c_val,\n",
    "        :kernel => k_str,\n",
    "        :gamma => g_val,\n",
    "        :degree => deg_val,\n",
    "        :coef0 => coef_val\n",
    "    )\n",
    "    \n",
    "    param_str = string(params_dict)\n",
    "    print(\"[$i/$(length(svm_configs))] Probando SVC con $name ... \")\n",
    "    \n",
    "    # LLAMADA CORREGIDA\n",
    "    try\n",
    "        mu, sigma = universalCrossValidation1(\n",
    "            :SVC,          # PASAR COMO SYMBOL (:SVC), NO STRING\n",
    "            params_dict,   # PASAR COMO DICT, NO TUPLA\n",
    "            dev_num, \n",
    "            dev_cat, \n",
    "            dev_targets, \n",
    "            cv_indices\n",
    "        )\n",
    "        \n",
    "        push!(results_grid, (\"SVC\", param_str, mu * 100, sigma * 100))\n",
    "        println(\"-> Acc: $(round(mu*100, digits=2))%\")\n",
    "        \n",
    "    catch e\n",
    "        println(\" Falló: $e\")\n",
    "    end\n",
    "end\n",
    "\n",
    "# ... (Resto del código de resultados igual) ...\n",
    "\n",
    "# 3. RESULTADOS Y MEJOR MODELO\n",
    "println(\"\\n--- TOP 10 MEJORES MODELOS ---\")\n",
    "sort!(results_grid, :Mean_Accuracy, rev=true)\n",
    "display(first(results_grid, 10))\n",
    "\n",
    "# Extraer el ganador\n",
    "best_row = results_grid[1, :]\n",
    "println(\"\\n GANADOR DEL APPROACH 4:\")\n",
    "println(\"Modelo: $(best_row.ModelType)\")\n",
    "println(\"Config: $(best_row.Hyperparams)\")\n",
    "println(\"Accuracy CV: $(round(best_row.Mean_Accuracy, digits=2))% ± $(round(best_row.Std_Accuracy, digits=2))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5177ee-ccc4-4e82-bad8-e4cafb8bd9c1",
   "metadata": {},
   "source": [
    "## Approach 5: PCA + Stratified Cross-Validation\n",
    "\n",
    "**Objective:** Combine the benefits of dimensionality reduction (PCA) with the statistical robustness of Cross-Validation.\n",
    "\n",
    "**Methodology:**\n",
    "* **Pipeline:** Inside each step of the Cross-Validation loop:\n",
    "    1.  **Z-Score** parameters are learned from the training fold.\n",
    "    2.  **PCA** projection matrix is calculated on the training fold.\n",
    "    3.  The validation fold is transformed using these learned parameters.\n",
    "* **Goal:** This approach provides the most rigorous evaluation of whether dimensionality reduction truly helps the SVM generalize better to unseen patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c933e27-b903-4109-afe5-bd1fc1faddb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading data from: heart_disease_uci.csv\n",
      "  Original Size: (920, 14)\n",
      " Categorical Null values replaced with ---> 'missingval'.\n",
      "  Deleted rows in features: [:trestbps, :chol, :thalch, :oldpeak]\n",
      "  Final shape: (827, 14)\n",
      "------------------------\n",
      "  Data split: 702 dev(85%), 125 test(15%)\n",
      "Indices generated for 5 stratified folds.\n",
      "[1/8] Probando SVC con RBF (C=1000000, G=0.03) ... -> Acc: 52.44%\n",
      "[2/8] Probando SVC con RBF (C=5000, G=0.07) ... -> Acc: 53.29%\n",
      "[3/8] Probando SVC con RBF (C=100000.0, G=0.5) ... -> Acc: 54.99%\n",
      "[4/8] Probando SVC con Linear (C=1000) ... -> Acc: 56.41%\n",
      "[5/8] Probando SVC con Poly (Deg=2, C=10000.0, Coef=1.0) ... -> Acc: 49.6%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: reaching max number of iterations\n",
      "\n",
      "WARNING: reaching max number of iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/8] Probando SVC con Poly (Deg=5, C=10000.0, Coef=1.0) ... -> Acc: 54.99%\n",
      "[7/8] Probando SVC con Sigmoid (C=100.0, G=0.01) ... -> Acc: 56.41%\n",
      "[8/8] Probando SVC con Sigmoid (C=1000.0, G=0.01) ... -> Acc: 56.27%\n",
      "\n",
      "--- Ranking Approach 5 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>8×4 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Model</th><th style = \"text-align: left;\">Params</th><th style = \"text-align: left;\">Acc_Mean</th><th style = \"text-align: left;\">Acc_Std</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 0.0, :degree =&gt; 0, :kernel =&gt; &quot;linear&quot;, :C =&gt; 1000.0)</td><td style = \"text-align: left;\">56.4106</td><td style = \"text-align: left;\">2.29659</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 0.01, :degree =&gt; 0, :kernel =&gt; &quot;linear&quot;, :C =&gt; 100.0)</td><td style = \"text-align: left;\">56.4106</td><td style = \"text-align: left;\">2.29659</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 0.01, :degree =&gt; 0, :kernel =&gt; &quot;rbf&quot;, :C =&gt; 1000.0)</td><td style = \"text-align: left;\">56.2687</td><td style = \"text-align: left;\">3.56011</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 1.0, :degree =&gt; 5, :kernel =&gt; &quot;poly&quot;, :C =&gt; 10000.0)</td><td style = \"text-align: left;\">54.9911</td><td style = \"text-align: left;\">3.65772</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 0.5, :degree =&gt; 0, :kernel =&gt; &quot;rbf&quot;, :C =&gt; 100000.0)</td><td style = \"text-align: left;\">54.9879</td><td style = \"text-align: left;\">3.20739</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 0.07, :degree =&gt; 0, :kernel =&gt; &quot;rbf&quot;, :C =&gt; 5000.0)</td><td style = \"text-align: left;\">53.2858</td><td style = \"text-align: left;\">2.63328</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 0.03, :degree =&gt; 0, :kernel =&gt; &quot;rbf&quot;, :C =&gt; 1.0e6)</td><td style = \"text-align: left;\">52.4377</td><td style = \"text-align: left;\">4.51294</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:coef0 =&gt; 0.0, :gamma =&gt; 1.0, :degree =&gt; 2, :kernel =&gt; &quot;poly&quot;, :C =&gt; 10000.0)</td><td style = \"text-align: left;\">49.5977</td><td style = \"text-align: left;\">4.37313</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& Model & Params & \\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & \\\\\n",
       "\t\\hline\n",
       "\t1 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 0.0, :degree => 0, :kernel => \"linear\", :C => 1000.0) & $\\dots$ \\\\\n",
       "\t2 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 0.01, :degree => 0, :kernel => \"linear\", :C => 100.0) & $\\dots$ \\\\\n",
       "\t3 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 0.01, :degree => 0, :kernel => \"rbf\", :C => 1000.0) & $\\dots$ \\\\\n",
       "\t4 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 1.0, :degree => 5, :kernel => \"poly\", :C => 10000.0) & $\\dots$ \\\\\n",
       "\t5 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 0.5, :degree => 0, :kernel => \"rbf\", :C => 100000.0) & $\\dots$ \\\\\n",
       "\t6 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 0.07, :degree => 0, :kernel => \"rbf\", :C => 5000.0) & $\\dots$ \\\\\n",
       "\t7 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 0.03, :degree => 0, :kernel => \"rbf\", :C => 1.0e6) & $\\dots$ \\\\\n",
       "\t8 & SVC & Dict\\{Symbol, Any\\}(:coef0 => 0.0, :gamma => 1.0, :degree => 2, :kernel => \"poly\", :C => 10000.0) & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m8×4 DataFrame\n",
       "\u001b[1m Row │\u001b[1m Model \u001b[1m Params                            \u001b[1m Acc_Mean \u001b[1m Acc_Std\n",
       "     │\u001b[90m Any   \u001b[90m Any                               \u001b[90m Any      \u001b[90m Any\n",
       "─────┼─────────────────────────────────────────────────────────────\n",
       "   1 │ SVC    Dict{Symbol, Any}(:coef0 => 0.0,…  56.4106   2.29659\n",
       "   2 │ SVC    Dict{Symbol, Any}(:coef0 => 0.0,…  56.4106   2.29659\n",
       "   3 │ SVC    Dict{Symbol, Any}(:coef0 => 0.0,…  56.2687   3.56011\n",
       "   4 │ SVC    Dict{Symbol, Any}(:coef0 => 0.0,…  54.9911   3.65772\n",
       "   5 │ SVC    Dict{Symbol, Any}(:coef0 => 0.0,…  54.9879   3.20739\n",
       "   6 │ SVC    Dict{Symbol, Any}(:coef0 => 0.0,…  53.2858   2.63328\n",
       "   7 │ SVC    Dict{Symbol, Any}(:coef0 => 0.0,…  52.4377   4.51294\n",
       "   8 │ SVC    Dict{Symbol, Any}(:coef0 => 0.0,…  49.5977   4.37313"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GANADOR DEL APPROACH 5:\n",
      "Modelo: SVC\n",
      "Config: Dict{Symbol, Any}(:coef0 => 0.0, :gamma => 0.0, :degree => 0, :kernel => \"linear\", :C => 1000.0)\n",
      "Accuracy CV: 56.41% ± 2.3\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# (Aproach 5) PCA with corssvalidation \n",
    "# -----------------------------------------------------------------\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "data, num_col, cat_col, target_col = load_and_clean_data(data_path)\n",
    "Random.seed!(1234)\n",
    "#---split training data and final test data---\n",
    "Pval = 0.15\n",
    "Ptest = 0.15\n",
    "rows, columns = size(data)\n",
    "N = rows\n",
    "(train_indices, val_indices, test_indices) = stratified_holdOut(data[!,target_col], Pval, Ptest)\n",
    "train_data = data[train_indices, :]\n",
    "val_data = data[val_indices, :]\n",
    "dev_data = vcat(train_data, val_data)\n",
    "test_data = data[test_indices, :]\n",
    "println(\"  Data split: $(size(dev_data,1)) dev(85%), $(size(test_data,1)) test(15%)\")\n",
    "\n",
    "#---split for crossvalidation---\n",
    "dev_num = select(dev_data, num_col)\n",
    "dev_cat = select(dev_data, cat_col)\n",
    "dev_targets = dev_data[!, target_col];\n",
    "\n",
    "#---make cv indices---\n",
    "k_folds=5 #numebr of folds, set to 5 as our dataset is small\n",
    "cv_indices = crossvalidation(dev_targets, k_folds);\n",
    "println(\"Indices generated for $k_folds stratified folds.\")\n",
    "\n",
    "\n",
    "\n",
    "results_pca = DataFrame(Model=[], Params=[], Acc_Mean=[], Acc_Std=[])\n",
    "\n",
    "for (i, conf) in enumerate(svm_configs)\n",
    "    # Desempaquetar tu tupla de configuración\n",
    "    # Asumiendo formato: (Nombre, Kernel, C, Gamma, Degree)\n",
    "    # Si tienes 6 elementos (con coef0), ajusta esto.\n",
    "    if length(conf) == 5\n",
    "        (name, k_type, c_val, g_val, deg_val) = conf\n",
    "        coef_val = 0.0\n",
    "    else\n",
    "        (name, k_type, c_val, g_val, deg_val, coef_val) = conf\n",
    "    end\n",
    "    \n",
    "    # CONVERSIÓN CRÍTICA: Crear el Diccionario que espera la función\n",
    "    # Necesitamos mapear tus tipos de Kernel de LIBSVM a Strings si la función interna lo requiere,\n",
    "    # o pasarlos tal cual si la función sabe manejarlos.\n",
    "    # Viendo el código de universalCrossValidation1, parece esperar :C, :kernel, etc.\n",
    "    \n",
    "    # Mapeo inverso de Kernel a String (por si acaso la función usa strings)\n",
    "    k_str = if k_type == Kernel.Linear; \"linear\"\n",
    "            elseif k_type == Kernel.RadialBasis; \"rbf\"\n",
    "            elseif k_type == Kernel.Polynomial; \"poly\"\n",
    "            elseif k_type == Kernel.Sigmoid; \"sigmoid\"\n",
    "            else; \"rbf\"; end\n",
    "\n",
    "    params_dict = Dict(\n",
    "        :C => c_val,\n",
    "        :kernel => k_str,\n",
    "        :gamma => g_val,\n",
    "        :degree => deg_val,\n",
    "        :coef0 => coef_val\n",
    "    )\n",
    "    \n",
    "    param_str = string(params_dict)\n",
    "    print(\"[$i/$(length(svm_configs))] Probando SVC con $name ... \")\n",
    "    \n",
    "    mu, sigma = universalCrossValidation_PCA(\n",
    "        :SVC, params_dict, \n",
    "        dev_num, dev_cat, dev_targets, \n",
    "        cv_indices\n",
    "    )\n",
    "    \n",
    "    push!(results_pca, (string(:SVC), param_str, mu*100, sigma*100))\n",
    "    println(\"-> Acc: $(round(mu*100, digits=2))%\")\n",
    "end\n",
    "\n",
    "println(\"\\n--- Ranking Approach 5 ---\")\n",
    "sort!(results_pca, :Acc_Mean, rev=true)\n",
    "display(results_pca)\n",
    "\n",
    "# Extraer el ganador\n",
    "best_row = results_pca[1, :]\n",
    "println(\"\\n GANADOR DEL APPROACH 5:\")\n",
    "println(\"Modelo: $(best_row.Model)\")\n",
    "println(\"Config: $(best_row.Params)\")\n",
    "println(\"Accuracy CV: $(round(best_row.Acc_Mean, digits=2))% ± $(round(best_row.Acc_Std, digits=2))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a08c8-2e20-48c0-ad1b-2c016ad7bb6a",
   "metadata": {},
   "source": [
    "# BINARIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e2d3a-39c3-44d9-b5d4-3ab8c12f544b",
   "metadata": {},
   "source": [
    "## 3. Problem Transformation: Binary Classification\n",
    "The original dataset contains 5 classes:\n",
    "* **0:** Healthy\n",
    "* **1-4:** Different severity levels of heart disease.\n",
    "\n",
    "Distinguishing between Severity 1 and Severity 2 is notoriously difficult due to noise and overlap. However, from a clinical triage perspective, the crucial question is: **\"Is the patient sick?\"**\n",
    "\n",
    "**Strategy:**\n",
    "We transform the problem into a **Binary Classification** task:\n",
    "* **Class 0 (Healthy) $\\rightarrow$ 0**\n",
    "* **Classes 1, 2, 3, 4 (Sick) $\\rightarrow$ 1**\n",
    "\n",
    "This simplifies the decision boundary and is expected to significantly boost **Accuracy** and **Sensitivity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "801fff0e-dc92-4dd8-a1a8-211fd635aa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Cargando y limpiando datos originales...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using MultivariateStats.ICA in module Main conflicts with an existing identifier.\n",
      "WARNING: using MultivariateStats.PCA in module Main conflicts with an existing identifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading data from: heart_disease_uci.csv\n",
      "  Original Size: (920, 14)\n",
      " Categorical Null values replaced with ---> 'missingval'.\n",
      "  Deleted rows in features: [:trestbps, :chol, :thalch, :oldpeak]\n",
      "  Final shape: (827, 14)\n",
      "------------------------\n",
      "Clases originales encontradas: [0, 1, 2, 3, 4]\n",
      "\n",
      ">> BINARIZANDO EL DATASET (Sano=0 vs Enfermo=1)...\n",
      "Nuevas clases binarias: [0, 1]\n",
      "Conteo de muestras: \n",
      "  Clase 0 (Sano):   371\n",
      "  Clase 1 (Enfermo): 456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8-element Vector{Tuple{String, LIBSVM.Kernel.KERNEL, Float64, Float64, Int64, Float64}}:\n",
       " (\"RBF (C=1, G=0.1)\", LIBSVM.Kernel.RadialBasis, 1.0, 0.1, 0, 0.0)\n",
       " (\"RBF (C=10, G=0.1)\", LIBSVM.Kernel.RadialBasis, 10.0, 0.1, 0, 0.0)\n",
       " (\"RBF (C=100, G=0.01)\", LIBSVM.Kernel.RadialBasis, 100.0, 0.01, 0, 0.0)\n",
       " (\"RBF (C=1000, G=0.001)\", LIBSVM.Kernel.RadialBasis, 1000.0, 0.001, 0, 0.0)\n",
       " (\"Linear (C=1)\", LIBSVM.Kernel.Linear, 1.0, 0.0, 0, 0.0)\n",
       " (\"Linear (C=10)\", LIBSVM.Kernel.Linear, 10.0, 0.0, 0, 0.0)\n",
       " (\"Poly (D=2, C=1)\", LIBSVM.Kernel.Polynomial, 1.0, 0.1, 2, 1.0)\n",
       " (\"Sigmoid (C=1, G=0.1)\", LIBSVM.Kernel.Sigmoid, 1.0, 0.1, 0, 0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 1. CARGA, LIMPIEZA Y BINARIZACIÓN INICIAL\n",
    "# ==============================================================================\n",
    "using LIBSVM, JLD2, FileIO, Statistics, Printf, Random, CategoricalArrays\n",
    "using DataFrames, CSV, MLJ, MultivariateStats # Y el resto de tus imports...\n",
    "\n",
    "# Incluir tus utilidades (Asumo que existen y funcionan como en el PDF)\n",
    "include(\"SVM_final_utils.jl\")\n",
    "# include(\"preprocess_utils.jl\") # Si es necesario\n",
    "\n",
    "# --- Configuración ---\n",
    "Random.seed!(1234)\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "\n",
    "# --- Carga original ---\n",
    "println(\">> Cargando y limpiando datos originales...\")\n",
    "# Esta función devuelve el dataframe con clases [0,1,2,3,4] en target_col\n",
    "data, num_col, cat_col, target_col = load_and_clean_data(data_path)\n",
    "println(\"Clases originales encontradas: \", sort(unique(data[!, target_col])))\n",
    "\n",
    "# ==============================================================================\n",
    "# --- BLOQUE NUEVO: TRANSFORMACIÓN BINARIA ---\n",
    "# ==============================================================================\n",
    "println(\"\\n>> BINARIZANDO EL DATASET (Sano=0 vs Enfermo=1)...\")\n",
    "\n",
    "# Aplicamos la lógica de tu imagen: Si es > 0 es 1, si no es 0.\n",
    "# Modificamos la columna objetivo directamente en el DataFrame principal.\n",
    "data[!, target_col] = map(y -> y > 0 ? 1 : 0, data[!, target_col])\n",
    "\n",
    "# Verificación\n",
    "classes_bin = sort(unique(data[!, target_col]))\n",
    "println(\"Nuevas clases binarias: \", classes_bin)\n",
    "println(\"Conteo de muestras: \")\n",
    "println(\"  Clase 0 (Sano):   \", count(==(0), data[!, target_col]))\n",
    "println(\"  Clase 1 (Enfermo): \", count(==(1), data[!, target_col]))\n",
    "# ==============================================================================\n",
    "\n",
    "# Definir configuraciones SVM (Sirven las mismas del PDF)\n",
    "svm_configs = [\n",
    "    (\"RBF (C=1, G=0.1)\",    Kernel.RadialBasis, 1.0,    0.1, 0, 0.0),\n",
    "    (\"RBF (C=10, G=0.1)\",   Kernel.RadialBasis, 10.0,   0.1, 0, 0.0),\n",
    "    (\"RBF (C=100, G=0.01)\", Kernel.RadialBasis, 100.0,  0.01, 0, 0.0),\n",
    "    (\"RBF (C=1000, G=0.001)\", Kernel.RadialBasis, 1000.0, 0.001, 0, 0.0),\n",
    "    (\"Linear (C=1)\",        Kernel.Linear,      1.0,    0.0, 0, 0.0),\n",
    "    (\"Linear (C=10)\",       Kernel.Linear,      10.0,   0.0, 0, 0.0),\n",
    "    (\"Poly (D=2, C=1)\",     Kernel.Polynomial,  1.0,    0.1, 2, 1.0),\n",
    "    (\"Sigmoid (C=1, G=0.1)\", Kernel.Sigmoid,    1.0,    0.1, 0, 0.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a00b60-a9e5-4504-a485-f013b03dfc56",
   "metadata": {},
   "source": [
    "### Approach 1: MinMax Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f05c0b4-0f1a-4ebb-8336-524629b5c6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      " APPROACH 1: MINMAX (BINARY)\n",
      "=================================================================\n",
      "\n",
      "--- init Preprocess ---\n",
      "   Normalization: minmax\n",
      "    Stratigfied HoldOut split: 579 train, 124 val, 124 test\n",
      "    Normalizing numerical features...\n",
      "    ...Normalization completed.\n",
      "    Encoding categorical features (OHE)...\n",
      "    ...OHE completed.\n",
      "    Concatenate numerical and categorical matrices...\n",
      "    Classes stored for the target: [0, 1]\n",
      "--- PREPROCESS END SUCCESFULLY ---\n",
      "\n",
      "=================================================================\n",
      " EXPERIMENT: A1-MinMax-Binary (Manual Train/Test)\n",
      "=================================================================\n",
      "   [Auto-Fix] Transponiendo matriz para formato LIBSVM (Features x Samples)...\n",
      "   Dimensiones finales X_train: (31, 579)\n",
      " Testing Config 1/8: RBF (C=1, G=0.1) ... Done. Sens: 0.7857 | Acc: 81.45%\n",
      " Testing Config 2/8: RBF (C=10, G=0.1) ... Done. Sens: 0.75 | Acc: 80.65%\n",
      " Testing Config 3/8: RBF (C=100, G=0.01) ... Done. Sens: 0.8036 | Acc: 81.45%\n",
      " Testing Config 4/8: RBF (C=1000, G=0.001) ... Done. Sens: 0.8214 | Acc: 83.06%\n",
      " Testing Config 5/8: Linear (C=1) ... Done. Sens: 0.8214 | Acc: 83.06%\n",
      " Testing Config 6/8: Linear (C=10) ... Done. Sens: 0.8214 | Acc: 83.06%\n",
      " Testing Config 7/8: Poly (D=2, C=1) ... Done. Sens: 0.7857 | Acc: 80.65%\n",
      " Testing Config 8/8: Sigmoid (C=1, G=0.1) ... Done. Sens: 0.8036 | Acc: 79.03%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(config = (\"RBF (C=1000, G=0.001)\", LIBSVM.Kernel.RadialBasis, 1000.0, 0.001, 0, 0.0),\n",
       " sens = 0.8214285714285714,\n",
       " acc = 83.06451612903226,\n",
       " f1 = 0.8141592920353982,\n",
       " time = 0.012856006622314453,\n",
       " model = LIBSVM.SVM{Int64, LIBSVM.Kernel.KERNEL}(LIBSVM.SVC, LIBSVM.Kernel.RadialBasis, Dict(0 => 1.1177606177606179, 1 => 0.9046875), 31, 579, 2, [1, 0], Int32[1, 2], [1.1177606177606179, 0.9046875], Int32[2, 1], LIBSVM.SupportVectors{Vector{Int64}, Matrix{Float64}}(238, Int32[134, 104], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.0625 0.22916666666666666 … 0.6458333333333334 0.6875; 0.125 0.125 … 0.3333333333333333 0.6666666666666666; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Int32[1, 4, 5, 11, 12, 17, 18, 29, 31, 32  …  527, 531, 532, 534, 550, 559, 561, 567, 570, 577], LIBSVM.SVMNode[LIBSVM.SVMNode(1, 0.0625), LIBSVM.SVMNode(1, 0.22916666666666666), LIBSVM.SVMNode(1, 0.3541666666666667), LIBSVM.SVMNode(1, 0.22916666666666666), LIBSVM.SVMNode(1, 0.7916666666666666), LIBSVM.SVMNode(1, 0.5833333333333334), LIBSVM.SVMNode(1, 0.2916666666666667), LIBSVM.SVMNode(1, 0.5833333333333334), LIBSVM.SVMNode(1, 0.7708333333333334), LIBSVM.SVMNode(1, 0.3125)  …  LIBSVM.SVMNode(1, 0.20833333333333334), LIBSVM.SVMNode(1, 0.3541666666666667), LIBSVM.SVMNode(1, 0.4583333333333333), LIBSVM.SVMNode(1, 0.5416666666666666), LIBSVM.SVMNode(1, 0.4583333333333333), LIBSVM.SVMNode(1, 0.8125), LIBSVM.SVMNode(1, 0.6666666666666666), LIBSVM.SVMNode(1, 0.625), LIBSVM.SVMNode(1, 0.6458333333333334), LIBSVM.SVMNode(1, 0.6875)]), 0.0, [904.6875; 904.6875; … ; -1117.7606177606178; -1117.7606177606178;;], Float64[], Float64[], [-4.310332152209515], 0, 0.001, 200.0, 0.001, 1000.0, 0.5, 0.1, true, false),)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"\\n=================================================================\")\n",
    "println(\" APPROACH 1: MINMAX (BINARY)\")\n",
    "println(\"=================================================================\")\n",
    "\n",
    "# La función prepare_data ahora recibe datos binarios y los divide\n",
    "# Asumo que norm_method=:minmax hace MinMax y OHE\n",
    "approach_1 = prepare_data(data, num_col, cat_col, target_col, norm_method=:minmax)\n",
    "\n",
    "# Entrenar (tu función run_svm_experiment debería manejar binario automáticamente)\n",
    "winner_a1 = run_svm_experiment(\n",
    "    approach_1.x_train, approach_1.y_train_cat,\n",
    "    approach_1.x_test, approach_1.y_test_cat,\n",
    "    \"A1-MinMax-Binary\", svm_configs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f68f91a-bfc6-4886-8fed-14b909473c88",
   "metadata": {},
   "source": [
    "### Approach 2: PCA Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb31a3c0-f1e2-4bf2-ad8c-5db77118a38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      " APPROACH 2: PCA (BINARY)\n",
      "=================================================================\n",
      "\n",
      "--- init Preprocess ---\n",
      "   Normalization: zscore\n",
      "    Stratigfied HoldOut split: 579 train, 124 val, 124 test\n",
      "    Normalizing numerical features...\n",
      "    ...Normalization completed.\n",
      "    Encoding categorical features (OHE)...\n",
      "    ...OHE completed.\n",
      "    Concatenate numerical and categorical matrices...\n",
      "    Classes stored for the target: [0, 1]\n",
      "--- PREPROCESS END SUCCESFULLY ---\n",
      "import MLJMultivariateStatsInterface ✔\n",
      "\n",
      "---data preprocessed---\n",
      "\n",
      "---Init PCA transformation---\n",
      " Train set size: (703, 31)\n",
      "Train set size: after PCA: (703, 17)\n",
      ">> Ejecutando SVM - Approach 2 (PCA)\n",
      "\n",
      "=================================================================\n",
      " EXPERIMENT: A2-PCA-Binary (Manual Train/Test)\n",
      "=================================================================\n",
      "   [Auto-Fix] Transponiendo matriz para formato LIBSVM (Features x Samples)...\n",
      "   Dimensiones finales X_train: (17, 703)\n",
      " Testing Config 1/8: RBF (C=1, G=0.1) ... Done. Sens: 0.8214 | Acc: 86.29%\n",
      " Testing Config 2/8: RBF (C=10, G=0.1) ... Done. Sens: 0.8036 | Acc: 80.65%\n",
      " Testing Config 3/8: RBF (C=100, G=0.01) ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Sens: 0.8571 | Acc: 83.87%\n",
      " Testing Config 4/8: RBF (C=1000, G=0.001) ... Done. Sens: 0.8393 | Acc: 86.29%\n",
      " Testing Config 5/8: Linear (C=1) ... Done. Sens: 0.8214 | Acc: 85.48%\n",
      " Testing Config 6/8: Linear (C=10) ... Done. Sens: 0.7857 | Acc: 84.68%\n",
      " Testing Config 7/8: Poly (D=2, C=1) ... Done. Sens: 0.8393 | Acc: 83.87%\n",
      " Testing Config 8/8: Sigmoid (C=1, G=0.1) ... Done. Sens: 0.7857 | Acc: 85.48%\n",
      "\n",
      "\n",
      "****************************************************************\n",
      "      WINNER FOR APPROACH 2: PCA\n",
      "****************************************************************\n",
      "Approach: MinMax\n",
      "Best Config:(\"RBF (C=100, G=0.01)\", LIBSVM.Kernel.RadialBasis, 100.0, 0.01, 0, 0.0)\n",
      "Sensib:0.8571428571428571\n",
      "Acc(%):83.87096774193549\n",
      "Time(s):0.03200793266296387\n"
     ]
    }
   ],
   "source": [
    "println(\"\\n=================================================================\")\n",
    "println(\" APPROACH 2: PCA (BINARY)\")\n",
    "println(\"=================================================================\")\n",
    "\n",
    "# El PCA ahora se calculará sobre datos cuya separación óptima es binaria\n",
    "approach_2 = prepare_data(data, num_col, cat_col, target_col, norm_method=:zscore)\n",
    "\n",
    "using MLJMultivariateStatsInterface\n",
    "PCA = MLJ.@load PCA pkg=MultivariateStats\n",
    "\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "\n",
    "println(\"\\n---data preprocessed---\")\n",
    "\n",
    "println(\"\\n---Init PCA transformation---\")\n",
    "\n",
    "\n",
    "#Unpack variables for MLJ\n",
    "x_train = approach_2.x_train\n",
    "x_val = approach_2.x_val\n",
    "x_test = approach_2.x_test\n",
    "\n",
    "y_train_pca = approach_2.y_train_cat \n",
    "y_val_pca = approach_2.y_val_cat     \n",
    "y_test_pca = approach_2.y_test_cat     \n",
    "\n",
    "# Combine Train + Val (to adjust PCA) for models != ANN, for ANN take this into account\n",
    "x_train_val_combined = vcat(x_train, x_val)\n",
    "y_train_val_combined = vcat(y_train_pca, y_val_pca)\n",
    "\n",
    "println(\" Train set size: \", size(x_train_val_combined))\n",
    "\n",
    "\n",
    "# Use PCA to select the components that explain 95% of the variance\n",
    "pca_model = PCA(variance_ratio=0.95)\n",
    "\n",
    "#1 Adjust the PCA only with the training data\n",
    "pca_machine = machine(pca_model, MLJ.table(x_train_val_combined))\n",
    "MLJ.fit!(pca_machine, verbosity=0)\n",
    "\n",
    "#2 transform data\n",
    "x_train_val_pca = MLJ.transform(pca_machine, MLJ.table(x_train_val_combined))\n",
    "\n",
    "x_test_pca = MLJ.transform(pca_machine, MLJ.table(x_test))\n",
    "\n",
    "#For MLJ is better to pass the data as table\n",
    "#To see data as matrix use: mat_train_pca = MLJ.matrix(x_train_val_pca)\n",
    "# Para ver los datos transformados como matriz:\n",
    "mat_train_pca = MLJ.matrix(x_train_val_pca)\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------\n",
    "mat_test_pca = MLJ.matrix(x_test_pca)\n",
    "println(\"Train set size: after PCA: \", size(mat_train_pca))\n",
    "\n",
    "# La unión de etiquetas ahora es de 0s y 1s\n",
    "y_train_val_combined = vcat(approach_2.y_train_cat, approach_2.y_val_cat)\n",
    "\n",
    "println(\">> Ejecutando SVM - Approach 2 (PCA)\")\n",
    "\n",
    "winner_a2 = run_svm_experiment(\n",
    "    mat_train_pca, y_train_val_combined,\n",
    "    mat_test_pca, approach_2.y_test_cat,\n",
    "    \"A2-PCA-Binary\", svm_configs\n",
    ")\n",
    "\n",
    "# Final Summary\n",
    "println(\"\\n\\n****************************************************************\")\n",
    "println(\"      WINNER FOR APPROACH 2: PCA\")\n",
    "println(\"****************************************************************\")\n",
    "println(\"Approach: MinMax\")\n",
    "println(\"Best Config:\",winner_a2.config)\n",
    "println(\"Sensib:\",winner_a2.sens)\n",
    "println(\"Acc(%):\",winner_a2.acc)\n",
    "println(\"Time(s):\",winner_a2.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89247ddd-ee8c-4484-8d0f-8e4f2d143d06",
   "metadata": {},
   "source": [
    "### Approach 3 : PCA Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e15f9881-4c1e-42f4-9716-2528f0dd95a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      " APPROACH 3: ICA (BINARY)\n",
      "=================================================================\n",
      "import MLJMultivariateStatsInterface ✔\n",
      "\n",
      "Init approach 3, ICA (Numerical features only)...\n",
      "\n",
      "--- init Preprocess ---\n",
      "   Normalization: zscore\n",
      "    Stratigfied HoldOut split: 579 train, 124 val, 124 test\n",
      "    Normalizing numerical features...\n",
      "    ...Normalization completed.\n",
      "    Encoding categorical features (OHE)...\n",
      "    ...OHE completed.\n",
      "    Concatenate numerical and categorical matrices...\n",
      "    Classes stored for the target: [0, 1]\n",
      "--- PREPROCESS END SUCCESFULLY ---\n",
      " ICA with k=2 ...\n",
      "\n",
      ">> Preparando datos ICA para LIBSVM...\n",
      "\n",
      ">> Ejecutando SVM - Approach 3 (ICA)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ICA(outdim = 2, …), …).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      " EXPERIMENT: A3-ICA-Binary (Manual Train/Test)\n",
      "=================================================================\n",
      "   Dimensiones finales X_train: (28, 703)\n",
      " Testing Config 1/8: RBF (C=1, G=0.1) ... Done. Sens: 0.8036 | Acc: 85.48%\n",
      " Testing Config 2/8: RBF (C=10, G=0.1) ... Done. Sens: 0.8036 | Acc: 80.65%\n",
      " Testing Config 3/8: RBF (C=100, G=0.01) ... Done. Sens: 0.8214 | Acc: 83.87%\n",
      " Testing Config 4/8: RBF (C=1000, G=0.001) ... Done. Sens: 0.8036 | Acc: 85.48%\n",
      " Testing Config 5/8: Linear (C=1) ... Done. Sens: 0.8393 | Acc: 85.48%\n",
      " Testing Config 6/8: Linear (C=10) ... Done. Sens: 0.8393 | Acc: 84.68%\n",
      " Testing Config 7/8: Poly (D=2, C=1) ... Done. Sens: 0.8214 | Acc: 83.87%\n",
      " Testing Config 8/8: Sigmoid (C=1, G=0.1) ... Done. Sens: 0.7679 | Acc: 78.23%\n",
      "\n",
      "\n",
      "****************************************************************\n",
      "      WINNER FOR APPROACH 3: ICA\n",
      "****************************************************************\n",
      "Approach: MinMax\n",
      "Best Config:(\"Linear (C=1)\", LIBSVM.Kernel.Linear, 1.0, 0.0, 0, 0.0)\n",
      "Sensib:0.8392857142857143\n",
      "Acc(%):85.48387096774194\n",
      "Time(s):0.016302108764648438\n"
     ]
    }
   ],
   "source": [
    "println(\"\\n=================================================================\")\n",
    "println(\" APPROACH 3: ICA (BINARY)\")\n",
    "println(\"=================================================================\")\n",
    "# -----------------------------------------------------------------\n",
    "# (Aproach 3) ICA and z-score (ICA just in numerical features , if we use it with the caegorical ones it wouldn't find a solution) \n",
    "# -----------------------------------------------------------------\n",
    "using MLJMultivariateStatsInterface\n",
    "ICA = MLJ.@load ICA pkg=MultivariateStats\n",
    "\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "\n",
    "\n",
    "println(\"\\nInit approach 3, ICA (Numerical features only)...\")\n",
    "\n",
    "# 1. Preprocess as previous aproach ( Z-Score, ideal for ICA\n",
    "approach_ica = prepare_data(data, num_col, cat_col, target_col, norm_method=:zscore)\n",
    "\n",
    "# 2. Unpack results\n",
    "x_train = approach_ica.x_train\n",
    "x_val = approach_ica.x_val\n",
    "x_test = approach_ica.x_test\n",
    "\n",
    "y_train_ica = approach_ica.y_train_cat \n",
    "y_val_ica = approach_ica.y_val_cat     \n",
    "y_test_ica = approach_ica.y_test_cat;\n",
    "\n",
    "# Our function  'prepare_data'order first numerical fetures and then categorical ones.\n",
    "\n",
    "n_num = length(num_col) # Should be (age, trestbps, chol, thalch, oldpeak)\n",
    "\n",
    "#Split \n",
    "x_num_train = x_train[:, 1:n_num]      # Just numerical \n",
    "x_cat_train = x_train[:, n_num+1:end]  # Just categorical OHE\n",
    "\n",
    "x_num_val = x_val[:, 1:n_num]\n",
    "x_cat_val = x_val[:, n_num+1:end]\n",
    "x_num_test = x_test[:, 1:n_num]\n",
    "x_cat_test = x_test[:, n_num+1:end]\n",
    "\n",
    "\n",
    "# --- ICA just for numerical ---\n",
    "\n",
    "# k should be less or equal than umber of features (5)\n",
    "k_components = 2\n",
    "\n",
    "#Random.seed!(1234)#ICA is a no deterministic method so we fix the seed for reproducibility. But somehow fail \n",
    "# Give some tolerance for the solution\n",
    "ica_model = ICA(outdim=k_components, maxiter=100000, tol=0.2) \n",
    "\n",
    "println(\" ICA with k=$k_components ...\")\n",
    "\n",
    "# Fit only the numerical data from training set, for ANN\n",
    "ica_machine = machine(ica_model, MLJ.table(x_num_train))\n",
    "MLJ.fit!(ica_machine, verbosity=1) # verbosity=1 for debug\n",
    "\n",
    "\"\"\"\n",
    "#for models != ANN:\n",
    "x_train_val_num=vcat(x_num_train, x_num_val)\n",
    "#fit on both, training and validation\n",
    "ica_machine = machine(ica_model, MLJ.table(x_train_val_num))\n",
    "MLJ.fit!(ica_machine, verbosity=1) # verbosity=1 for debug\n",
    "\"\"\"\n",
    "\n",
    "# Transform and return to matrix\n",
    "x_num_train_ica = MLJ.transform(ica_machine, MLJ.table(x_num_train))\n",
    "x_num_val_ica  = MLJ.transform(ica_machine, MLJ.table(x_num_val))\n",
    "x_num_test_ica  = MLJ.transform(ica_machine, MLJ.table(x_num_test))\n",
    "\n",
    "\n",
    "mat_train_ica = MLJ.matrix(x_num_train_ica)\n",
    "mat_val_ica  = MLJ.matrix(x_num_val_ica)\n",
    "mat_test_ica  = MLJ.matrix(x_num_test_ica)\n",
    "\n",
    "#Add the categorical OHE \n",
    "x_train_ica = hcat(mat_train_ica, x_cat_train)\n",
    "x_val_ica = hcat(mat_val_ica, x_cat_val)\n",
    "x_test_ica     = hcat(mat_test_ica, x_cat_test)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# PREPARACIÓN FINAL PARA SVM (APPROACH 3: ICA)\n",
    "# ==============================================================================\n",
    "\n",
    "println(\"\\n>> Preparando datos ICA para LIBSVM...\")\n",
    "\n",
    "# 1. Combinar Train + Validation\n",
    "# SVM funciona mejor con más datos. Unimos las matrices que ya procesaste.\n",
    "x_train_val_ica_combined = vcat(x_train_ica, x_val_ica)\n",
    "y_train_val_ica_combined = vcat(y_train_ica, y_val_ica)\n",
    "\n",
    "# 2. Transponer Matrices (Features x Samples)\n",
    "# LIBSVM es estricto con esto. Convertimos a Float64 y transponemos.\n",
    "x_train_svm_ica = Float64.(permutedims(x_train_val_ica_combined))\n",
    "x_test_svm_ica  = Float64.(permutedims(x_test_ica))\n",
    "\n",
    "# 3. Limpiar Etiquetas\n",
    "# Nos aseguramos de que sean enteros simples (sin envoltorios CategoricalValue)\n",
    "get_val(x) = (typeof(x) <: CategoricalValue) ? unwrap(x) : x\n",
    "\n",
    "y_train_final_ica = vec(Int.(get_val.(y_train_val_ica_combined)))\n",
    "y_test_final_ica  = vec(Int.(get_val.(y_test_ica)))\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURACIÓN Y EJECUCIÓN\n",
    "# ==============================================================================\n",
    "\n",
    "println(\"\\n>> Ejecutando SVM - Approach 3 (ICA)\")\n",
    "winner_a3 = run_svm_experiment(\n",
    "    x_train_svm_ica, y_train_final_ica, # Variables resultantes del proceso ICA\n",
    "    x_test_svm_ica, y_test_final_ica,\n",
    "    \"A3-ICA-Binary\", svm_configs # Quizás añadir configs Sigmoide/Poly aquí\n",
    ")\n",
    "\n",
    "# Final Summary\n",
    "println(\"\\n\\n****************************************************************\")\n",
    "println(\"      WINNER FOR APPROACH 3: ICA\")\n",
    "println(\"****************************************************************\")\n",
    "println(\"Approach: MinMax\")\n",
    "println(\"Best Config:\",winner_a3.config)\n",
    "println(\"Sensib:\",winner_a3.sens)\n",
    "println(\"Acc(%):\",winner_a3.acc)\n",
    "println(\"Time(s):\",winner_a3.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a4c40d-e8f5-4ba7-9714-779ae12aa8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

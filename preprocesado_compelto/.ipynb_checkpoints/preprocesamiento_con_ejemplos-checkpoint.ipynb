{
 "cells": [
  {
   "cell_type": "raw",
   "id": "274420c3-8405-41b0-aa81-f0aad9e7843c",
   "metadata": {},
   "source": [
    "using Pkg\n",
    "# Ensure required packages \n",
    "# To execurte a single time\n",
    "Pkg.add([\n",
    "    \"MLJ\", \n",
    "    \"MLJBase\", \n",
    "    \"MLJNaiveBayesInterface\",\n",
    "    \"MLJModels\", \n",
    "    \"MultivariateStats\",\n",
    "    \"MLJMultivariateStatsInterface\",\n",
    "    \"MLJEnsembles\", \n",
    "    \"MLJLinearModels\", \n",
    "    \"DecisionTree\", \n",
    "    \"MLJDecisionTreeInterface\", \n",
    "    \"NaiveBayes\", \n",
    "    \"EvoTrees\", \n",
    "    \"CategoricalArrays\", \n",
    "    \"Random\",\n",
    "    \"LIBSVM\",           \n",
    "    \"Plots\",            \n",
    "    \"MLJModelInterface\", \n",
    "    \"CSV\",              \n",
    "    \"DataFrames\", \n",
    "    \"DataFramesMeta\",\n",
    "    \"UrlDownload\",      \n",
    "    \"XGBoost\",\n",
    "    \"MLJLIBSVMInterface\",\n",
    "    \"Flux\",\n",
    "    \"NearestNeighborModels\",\n",
    "    \"Tables\",\n",
    "    \"JLD2\",\n",
    "    \"Measures\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4401fd3-4e44-4431-b0ba-9e119823de3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "universalCrossValidation_PCA"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load libraries and previous functions:\n",
    "using Downloads\n",
    "using DelimitedFiles\n",
    "using Plots\n",
    "using MLJ\n",
    "using MLJModels\n",
    "using MLJMultivariateStatsInterface\n",
    "using MLJLinearModels\n",
    "using MLJDecisionTreeInterface\n",
    "using MLJNaiveBayesInterface\n",
    "using MLJLIBSVMInterface\n",
    "using Statistics\n",
    "using Flux\n",
    "using Flux: Losses\n",
    "using Printf\n",
    "using Random\n",
    "using NearestNeighborModels\n",
    "using CSV\n",
    "using DataFrames\n",
    "using DataFramesMeta\n",
    "import MultivariateStats\n",
    "include(\"unit2-multilayer-perceptron.jl\")\n",
    "include(\"unit3-overfitting.jl\")\n",
    "include(\"unit4-metrics.jl\")\n",
    "include(\"unit5-crossvalidation.jl\")\n",
    "include(\"unit6-modelcrossvalidation.jl\")\n",
    "include(\"preprocess_utils.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "818b4f4e-ec39-4282-9d6b-d402e79756ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prepare_data"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    stratified_holdOut(y, p_val, p_test)\n",
    "\n",
    "    Split the indices, while keeping the proportions of the classes in \"y\" for each set\n",
    "    Also seed is fixed by default, as for reproducibility\n",
    "\"\"\"\n",
    "function stratified_holdOut(targets::AbstractVector, p_val::Real, p_test::Real; seed::Int=1234) \n",
    "    Random.seed!(seed)\n",
    "    N = length(targets)\n",
    "    classes = unique(targets)\n",
    "    \n",
    "    # Final Indices\n",
    "    idx_train = Int[]\n",
    "    idx_val   = Int[]\n",
    "    idx_test  = Int[]\n",
    "    \n",
    "    # Loop iterating over all classes\n",
    "    for c in classes\n",
    "        # Get the index for a given class\n",
    "        idx_class = findall(x -> x == c, targets)\n",
    "        n_class = length(idx_class)\n",
    "        \n",
    "        # Shuffle inside the class\n",
    "        shuffle!(idx_class)\n",
    "        \n",
    "        # Measure how many are going into each set\n",
    "        n_val  = round(Int, n_class * p_val)\n",
    "        n_test = round(Int, n_class * p_test)\n",
    "        n_train = n_class - n_val - n_test\n",
    "        \n",
    "        # Distibute the data\n",
    "        \n",
    "        append!(idx_val,   idx_class[1:n_val])\n",
    "        append!(idx_test,  idx_class[n_val+1 : n_val+n_test])\n",
    "        append!(idx_train, idx_class[n_val+n_test+1 : end])\n",
    "    end\n",
    "    \n",
    "    # Shuffle final indices, avoiding order by class\n",
    "    shuffle!(idx_train)\n",
    "    shuffle!(idx_val)\n",
    "    shuffle!(idx_test)\n",
    "    \n",
    "    return idx_train, idx_val, idx_test\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    load_and_clean_data(path::String)\n",
    "\n",
    "Carga el dataset de enfermedades cardíacas, gestiona los valores nulos según\n",
    "la lógica del 'Approach 1' (imputación categórica + eliminación de filas numéricas)\n",
    "y devuelve los datos listos junto con los metadatos de las columnas.\n",
    "\n",
    "# Returns\n",
    "- `data`: DataFrame limpio.\n",
    "- `num_col`: Vector de símbolos con columnas numéricas.\n",
    "- `cat_col`: Vector de símbolos con columnas categóricas.\n",
    "- `target_col`: Símbolo de la columna objetivo.\n",
    "\"\"\"\n",
    "function load_and_clean_data(path::String)\n",
    "    println(\">>> Loading data from: $path\")\n",
    "    \n",
    "    # 1. Load data\n",
    "    data = DataFrame()\n",
    "    try\n",
    "        data = CSV.read(path, DataFrame)\n",
    "    catch e\n",
    "        error(\"Error while loading file. Check path.\\nDetails: $e\")\n",
    "    end\n",
    "\n",
    "    # 2. Drop irrelevant features\n",
    "    select!(data, Not([:id, :dataset])) \n",
    "\n",
    "    println(\"  Original Size: $(size(data))\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. Mange Nulls (CAT) -> \"missingval\"\n",
    "    # ---------------------------------------------------------\n",
    "    cat_col_null = [:fbs, :restecg, :exang, :slope, :thal, :ca]\n",
    "    \n",
    "    for col in cat_col_null\n",
    "        \n",
    "        data[!, col] = replace(data[!, col], missing => \"missingval\")\n",
    "    end\n",
    "    println(\" Categorical Null values replaced with ---> 'missingval'.\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. manage Nulls (NUM) -> Drop rows if null < given percentage\n",
    "    # ---------------------------------------------------------\n",
    "    \n",
    "    rows = nrow(data)\n",
    "    desc_df = describe(data, :nmissing)\n",
    "    aux_miss = DataFrame(\n",
    "        Column = desc_df.variable, \n",
    "        Percent = (desc_df.nmissing ./ rows) .* 100\n",
    "    )\n",
    "\n",
    "    #  Drop rows if null < given percentage\n",
    "    cols_to_clean_df = @rsubset(aux_miss, 0 < :Percent < 7.5)\n",
    "    cols_to_clean = Symbol.(cols_to_clean_df.Column)\n",
    "\n",
    "    if !isempty(cols_to_clean)\n",
    "        dropmissing!(data, cols_to_clean)\n",
    "        println(\"  Deleted rows in features: $cols_to_clean\")\n",
    "    end\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5. Final sort\n",
    "    # ---------------------------------------------------------\n",
    "    num_col = [:age, :trestbps, :chol, :thalch, :oldpeak]\n",
    "    cat_col = [:sex, :cp, :fbs, :restecg, :exang, :slope, :ca, :thal]\n",
    "    target_col = :num\n",
    "    # disallowmissing, transform clean features to single types\n",
    "    data = select(data, num_col, cat_col, target_col)\n",
    "    disallowmissing!(data) \n",
    "\n",
    "    println(\"  Final shape: $(size(data))\")\n",
    "    println(\"------------------------\")\n",
    "\n",
    "    return data, num_col, cat_col, target_col\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "    check_class_distribution(y_train, y_val, y_test)\n",
    "\n",
    "    Auxiliar function to check the class distribution and verify stratification\n",
    "\"\"\"\n",
    "function check_class_distribution(y_train, y_val, y_test)\n",
    "    \n",
    "    all_classes = sort(unique(vcat(y_train, y_val, y_test)))\n",
    "    \n",
    "    println(\"\\n--- Class Distribution Analisys ---\")\n",
    "    @printf(\"%-10s | %-15s | %-15s | %-15s\\n\", \"Class\", \"Train % (N)\", \"Val % (N)\", \"Test % (N)\")\n",
    "    println(\"-\"^65)\n",
    "    \n",
    "    for c in all_classes\n",
    "        \n",
    "        n_tr = count(x -> x == c, y_train)\n",
    "        n_val = count(x -> x == c, y_val)\n",
    "        n_te = count(x -> x == c, y_test)\n",
    "        \n",
    "        p_tr = (n_tr / length(y_train)) * 100\n",
    "        p_val = (n_val / length(y_val)) * 100\n",
    "        p_te = (n_te / length(y_test)) * 100\n",
    "        \n",
    "        @printf(\"Class %d    | %5.2f%% (%3d)    | %5.2f%% (%3d)    | %5.2f%% (%3d)\\n\", \n",
    "                c, p_tr, n_tr, p_val, n_val, p_te, n_te)\n",
    "    end\n",
    "    println(\"-\"^65)\n",
    "    println(\"Total |         %-6d    |         %-6d    |         %-6d\\n\", \n",
    "            length(y_train), length(y_val), length(y_test))\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    prepare_data(clean_data, num_col, cat_col, target_col; ...)\n",
    "\n",
    "    Take a clean DataFrame without NULL values and prepare the data to feed the models:\n",
    "    1. Split Train/Validation/Test (stratified_holdOut)\n",
    "    2. Split X/Y, input and output \n",
    "    3. Normalization (MinMax or Z-score) numerical features\n",
    "    4. One-Hot Encoding Categorical features\n",
    "    5. Combine the matrices\n",
    "    6. Process the target Y (MLJ.categorical and OHE)\n",
    "\"\"\"\n",
    "function prepare_data(clean_data::DataFrame, \n",
    "                                    num_col::Vector{Symbol}, #name of the numerical features\n",
    "                                    cat_col::Vector{Symbol}, #name of the categorical features\n",
    "                                    target_col::Symbol; #name of the target feature\n",
    "                                    Pval::Real=0.15, #percent for split  val set\n",
    "                                    Ptest::Real=0.15, #percent for split test set\n",
    "                                    norm_method::Symbol=:minmax) #normalization method, either :minmax or :zscore\n",
    "    \n",
    "    println(\"\\n--- init Preprocess ---\")\n",
    "    println(\"   Normalization: $norm_method\")\n",
    "\n",
    "    # --- 1. Data Split (HoldOut) ---\n",
    "    rows, columns = size(clean_data)\n",
    "    N = rows\n",
    "    \n",
    "    (train_indices, val_indices, test_indices) = stratified_holdOut(data[!, target_col], Pval, Ptest; seed = 1234)\n",
    "    \n",
    "    train_data = clean_data[train_indices, :]\n",
    "    val_data = clean_data[val_indices, :]\n",
    "    test_data = clean_data[test_indices, :]\n",
    "    println(\"    Stratigfied HoldOut split: $(size(train_data,1)) train, $(size(val_data,1)) val, $(size(test_data,1)) test\")\n",
    "\n",
    "    # --- 2. Features/Target Split ---\n",
    "    x_train_df = select(train_data, Not(target_col))\n",
    "    y_train_vec = train_data[!, target_col]\n",
    "    x_val_df = select(val_data, Not(target_col))\n",
    "    y_val_vec = val_data[!, target_col]\n",
    "    x_test_df = select(test_data, Not(target_col))\n",
    "    y_test_vec = test_data[!, target_col]\n",
    "\n",
    "    # --- 3. Normalization of numerical features ---\n",
    "    println(\"    Normalizing numerical features...\")\n",
    "    x_train_num_mat = Matrix{Float64}(x_train_df[!, num_col])\n",
    "    x_test_num_mat = Matrix{Float64}(x_test_df[!, num_col])\n",
    "    x_val_num_mat = Matrix{Float64}(x_val_df[!, num_col])\n",
    "    \n",
    "    norm_param = nothing #Init the variable \n",
    "\n",
    "    if norm_method == :minmax\n",
    "        norm_param = calculateMinMaxNormalizationParameters(x_train_num_mat)\n",
    "        normalizeMinMax!(x_train_num_mat, norm_param)\n",
    "        normalizeMinMax!(x_test_num_mat, norm_param)\n",
    "        normalizeMinMax!(x_val_num_mat, norm_param)\n",
    "    elseif norm_method == :zscore\n",
    "        norm_param = calculateZeroMeanNormalizationParameters(x_train_num_mat)\n",
    "        normalizeZeroMean!(x_train_num_mat, norm_param)\n",
    "        normalizeZeroMean!(x_test_num_mat, norm_param)\n",
    "        normalizeZeroMean!(x_val_num_mat, norm_param)\n",
    "    else\n",
    "        error(\"Normalization method not clear: '$norm_method' . Use :minmax or :zscore.\")\n",
    "    end\n",
    "    println(\"    ...Normalization completed.\")\n",
    "\n",
    "    # --- 4. One-Hot Encoding Categorial features ---\n",
    "    println(\"    Encoding categorical features (OHE)...\")\n",
    "    \n",
    "    x_train_cat_mat = BitArray{2}(undef, size(x_train_df, 1), 0)\n",
    "    x_test_cat_mat  = BitArray{2}(undef, size(x_test_df, 1), 0)\n",
    "    x_val_cat_mat = BitArray{2}(undef, size(x_val_df, 1), 0)\n",
    "    \n",
    "    ohe_classes_map = Dict{Symbol, Vector{Any}}() # Store classes\n",
    "\n",
    "    for col in cat_col\n",
    "        feature_train = x_train_df[!, col]\n",
    "        feature_test  = x_test_df[!, col]\n",
    "        feature_val = x_val_df[!, col]\n",
    "        \n",
    "        learn_classes = unique(feature_train)\n",
    "        \n",
    "        # Manage unseen clases, ex. if missingval is only present in tets and validation due to the randomness in split\n",
    "        for val in unique(vcat(feature_test, feature_val))\n",
    "            if !(val in learn_classes)\n",
    "                push!(learn_classes, val)\n",
    "                println(\"        -> Warning: Feature '$col': Class '$val' aded (Not present in train).\")\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        ohe_classes_map[col] = learn_classes # Save the classes\n",
    "        \n",
    "        encoded_train = oneHotEncoding(feature_train, learn_classes)\n",
    "        encoded_test  = oneHotEncoding(feature_test, learn_classes)\n",
    "        encoded_val   = oneHotEncoding(feature_val, learn_classes)\n",
    "        \n",
    "        x_train_cat_mat = hcat(x_train_cat_mat, encoded_train)\n",
    "        x_test_cat_mat  = hcat(x_test_cat_mat, encoded_test)\n",
    "        x_val_cat_mat   = hcat(x_val_cat_mat, encoded_val) \n",
    "    end\n",
    "    println(\"    ...OHE completed.\")\n",
    "\n",
    "    # --- 5. Combine the matrices ---\n",
    "    println(\"    Concatenate numerical and categorical matrices...\")\n",
    "    x_train_final = hcat(x_train_num_mat, x_train_cat_mat)\n",
    "    x_test_final  = hcat(x_test_num_mat, x_test_cat_mat)\n",
    "    x_val_final = hcat(x_val_num_mat, x_val_cat_mat)\n",
    "    \n",
    "    # --- 6. Process the targets ---\n",
    "    target_classes = sort(unique(clean_data[!, target_col]))\n",
    "    println(\"    Classes stored for the target: $target_classes\")\n",
    "    \n",
    "    # (SVM, DT, kNN)\n",
    "    y_train_cat = MLJ.categorical(y_train_vec)\n",
    "    y_test_cat = MLJ.categorical(y_test_vec)\n",
    "    y_val_cat = MLJ.categorical(y_val_vec)\n",
    "    \n",
    "    # For ANN (OHE)\n",
    "    y_train_ohe = oneHotEncoding(y_train_vec, target_classes)\n",
    "    y_test_ohe  = oneHotEncoding(y_test_vec, target_classes)\n",
    "    y_val_ohe   = oneHotEncoding(y_val_vec, target_classes)\n",
    "    \n",
    "    println(\"--- PREPROCESS END SUCCESFULLY ---\")\n",
    "\n",
    "    # --- 7. Return data ---\n",
    "    return (\n",
    "        x_train = x_train_final,\n",
    "        y_train_cat = y_train_cat, # For MLJ\n",
    "        y_train_ohe = y_train_ohe, # For ANN\n",
    "        \n",
    "        x_val = x_val_final,\n",
    "        y_val_cat = y_val_cat,     # For MLJ\n",
    "        y_val_ohe = y_val_ohe,     # For ANN\n",
    "        \n",
    "        x_test = x_test_final,\n",
    "        y_test_cat = y_test_cat,   # For MLJ\n",
    "        y_test_ohe = y_test_ohe,   # For ANN\n",
    "        \n",
    "        norm_params = norm_param,\n",
    "        ohe_classes = ohe_classes_map\n",
    "    )\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9482db1-2ad7-4bca-b159-60c75560bf23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading data from: heart_disease_uci.csv\n",
      "  Original Size: (920, 14)\n",
      " Categorical Null values replaced with ---> 'missingval'.\n",
      "  Deleted rows in features: [:trestbps, :chol, :thalch, :oldpeak]\n",
      "  Final shape: (827, 14)\n",
      "------------------------\n",
      "\n",
      " Init aproach 1 (MinMax)...\n",
      "\n",
      "--- init Preprocess ---\n",
      "   Normalization: minmax\n",
      "    Stratigfied HoldOut split: 577 train, 125 val, 125 test\n",
      "    Normalizing numerical features...\n",
      "    ...Normalization completed.\n",
      "    Encoding categorical features (OHE)...\n",
      "    ...OHE completed.\n",
      "    Concatenate numerical and categorical matrices...\n",
      "    Classes stored for the target: [0, 1, 2, 3, 4]\n",
      "--- PREPROCESS END SUCCESFULLY ---\n",
      "\n",
      "--- Approach 1 ---\n",
      "To acces data:\n",
      "approach_1.x_train\n",
      "approach_1.y_train_cat (for SVM/DT/kNN)\n",
      "approach_1.y_train_ohe (for ANN)\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# (Aproach 1) minmax\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "\n",
    "data, num_col, cat_col, target_col = load_and_clean_data(data_path)\n",
    "\n",
    "println(\"\\n Init aproach 1 (MinMax)...\")\n",
    "approach_1 = prepare_data(\n",
    "    data,          # Clean DataFrame without Nulls\n",
    "    num_col,       # numerical features\n",
    "    cat_col,       # caetgorical features\n",
    "    target_col,    # target feature\n",
    "    norm_method=:minmax #norm metghod, either :minmax or :zscore\n",
    ")\n",
    "\n",
    "println(\"\\n--- Approach 1 ---\")\n",
    "println(\"To acces data:\")\n",
    "println(\"approach_1.x_train\")\n",
    "println(\"approach_1.y_train_cat (for SVM/DT/kNN)\")\n",
    "println(\"approach_1.y_train_ohe (for ANN)\")\n",
    "println(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0abe2492-e005-43cb-88a1-189b6aec1473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acceder a los datos del approach 1:\n",
    "x_train = approach_1.x_train\n",
    "x_val   = approach_1.x_val\n",
    "x_test  = approach_1.x_test\n",
    "y_train = approach_1.y_train_cat\n",
    "y_val   = approach_1.y_val_cat\n",
    "y_test  = approach_1.y_test_cat;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "944350dc-d3ae-4ac3-b9bf-5eb8ed185c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_class_distribution(y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5236e249-1c8f-4ad0-ba5c-f534290293f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJMultivariateStatsInterface ✔\n",
      ">>> Loading data from: heart_disease_uci.csv\n",
      "  Original Size: (920, 14)\n",
      " Categorical Null values replaced with ---> 'missingval'.\n",
      "  Deleted rows in features: [:trestbps, :chol, :thalch, :oldpeak]\n",
      "  Final shape: (827, 14)\n",
      "------------------------\n",
      "\n",
      "--- init Preprocess ---\n",
      "   Normalization: zscore\n",
      "    Stratigfied HoldOut split: 577 train, 125 val, 125 test\n",
      "    Normalizing numerical features...\n",
      "    ...Normalization completed.\n",
      "    Encoding categorical features (OHE)...\n",
      "    ...OHE completed.\n",
      "    Concatenate numerical and categorical matrices...\n",
      "    Classes stored for the target: [0, 1, 2, 3, 4]\n",
      "--- PREPROCESS END SUCCESFULLY ---\n",
      "\n",
      "---data preprocessed---\n",
      "\n",
      "---Init PCA transformation---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train set size: (702, 31)\n",
      "Train set size: after PCA: (702, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"#Example of use for ANN\\n\\nprintln(\\\" Train set size: \\\", size(x_train))\\n\\n\\n# Use PCA to select the components that explain 95% of the variance\\npca_model = PCA(variance_ratio=0.95)\\n\\n#1 Adjust the PCA only with the training data\\npca_machine = machine(pca_model, MLJ.table(x_tra\"\u001b[93m\u001b[1m ⋯ 84 bytes ⋯ \u001b[22m\u001b[39m\"rm(pca_machine, MLJ.table(x_train))\\nx_val_pca = MLJ.transform(pca_machine, MLJ.table(x_val))\\nx_test_pca = MLJ.transform(pca_machine, MLJ.table(x_test))\\n\\n#For MLJ is better to pass the data as table\\n#To see data as matrix use: mat_train_pca = MLJ.matrix(x_train_val_test)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# (Aproach 2) PCA and z-score \n",
    "# -----------------------------------------------------------------\n",
    "using MLJMultivariateStatsInterface\n",
    "PCA = @load PCA pkg=MultivariateStats\n",
    "\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "\n",
    "data, num_col, cat_col, target_col = load_and_clean_data(data_path)\n",
    "\n",
    "approach_2 = prepare_data(\n",
    "    data,         \n",
    "    num_col,       \n",
    "    cat_col,       \n",
    "    target_col,    \n",
    "    norm_method=:zscore \n",
    ")\n",
    "\n",
    "println(\"\\n---data preprocessed---\")\n",
    "\n",
    "println(\"\\n---Init PCA transformation---\")\n",
    "\n",
    "\n",
    "#Unpack variables for MLJ\n",
    "x_train = approach_2.x_train\n",
    "x_val = approach_2.x_val\n",
    "x_test = approach_2.x_test\n",
    "\n",
    "y_train_pca = approach_2.y_train_cat \n",
    "y_val_pca = approach_2.y_val_cat     \n",
    "y_test_pca = approach_2.y_test_cat     \n",
    "\n",
    "# Combine Train + Val (to adjust PCA) for models != ANN, for ANN take this into account\n",
    "x_train_val_combined = vcat(x_train, x_val)\n",
    "y_train_val_combined = vcat(y_train, y_val)\n",
    "\n",
    "println(\" Train set size: \", size(x_train_val_combined))\n",
    "\n",
    "\n",
    "# Use PCA to select the components that explain 95% of the variance\n",
    "pca_model = PCA(variance_ratio=0.95)\n",
    "\n",
    "#1 Adjust the PCA only with the training data\n",
    "pca_machine = machine(pca_model, MLJ.table(x_train_val_combined))\n",
    "MLJ.fit!(pca_machine, verbosity=0)\n",
    "\n",
    "#2 transform data\n",
    "x_train_val_pca = MLJ.transform(pca_machine, MLJ.table(x_train_val_combined))\n",
    "\n",
    "x_test_pca = MLJ.transform(pca_machine, MLJ.table(x_test))\n",
    "\n",
    "#For MLJ is better to pass the data as table\n",
    "#To see data as matrix use: mat_train_pca = MLJ.matrix(x_train_val_pca)\n",
    "# Para ver los datos transformados como matriz:\n",
    "mat_train_pca = MLJ.matrix(x_train_val_pca)\n",
    "println(\"Train set size: after PCA: \", size(mat_train_pca))\n",
    "\n",
    "\"\"\"\n",
    "#Example of use for ANN\n",
    "\n",
    "println(\" Train set size: \", size(x_train))\n",
    "\n",
    "\n",
    "# Use PCA to select the components that explain 95% of the variance\n",
    "pca_model = PCA(variance_ratio=0.95)\n",
    "\n",
    "#1 Adjust the PCA only with the training data\n",
    "pca_machine = machine(pca_model, MLJ.table(x_train))\n",
    "MLJ.fit!(pca_machine, verbosity=0)\n",
    "\n",
    "#2 transform data\n",
    "x_train_pca = MLJ.transform(pca_machine, MLJ.table(x_train))\n",
    "x_val_pca = MLJ.transform(pca_machine, MLJ.table(x_val))\n",
    "x_test_pca = MLJ.transform(pca_machine, MLJ.table(x_test))\n",
    "\n",
    "#For MLJ is better to pass the data as table\n",
    "#To see data as matrix use: mat_train_pca = MLJ.matrix(x_train_val_test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33fb9870-9234-4ec0-9cff-260650e2bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_class_distribution(y_train_pca, y_val_pca, y_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "242f16fd-6254-4177-9fac-9c3e3da84753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJMultivariateStatsInterface ✔\n",
      ">>> Loading data from: heart_disease_uci.csv\n",
      "  Original Size: (920, 14)\n",
      " Categorical Null values replaced with ---> 'missingval'.\n",
      "  Deleted rows in features: [:trestbps, :chol, :thalch, :oldpeak]\n",
      "  Final shape: (827, 14)\n",
      "------------------------\n",
      "\n",
      "Init approach 3, ICA (Numerical features only)...\n",
      "\n",
      "--- init Preprocess ---\n",
      "   Normalization: zscore\n",
      "    Stratigfied HoldOut split: 577 train, 125 val, 125 test\n",
      "    Normalizing numerical features...\n",
      "    ...Normalization completed.\n",
      "    Encoding categorical features (OHE)...\n",
      "    ...OHE completed.\n",
      "    Concatenate numerical and categorical matrices...\n",
      "    Classes stored for the target: [0, 1, 2, 3, 4]\n",
      "--- PREPROCESS END SUCCESFULLY ---\n",
      " ICA with k=2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ICA(outdim = 2, …), …).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape (ICA Nums + OHE Cats): (577, 28)\n",
      "\n",
      " Results for approach 3 stored in:\n",
      "x_train_ica\n",
      "x_val_ica\n",
      "x_test_ica\n",
      "y_train_ica\n",
      "y_val_ica\n",
      "y_test_ica\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# (Aproach 3) ICA and z-score (ICA just in numerical features , if we use it with the caegorical ones it wouldn't find a solution) \n",
    "# -----------------------------------------------------------------\n",
    "using MLJMultivariateStatsInterface\n",
    "ICA = @load ICA pkg=MultivariateStats\n",
    "\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "\n",
    "data, num_col, cat_col, target_col = load_and_clean_data(data_path)\n",
    "\n",
    "\n",
    "println(\"\\nInit approach 3, ICA (Numerical features only)...\")\n",
    "\n",
    "# 1. Preprocess as previous aproach ( Z-Score, ideal for ICA\n",
    "approach_ica = prepare_data(\n",
    "    data,          \n",
    "    num_col,       \n",
    "    cat_col,       \n",
    "    target_col,    \n",
    "    norm_method=:zscore \n",
    ")\n",
    "\n",
    "# 2. Unpack results\n",
    "x_train = approach_ica.x_train\n",
    "x_val = approach_ica.x_val\n",
    "x_test = approach_ica.x_test\n",
    "\n",
    "y_train_ica = approach_ica.y_train_cat \n",
    "y_val_ica = approach_ica.y_val_cat     \n",
    "y_test_ica = approach_ica.y_test_cat;\n",
    "\n",
    "# Our function  'prepare_data'order first numerical fetures and then categorical ones.\n",
    "\n",
    "n_num = length(num_col) # Should be (age, trestbps, chol, thalch, oldpeak)\n",
    "\n",
    "#Split \n",
    "x_num_train = x_train[:, 1:n_num]      # Just numerical \n",
    "x_cat_train = x_train[:, n_num+1:end]  # Just categorical OHE\n",
    "\n",
    "x_num_val = x_val[:, 1:n_num]\n",
    "x_cat_val = x_val[:, n_num+1:end]\n",
    "x_num_test = x_test[:, 1:n_num]\n",
    "x_cat_test = x_test[:, n_num+1:end]\n",
    "\n",
    "\n",
    "# --- ICA just for numerical ---\n",
    "\n",
    "# k should be less or equal than umber of features (5)\n",
    "k_components = 2\n",
    "\n",
    "#Random.seed!(1234)#ICA is a no deterministic method so we fix the seed for reproducibility. But somehow fail \n",
    "# Give some tolerance for the solution\n",
    "ica_model = ICA(outdim=k_components, maxiter=100000, tol=0.2) \n",
    "\n",
    "println(\" ICA with k=$k_components ...\")\n",
    "\n",
    "# Fit only the numerical data from training set, for ANN\n",
    "ica_machine = machine(ica_model, MLJ.table(x_num_train))\n",
    "MLJ.fit!(ica_machine, verbosity=1) # verbosity=1 for debug\n",
    "\n",
    "\"\"\"\n",
    "#for models != ANN:\n",
    "x_train_val_num=vcat(x_num_train, x_num_val)\n",
    "#fit on both, training and validation\n",
    "ica_machine = machine(ica_model, MLJ.table(x_train_val_num))\n",
    "MLJ.fit!(ica_machine, verbosity=1) # verbosity=1 for debug\n",
    "\"\"\"\n",
    "\n",
    "# Transform and return to matrix\n",
    "x_num_train_ica = MLJ.transform(ica_machine, MLJ.table(x_num_train))\n",
    "x_num_val_ica  = MLJ.transform(ica_machine, MLJ.table(x_num_val))\n",
    "x_num_test_ica  = MLJ.transform(ica_machine, MLJ.table(x_num_test))\n",
    "\n",
    "\n",
    "mat_train_ica = MLJ.matrix(x_num_train_ica)\n",
    "mat_val_ica  = MLJ.matrix(x_num_val_ica)\n",
    "mat_test_ica  = MLJ.matrix(x_num_test_ica)\n",
    "\n",
    "#Add the categorical OHE \n",
    "x_train_ica = hcat(mat_train_ica, x_cat_train)\n",
    "x_val_ica = hcat(mat_val_ica, x_cat_val)\n",
    "x_test_ica     = hcat(mat_test_ica, x_cat_test)\n",
    "\n",
    "println(\"Final shape (ICA Nums + OHE Cats): \", size(x_train_ica))\n",
    "println(\"\\n Results for approach 3 stored in:\")\n",
    "println(\"x_train_ica\")\n",
    "println(\"x_val_ica\")\n",
    "println(\"x_test_ica\")\n",
    "println(\"y_train_ica\")\n",
    "println(\"y_val_ica\")\n",
    "println(\"y_test_ica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e786ef-3e89-49d6-ae7f-80b46a49a359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados tras ICA:\n",
      "SVM: 55.2 %\n",
      "LR: 56.8 %\n",
      "DT: 56.0 %\n",
      " 14.752198 seconds (49.01 M allocations: 2.405 GiB, 3.77% gc time, 99.59% compilation time)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# EXample of usage with models that don't use val set.\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "models_final = Dict(\n",
    "    \"SVM\" => SVC(cost=10.0), \n",
    "    \"LR\"  => LogisticClassifier(),\n",
    "    \"DT\"  => DecisionTreeClassifier(max_depth=4), \n",
    ")\n",
    "\n",
    "x_train_val = vcat(x_train_ica, x_val_ica)\n",
    "y_train_val= vcat(y_train_ica, y_val_ica)\n",
    "println(\"\\nResultados tras ICA:\")\n",
    "@time begin\n",
    "    for (name, model) in models_final\n",
    "        # Entrenamos con la matriz reconstruida\n",
    "        mach = machine(model, MLJ.table(x_train_val), y_train_val)\n",
    "        MLJ.fit!(mach, verbosity=0)\n",
    "        \n",
    "        # Predecimos\n",
    "        ŷ = MLJ.predict(mach, MLJ.table(x_test_ica))\n",
    "        \n",
    "        if name != \"SVM\"\n",
    "            ŷ = mode.(ŷ)\n",
    "        end\n",
    "\n",
    "        acc = MLJ.accuracy(ŷ, y_test_ica)\n",
    "        println(\"$name: $(round(acc*100, digits=2)) %\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "472dfa1c-2134-4749-8ad7-9bb7cf7fd106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading data from: heart_disease_uci.csv\n",
      "  Original Size: (920, 14)\n",
      " Categorical Null values replaced with ---> 'missingval'.\n",
      "  Deleted rows in features: [:trestbps, :chol, :thalch, :oldpeak]\n",
      "  Final shape: (827, 14)\n",
      "------------------------\n",
      "  Data split: 702 dev(85%), 125 test(15%)\n",
      "Indices generated for 5 stratified folds.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# (Aproach 4) Same as approach 1 with corssvalidation \n",
    "# -----------------------------------------------------------------\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "data, num_col, cat_col, target_col = load_and_clean_data(data_path)\n",
    "Random.seed!(1234)\n",
    "#---split training data and final test data---\n",
    "Pval = 0.15\n",
    "Ptest = 0.15\n",
    "rows, columns = size(data)\n",
    "N = rows\n",
    "(train_indices, val_indices, test_indices) = stratified_holdOut(data[!,target_col], Pval, Ptest)\n",
    "train_data = data[train_indices, :]\n",
    "val_data = data[val_indices, :]\n",
    "dev_data = vcat(train_data, val_data)\n",
    "test_data = data[test_indices, :]\n",
    "println(\"  Data split: $(size(dev_data,1)) dev(85%), $(size(test_data,1)) test(15%)\")\n",
    "\n",
    "#---split for crossvalidation---\n",
    "dev_num = select(dev_data, num_col)\n",
    "dev_cat = select(dev_data, cat_col)\n",
    "dev_targets = dev_data[!, target_col];\n",
    "\n",
    "#---make cv indices---\n",
    "k_folds=5 #numebr of folds, set to 5 as our dataset is small\n",
    "cv_indices = crossvalidation(dev_targets, k_folds);\n",
    "println(\"Indices generated for $k_folds stratified folds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae66ea74-024a-4595-9772-626fe9fa746c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Grid Search Masivo (Approach 4) ---\n",
      "Evaluando 28 configuraciones...\n",
      "[1/28] Probando SVC con Dict{Symbol, Any}(:kernel => \"rbf\", :C => 0.1) ... -> Acc: 57.84%\n",
      "[2/28] Probando SVC con Dict{Symbol, Any}(:kernel => \"rbf\", :C => 1.0) ... -> Acc: 56.56%\n",
      "[3/28] Probando SVC con Dict{Symbol, Any}(:kernel => \"rbf\", :C => 10.0) ... -> Acc: 55.99%\n",
      "[4/28] Probando SVC con Dict{Symbol, Any}(:kernel => \"rbf\", :C => 100.0) ... -> Acc: 54.56%\n",
      "[5/28] Probando SVC con Dict{Symbol, Any}(:kernel => \"linear\", :C => 0.1) ... -> Acc: 57.84%\n",
      "[6/28] Probando SVC con Dict{Symbol, Any}(:kernel => \"linear\", :C => 1.0) ... -> Acc: 56.56%\n",
      "[7/28] Probando SVC con Dict{Symbol, Any}(:degree => 2, :kernel => \"poly\", :C => 1.0) ... -> Acc: 56.56%\n",
      "[8/28] Probando SVC con Dict{Symbol, Any}(:kernel => \"sigmoid\", :C => 1.0) ... -> Acc: 56.56%\n",
      "[9/28] Probando DT con Dict(:max_depth => 3) ... -> Acc: 55.69%\n",
      "[10/28] Probando DT con Dict(:max_depth => 5) ... -> Acc: 56.55%\n",
      "[11/28] Probando DT con Dict(:max_depth => 7) ... -> Acc: 52.56%\n",
      "[12/28] Probando DT con Dict(:max_depth => 9) ... -> Acc: 49.01%\n",
      "[13/28] Probando DT con Dict(:max_depth => 12) ... -> Acc: 47.0%\n",
      "[14/28] Probando DT con Dict(:max_depth => -1) ... -> Acc: 46.59%\n",
      "[15/28] Probando KNN con Dict(:K => 1) ... -> Acc: 50.84%\n",
      "[16/28] Probando KNN con Dict(:K => 3) ... -> Acc: 54.55%\n",
      "[17/28] Probando KNN con Dict(:K => 5) ... -> Acc: 55.84%\n",
      "[18/28] Probando KNN con Dict(:K => 7) ... -> Acc: 57.69%\n",
      "[19/28] Probando KNN con Dict(:K => 15) ... -> Acc: 56.83%\n",
      "[20/28] Probando KNN con Dict(:K => 31) ... -> Acc: 57.84%\n",
      "[21/28] Probando ANN con Dict{Symbol, Any}(:topology => [5], :learningRate => 0.01) ... -> Acc: 57.42%\n",
      "[22/28] Probando ANN con Dict{Symbol, Any}(:topology => [10], :learningRate => 0.01) ... -> Acc: 57.27%\n",
      "[23/28] Probando ANN con Dict{Symbol, Any}(:topology => [32], :learningRate => 0.01) ... -> Acc: 57.28%\n",
      "[24/28] Probando ANN con Dict{Symbol, Any}(:topology => [64], :learningRate => 0.005) ... -> Acc: 56.98%\n",
      "[25/28] Probando ANN con Dict{Symbol, Any}(:topology => [10, 5], :learningRate => 0.01) ... -> Acc: 57.56%\n",
      "[26/28] Probando ANN con Dict{Symbol, Any}(:topology => [16, 8], :learningRate => 0.01) ... -> Acc: 57.29%\n",
      "[27/28] Probando ANN con Dict{Symbol, Any}(:topology => [32, 16], :learningRate => 0.005) ... -> Acc: 57.56%\n",
      "[28/28] Probando ANN con Dict{Symbol, Any}(:topology => [64, 32], :learningRate => 0.001) ... -> Acc: 56.13%\n",
      "\n",
      "--- TOP 10 MEJORES MODELOS ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>10×4 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">ModelType</th><th style = \"text-align: left;\">Hyperparams</th><th style = \"text-align: left;\">Mean_Accuracy</th><th style = \"text-align: left;\">Std_Accuracy</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:kernel =&gt; &quot;rbf&quot;, :C =&gt; 0.1)</td><td style = \"text-align: right;\">57.8413</td><td style = \"text-align: right;\">1.26273</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:kernel =&gt; &quot;linear&quot;, :C =&gt; 0.1)</td><td style = \"text-align: right;\">57.8413</td><td style = \"text-align: right;\">1.26273</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">KNN</td><td style = \"text-align: left;\">Dict(:K =&gt; 31)</td><td style = \"text-align: right;\">57.8352</td><td style = \"text-align: right;\">1.73292</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">KNN</td><td style = \"text-align: left;\">Dict(:K =&gt; 7)</td><td style = \"text-align: right;\">57.6943</td><td style = \"text-align: right;\">0.57103</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">ANN</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:topology =&gt; [10, 5], :learningRate =&gt; 0.01)</td><td style = \"text-align: right;\">57.5648</td><td style = \"text-align: right;\">4.01697</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">ANN</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:topology =&gt; [32, 16], :learningRate =&gt; 0.005)</td><td style = \"text-align: right;\">57.5607</td><td style = \"text-align: right;\">3.9794</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">ANN</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:topology =&gt; [5], :learningRate =&gt; 0.01)</td><td style = \"text-align: right;\">57.4208</td><td style = \"text-align: right;\">2.64739</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">ANN</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:topology =&gt; [16, 8], :learningRate =&gt; 0.01)</td><td style = \"text-align: right;\">57.2871</td><td style = \"text-align: right;\">4.56485</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">ANN</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:topology =&gt; [32], :learningRate =&gt; 0.01)</td><td style = \"text-align: right;\">57.279</td><td style = \"text-align: right;\">3.10975</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">ANN</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:topology =&gt; [10], :learningRate =&gt; 0.01)</td><td style = \"text-align: right;\">57.271</td><td style = \"text-align: right;\">3.91323</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& ModelType & Hyperparams & Mean\\_Accuracy & \\\\\n",
       "\t\\hline\n",
       "\t& String & String & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & SVC & Dict\\{Symbol, Any\\}(:kernel => \"rbf\", :C => 0.1) & 57.8413 & $\\dots$ \\\\\n",
       "\t2 & SVC & Dict\\{Symbol, Any\\}(:kernel => \"linear\", :C => 0.1) & 57.8413 & $\\dots$ \\\\\n",
       "\t3 & KNN & Dict(:K => 31) & 57.8352 & $\\dots$ \\\\\n",
       "\t4 & KNN & Dict(:K => 7) & 57.6943 & $\\dots$ \\\\\n",
       "\t5 & ANN & Dict\\{Symbol, Any\\}(:topology => [10, 5], :learningRate => 0.01) & 57.5648 & $\\dots$ \\\\\n",
       "\t6 & ANN & Dict\\{Symbol, Any\\}(:topology => [32, 16], :learningRate => 0.005) & 57.5607 & $\\dots$ \\\\\n",
       "\t7 & ANN & Dict\\{Symbol, Any\\}(:topology => [5], :learningRate => 0.01) & 57.4208 & $\\dots$ \\\\\n",
       "\t8 & ANN & Dict\\{Symbol, Any\\}(:topology => [16, 8], :learningRate => 0.01) & 57.2871 & $\\dots$ \\\\\n",
       "\t9 & ANN & Dict\\{Symbol, Any\\}(:topology => [32], :learningRate => 0.01) & 57.279 & $\\dots$ \\\\\n",
       "\t10 & ANN & Dict\\{Symbol, Any\\}(:topology => [10], :learningRate => 0.01) & 57.271 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m ModelType \u001b[0m\u001b[1m Hyperparams                       \u001b[0m\u001b[1m Mean_Accuracy \u001b[0m\u001b[1m Std_Accura\u001b[0m ⋯\n",
       "     │\u001b[90m String    \u001b[0m\u001b[90m String                            \u001b[0m\u001b[90m Float64       \u001b[0m\u001b[90m Float64   \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ SVC        Dict{Symbol, Any}(:kernel => \"rb…        57.8413       1.262 ⋯\n",
       "   2 │ SVC        Dict{Symbol, Any}(:kernel => \"li…        57.8413       1.262\n",
       "   3 │ KNN        Dict(:K => 31)                           57.8352       1.732\n",
       "   4 │ KNN        Dict(:K => 7)                            57.6943       0.571\n",
       "   5 │ ANN        Dict{Symbol, Any}(:topology => […        57.5648       4.016 ⋯\n",
       "   6 │ ANN        Dict{Symbol, Any}(:topology => […        57.5607       3.979\n",
       "   7 │ ANN        Dict{Symbol, Any}(:topology => […        57.4208       2.647\n",
       "   8 │ ANN        Dict{Symbol, Any}(:topology => […        57.2871       4.564\n",
       "   9 │ ANN        Dict{Symbol, Any}(:topology => […        57.279        3.109 ⋯\n",
       "  10 │ ANN        Dict{Symbol, Any}(:topology => […        57.271        3.913\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GANADOR DEL APPROACH 4:\n",
      "Modelo: SVC\n",
      "Config: Dict{Symbol, Any}(:kernel => \"rbf\", :C => 0.1)\n",
      "Accuracy CV: 57.84% ± 1.26\n"
     ]
    }
   ],
   "source": [
    "using DataFrames, Statistics\n",
    "\n",
    "println(\"--- Iniciando Grid Search Masivo (Approach 4) ---\")\n",
    "\n",
    "# 1. DEFINICIÓN DE HIPERPARÁMETROS A PROBAR\n",
    "# (Cumpliendo requisitos de la práctica)\n",
    "\n",
    "# A. SVM (Mínimo 8 configuraciones: Kernels y C variados)\n",
    "configs_svm = [\n",
    "    (:SVC, Dict(:kernel => \"rbf\", :C => 0.1)),\n",
    "    (:SVC, Dict(:kernel => \"rbf\", :C => 1.0)),\n",
    "    (:SVC, Dict(:kernel => \"rbf\", :C => 10.0)),\n",
    "    (:SVC, Dict(:kernel => \"rbf\", :C => 100.0)),\n",
    "    (:SVC, Dict(:kernel => \"linear\", :C => 0.1)),\n",
    "    (:SVC, Dict(:kernel => \"linear\", :C => 1.0)),\n",
    "    (:SVC, Dict(:kernel => \"poly\", :degree => 2, :C => 1.0)),\n",
    "    (:SVC, Dict(:kernel => \"sigmoid\", :C => 1.0))\n",
    "]\n",
    "\n",
    "# B. Decision Tree (Mínimo 6 profundidades)\n",
    "configs_dt = [\n",
    "    (:DT, Dict(:max_depth => 3)),\n",
    "    (:DT, Dict(:max_depth => 5)),\n",
    "    (:DT, Dict(:max_depth => 7)),\n",
    "    (:DT, Dict(:max_depth => 9)),\n",
    "    (:DT, Dict(:max_depth => 12)),\n",
    "    (:DT, Dict(:max_depth => -1)) # Sin límite\n",
    "]\n",
    "\n",
    "# C. k-NN (Mínimo 6 valores de k)\n",
    "configs_knn = [\n",
    "    (:KNN, Dict(:K => 1)),\n",
    "    (:KNN, Dict(:K => 3)),\n",
    "    (:KNN, Dict(:K => 5)),\n",
    "    (:KNN, Dict(:K => 7)),\n",
    "    (:KNN, Dict(:K => 15)),\n",
    "    (:KNN, Dict(:K => 31)) # k alto para ver si suaviza demasiado\n",
    "]\n",
    "\n",
    "# D. ANN (Mínimo 8 arquitecturas)\n",
    "# Variamos capas (1 o 2 ocultas) y neuronas\n",
    "configs_ann = [\n",
    "    # 1 Capa Oculta\n",
    "    (:ANN, Dict(:topology => [5], :learningRate => 0.01)),\n",
    "    (:ANN, Dict(:topology => [10], :learningRate => 0.01)),\n",
    "    (:ANN, Dict(:topology => [32], :learningRate => 0.01)),\n",
    "    (:ANN, Dict(:topology => [64], :learningRate => 0.005)),\n",
    "    # 2 Capas Ocultas\n",
    "    (:ANN, Dict(:topology => [10, 5], :learningRate => 0.01)),\n",
    "    (:ANN, Dict(:topology => [16, 8], :learningRate => 0.01)),\n",
    "    (:ANN, Dict(:topology => [32, 16], :learningRate => 0.005)),\n",
    "    (:ANN, Dict(:topology => [64, 32], :learningRate => 0.001))\n",
    "]\n",
    "\n",
    "# Unimos todas las configuraciones en una sola lista\n",
    "all_configs = vcat(configs_svm, configs_dt, configs_knn, configs_ann)\n",
    "\n",
    "# 2. BUCLE DE EJECUCIÓN\n",
    "results_grid = DataFrame(\n",
    "    ModelType = String[], \n",
    "    Hyperparams = String[], \n",
    "    Mean_Accuracy = Float64[], \n",
    "    Std_Accuracy = Float64[]\n",
    ")\n",
    "\n",
    "println(\"Evaluando $(length(all_configs)) configuraciones...\")\n",
    "\n",
    "for (idx, (m_type, params)) in enumerate(all_configs)\n",
    "    # Convertimos params a string para reporte\n",
    "    param_str = string(params)\n",
    "    \n",
    "    print(\"[$idx/$(length(all_configs))] Probando $m_type con $param_str ... \")\n",
    "    \n",
    "    # LLAMADA A TU FUNCIÓN MAESTRA\n",
    "    # (Asegúrate de que 'universalCrossValidation' esté cargada)\n",
    "    mu, sigma = universalCrossValidation1(\n",
    "        m_type, \n",
    "        params, \n",
    "        dev_num, \n",
    "        dev_cat, \n",
    "        dev_targets, \n",
    "        cv_indices\n",
    "    )\n",
    "    \n",
    "    push!(results_grid, (string(m_type), param_str, mu * 100, sigma * 100))\n",
    "    println(\"-> Acc: $(round(mu*100, digits=2))%\")\n",
    "end\n",
    "\n",
    "# 3. RESULTADOS Y MEJOR MODELO\n",
    "println(\"\\n--- TOP 10 MEJORES MODELOS ---\")\n",
    "sort!(results_grid, :Mean_Accuracy, rev=true)\n",
    "display(first(results_grid, 10))\n",
    "\n",
    "# Extraer el ganador\n",
    "best_row = results_grid[1, :]\n",
    "println(\"\\n GANADOR DEL APPROACH 4:\")\n",
    "println(\"Modelo: $(best_row.ModelType)\")\n",
    "println(\"Config: $(best_row.Hyperparams)\")\n",
    "println(\"Accuracy CV: $(round(best_row.Mean_Accuracy, digits=2))% ± $(round(best_row.Std_Accuracy, digits=2))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e73bc5f-b197-411c-a981-4803dfad856f",
   "metadata": {},
   "source": [
    "**LA FUNCION QUE SE VE ARRIBA PARA EL GRID SEARCH SIRVE COMO REFERENCIA PARA ENCONTRAR EL QEU DEBERÍA SER EL MEJOR MODELO, UNA VEZ ENCONTRADO ESE MODELO HAY QUE REENTRENARLO DE CERO CON EL 85% DE LOS DATOS Y EVALUARLO EN EL TEST SET RESERVADO AL INICIO QUE AÚN NO SE UTILIZÓ, PARA EVITAR ASI FILTRAR INFORMACION DEL TEST SET AL MODELO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f4771d-ef2b-466b-9ed5-c0c533ec898a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading data from: heart_disease_uci.csv\n",
      "  Original Size: (920, 14)\n",
      " Categorical Null values replaced with ---> 'missingval'.\n",
      "  Deleted rows in features: [:trestbps, :chol, :thalch, :oldpeak]\n",
      "  Final shape: (827, 14)\n",
      "------------------------\n",
      "  Data split: 702 dev(85%), 125 test(15%)\n",
      "Indices generated for 5 stratified folds.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# (Aproach 5) PCA with corssvalidation \n",
    "# -----------------------------------------------------------------\n",
    "data_path = \"heart_disease_uci.csv\"\n",
    "data, num_col, cat_col, target_col = load_and_clean_data(data_path)\n",
    "Random.seed!(1234)\n",
    "#---split training data and final test data---\n",
    "Pval = 0.15\n",
    "Ptest = 0.15\n",
    "rows, columns = size(data)\n",
    "N = rows\n",
    "(train_indices, val_indices, test_indices) = stratified_holdOut(data[!,target_col], Pval, Ptest)\n",
    "train_data = data[train_indices, :]\n",
    "val_data = data[val_indices, :]\n",
    "dev_data = vcat(train_data, val_data)\n",
    "test_data = data[test_indices, :]\n",
    "println(\"  Data split: $(size(dev_data,1)) dev(85%), $(size(test_data,1)) test(15%)\")\n",
    "\n",
    "#---split for crossvalidation---\n",
    "dev_num = select(dev_data, num_col)\n",
    "dev_cat = select(dev_data, cat_col)\n",
    "dev_targets = dev_data[!, target_col];\n",
    "\n",
    "#---make cv indices---\n",
    "k_folds=5 #numebr of folds, set to 5 as our dataset is small\n",
    "cv_indices = crossvalidation(dev_targets, k_folds);\n",
    "println(\"Indices generated for $k_folds stratified folds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "442d6ecd-3cdf-4c25-aa6d-87b53c7815b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Massive Grid Search (Approach 5: PCA + CV) ---\n",
      "Testing SVC ... -> Acc: 58.27%\n",
      "Testing SVC ... -> Acc: 53.55%\n",
      "Testing SVC ... -> Acc: 58.27%\n",
      "Testing DT ... -> Acc: 52.41%\n",
      "Testing DT ... -> Acc: 50.71%\n",
      "Testing KNN ... -> Acc: 56.7%\n",
      "Testing KNN ... -> Acc: 58.69%\n",
      "Testing ANN ... -> Acc: 58.42%\n",
      "Testing ANN ... -> Acc: 58.41%\n",
      "\n",
      "--- Ranking Approach 5 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>9×4 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Model</th><th style = \"text-align: left;\">Params</th><th style = \"text-align: left;\">Acc_Mean</th><th style = \"text-align: left;\">Acc_Std</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">KNN</td><td style = \"text-align: left;\">Dict(:K =&gt; 15, :pca_components =&gt; 17)</td><td style = \"text-align: left;\">58.6944</td><td style = \"text-align: left;\">2.06187</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">ANN</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:topology =&gt; [10], :learningRate =&gt; 0.01, :pca_components =&gt; 17)</td><td style = \"text-align: left;\">58.4167</td><td style = \"text-align: left;\">2.30317</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">ANN</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:topology =&gt; [16, 8], :learningRate =&gt; 0.005, :pca_components =&gt; 17)</td><td style = \"text-align: left;\">58.4138</td><td style = \"text-align: left;\">2.50284</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Real}(:pca_components =&gt; 17, :C =&gt; 1.0)</td><td style = \"text-align: left;\">58.2679</td><td style = \"text-align: left;\">2.14098</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Any}(:kernel =&gt; &quot;linear&quot;, :pca_components =&gt; 17, :C =&gt; 1.0)</td><td style = \"text-align: left;\">58.2679</td><td style = \"text-align: left;\">2.14098</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">KNN</td><td style = \"text-align: left;\">Dict(:K =&gt; 5, :pca_components =&gt; 17)</td><td style = \"text-align: left;\">56.7024</td><td style = \"text-align: left;\">4.18508</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">SVC</td><td style = \"text-align: left;\">Dict{Symbol, Real}(:pca_components =&gt; 17, :C =&gt; 10.0)</td><td style = \"text-align: left;\">53.5493</td><td style = \"text-align: left;\">2.85826</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">DT</td><td style = \"text-align: left;\">Dict(:pca_components =&gt; 17, :max_depth =&gt; 5)</td><td style = \"text-align: left;\">52.4074</td><td style = \"text-align: left;\">3.44528</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">DT</td><td style = \"text-align: left;\">Dict(:pca_components =&gt; 17, :max_depth =&gt; 8)</td><td style = \"text-align: left;\">50.7144</td><td style = \"text-align: left;\">3.3973</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& Model & Params & \\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & \\\\\n",
       "\t\\hline\n",
       "\t1 & KNN & Dict(:K => 15, :pca\\_components => 17) & $\\dots$ \\\\\n",
       "\t2 & ANN & Dict\\{Symbol, Any\\}(:topology => [10], :learningRate => 0.01, :pca\\_components => 17) & $\\dots$ \\\\\n",
       "\t3 & ANN & Dict\\{Symbol, Any\\}(:topology => [16, 8], :learningRate => 0.005, :pca\\_components => 17) & $\\dots$ \\\\\n",
       "\t4 & SVC & Dict\\{Symbol, Real\\}(:pca\\_components => 17, :C => 1.0) & $\\dots$ \\\\\n",
       "\t5 & SVC & Dict\\{Symbol, Any\\}(:kernel => \"linear\", :pca\\_components => 17, :C => 1.0) & $\\dots$ \\\\\n",
       "\t6 & KNN & Dict(:K => 5, :pca\\_components => 17) & $\\dots$ \\\\\n",
       "\t7 & SVC & Dict\\{Symbol, Real\\}(:pca\\_components => 17, :C => 10.0) & $\\dots$ \\\\\n",
       "\t8 & DT & Dict(:pca\\_components => 17, :max\\_depth => 5) & $\\dots$ \\\\\n",
       "\t9 & DT & Dict(:pca\\_components => 17, :max\\_depth => 8) & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m9×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Model \u001b[0m\u001b[1m Params                            \u001b[0m\u001b[1m Acc_Mean \u001b[0m\u001b[1m Acc_Std \u001b[0m\n",
       "     │\u001b[90m Any   \u001b[0m\u001b[90m Any                               \u001b[0m\u001b[90m Any      \u001b[0m\u001b[90m Any     \u001b[0m\n",
       "─────┼─────────────────────────────────────────────────────────────\n",
       "   1 │ KNN    Dict(:K => 15, :pca_components =…  58.6944   2.06187\n",
       "   2 │ ANN    Dict{Symbol, Any}(:topology => […  58.4167   2.30317\n",
       "   3 │ ANN    Dict{Symbol, Any}(:topology => […  58.4138   2.50284\n",
       "   4 │ SVC    Dict{Symbol, Real}(:pca_componen…  58.2679   2.14098\n",
       "   5 │ SVC    Dict{Symbol, Any}(:kernel => \"li…  58.2679   2.14098\n",
       "   6 │ KNN    Dict(:K => 5, :pca_components =>…  56.7024   4.18508\n",
       "   7 │ SVC    Dict{Symbol, Real}(:pca_componen…  53.5493   2.85826\n",
       "   8 │ DT     Dict(:pca_components => 17, :max…  52.4074   3.44528\n",
       "   9 │ DT     Dict(:pca_components => 17, :max…  50.7144   3.3973"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "println(\"\\n--- Massive Grid Search (Approach 5: PCA + CV) ---\")\n",
    "\n",
    "# Define Configurations\n",
    "configs_pca = [\n",
    "    # SVM (Kernel Linear often works well with PCA)\n",
    "    (:SVC, Dict(:C => 1.0, :pca_components => 17)),\n",
    "    (:SVC, Dict(:C => 10.0, :pca_components => 17)),\n",
    "    (:SVC, Dict(:kernel => \"linear\", :C => 1.0, :pca_components => 17)),\n",
    "    \n",
    "    # Decision Tree\n",
    "    (:DT,  Dict(:max_depth => 5, :pca_components => 17)),\n",
    "    (:DT,  Dict(:max_depth => 8, :pca_components => 17)),\n",
    "    \n",
    "    # k-NN\n",
    "    (:KNN, Dict(:K => 5, :pca_components => 17)),\n",
    "    (:KNN, Dict(:K => 15, :pca_components => 17)),\n",
    "    \n",
    "    # ANN (Topologies adjusted for 17 inputs)\n",
    "    (:ANN, Dict(:topology => [10], :learningRate => 0.01, :pca_components => 17)),\n",
    "    (:ANN, Dict(:topology => [16, 8], :learningRate => 0.005, :pca_components => 17))\n",
    "]\n",
    "\n",
    "results_pca = DataFrame(Model=[], Params=[], Acc_Mean=[], Acc_Std=[])\n",
    "\n",
    "for (m_type, params) in configs_pca\n",
    "    p_str = string(params)\n",
    "    print(\"Testing $m_type ... \")\n",
    "    \n",
    "    mu, sigma = universalCrossValidation_PCA(\n",
    "        m_type, params, \n",
    "        dev_num, dev_cat, dev_targets, \n",
    "        cv_indices\n",
    "    )\n",
    "    \n",
    "    push!(results_pca, (string(m_type), p_str, mu*100, sigma*100))\n",
    "    println(\"-> Acc: $(round(mu*100, digits=2))%\")\n",
    "end\n",
    "\n",
    "println(\"\\n--- Ranking Approach 5 ---\")\n",
    "sort!(results_pca, :Acc_Mean, rev=true)\n",
    "display(results_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522038ec-fc46-4b59-adc8-6ef66ba9229c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc514f3-95e8-4a10-b623-d1a14ec5bc68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c5139-5123-4b5c-b7a9-32f97dc4ddbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.7",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
